<!DOCTYPE HTML>
<html lang="zh_CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="理解和使用Pytorch搭建GAN, Matter">
    <meta name="description" content="参考链接：https://becominghuman.ai/understanding-and-building-generative-adversarial-networks-gans-8de7c1dc0e25
原文标题：Understa">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <title>理解和使用Pytorch搭建GAN | Matter</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    <script src="/libs/jquery/jquery.min.js"></script>
    
<meta name="generator" content="Hexo 4.2.0"><link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css"></head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper head-container">
            <div class="brand-logo">
                <a href="../index.html" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Matter</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>主页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>文章分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>

<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Matter</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			主页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			文章分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>

        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/4.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">理解和使用Pytorch搭建GAN</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        margin: 35px 0 15px 0;
        padding-left: 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #toc-content .is-active-link::before {
        background-color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">
                                深度学习
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2019-12-20
                </div>
                

                

                

                

                
            </div>

        </div>
        <hr class="clearfix">
        <div class="card-content article-card-content">
            <div id="articleContent">
                <p>参考链接：<a href="https://becominghuman.ai/understanding-and-building-generative-adversarial-networks-gans-8de7c1dc0e25" target="_blank" rel="noopener">https://becominghuman.ai/understanding-and-building-generative-adversarial-networks-gans-8de7c1dc0e25</a></p>
<p>原文标题：Understanding and building Generative Adversarial Networks(GANs)- Deep Learning with PyTorch</p>
<hr>
<blockquote>
<p><em>We’ll be building a Generative Adversarial Network that will be able to generate images of birds that never actually existed in the real world.</em></p>
</blockquote>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_OshLCyKhDM6bo-MXqfrM9w.jpeg" alt="img"></p>
<p>-These bird images are purely generated by the Deep Learning Model(GAN)-</p>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_RiLLyBMOagYJktyv5eodIQ.png" alt="img"></p>
<p>Before we actually start building a GAN, let us first talk about the idea behind GANs. GANs were invented by Ian Goodfellow, he obtained his <a href="https://en.wikipedia.org/wiki/Bachelor_of_Science" target="_blank" rel="noopener">B.S.</a> and <a href="https://en.wikipedia.org/wiki/Master_of_Science" target="_blank" rel="noopener">M.S.</a> in computer science from <a href="https://en.wikipedia.org/wiki/Stanford_University" target="_blank" rel="noopener">Stanford University</a> and his Ph.D. in machine learning from the <a href="https://en.wikipedia.org/wiki/Université_de_Montréal" target="_blank" rel="noopener">Université de Montréal</a>,. This is the new big thing in the field of Deep Learning right now. Yann LeCun, the director of Facebook AI said :</p>
<blockquote>
<p><em>“Generative Adversarial Networks is the most interesting idea in the last ten years in Machine Learning.”</em></p>
</blockquote>
<h2 id="何谓GANs-它有何用"><a href="#何谓GANs-它有何用" class="headerlink" title="何谓GANs ? 它有何用 ?"></a>何谓GANs ? 它有何用 ?</h2><p>Neural Networks are good at classifying and predicting things, and AI Researchers wanted to make the neural net more human in nature by allowing it to CREATE rather than just letting it see things, and turns out that Ian Goodfellow was successful in inventing a class of Deep Learning Model which could do that.</p>
<h2 id="GANs如何工作"><a href="#GANs如何工作" class="headerlink" title="GANs如何工作 ?"></a>GANs如何工作 ?</h2><p>GANs contain two separate neural networks. Let us call one neural network as “G”, which stands for <strong>Generator </strong>and the other neural network as “D”, which is a <strong>Discriminator</strong>. The Generator first generates random images and a Discriminator sees those images and tells the Generator how real the generated images are.</p>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_YH3b1fARO-bf6gU3kyzT4A.jpeg" alt="img"></p>
<h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器 :"></a>生成器 :</h2><p>In the starting phase, a Generator model takes <code>random noise signals</code> as input and generates a random noisy image as the output, gradually with the help of the Discriminator, it starts generating images of a particular class that look real.</p>
<h2 id="判别器"><a href="#判别器" class="headerlink" title="判别器 :"></a>判别器 :</h2><p>The Discriminator which will be the opponent of Generator is fed with both the generated images as well as a certain class of images at the same time, allowing it to tell the generated how the real image looks like.</p>
<p>After reaching a certain point, the Discriminator will be unable to tell if the generate image is a real or a fake image, and that is when we can see images of a certain class(class that the discriminator is trained with.) being generated by out Generator that never actually existed before.</p>
<h2 id="GAN的应用"><a href="#GAN的应用" class="headerlink" title="GAN的应用 :"></a>GAN的应用 :</h2><ul>
<li><p>超分辨率（Super Resolution）.</p>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_CjlvvAEa800e3asqLWkFpQ.png" alt="img"></p>
</li>
</ul>
<ul>
<li>Assisting Artists.</li>
</ul>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_xW7HOxpzO_ZNGyYXX4MMPQ.jpeg" alt="img"></p>
<ul>
<li><p>Element Abstraction.</p>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_iRyCj-s28wuupEZjOIcknw.png" alt="img"></p>
<h1 id="上代码"><a href="#上代码" class="headerlink" title="上代码"></a>上代码</h1><p>NOTE : The below explanation of the code is not prepared for a novice deep learning programmer , i expect you to be comfortable with the deep learning accent in python.</p>
<p><strong>L</strong>et us start by importing all the required python libraries for building our GAN. Please make sure PyTorch is installed in your computer before you start.</p>
<pre class=" language-lang-python"><code class="language-lang-python">#importing required libraries
from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torch.autograd import Variable
</code></pre>
<p><strong>N</strong>ow let us set the hyper-parameters which will be the <strong>batch-size</strong> and <strong>image-size</strong> in this case :</p>
<pre class=" language-lang-python"><code class="language-lang-python"># Setting hyperparameters
batchSize = 64 
imageSize = 64
</code></pre>
</li>
</ul>
<p>  In the first line, we have set the size of the batch to 64. And in the second line we have set the size of the images generated by the generator to 64 x 64 resolution.</p>
<hr>
<p>  <strong>T</strong>hen we are going to create an object to perform image transformations as given below :</p>
<pre class=" language-lang-python"><code class="language-lang-python"># Creating the transformations
transform = transforms.Compose([transforms.Scale(imageSize), 
                                transforms.ToTensor(), 
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])
</code></pre>
<p>The above transformations are necessary to make the image compatible as an input to the neural network of the discriminator.</p>
<hr>
<p>NOTE : In order to get the dataset, click here and you will be directed to <a href="https://github.com/venkateshtata/GAN_Medium.git" target="_blank" rel="noopener">https://github.com/venkateshtata/GAN_Medium.git</a> , clone that repository into your local system and replace the <code>dcgan.py</code> file with the python file your writing to. the <code>data</code> folder contains the dataset.</p>
<hr>
<p><strong>N</strong>ow lets load our dataset from a respective directory. The type of dataset we are going to be using here is a <code>CIFAR-10</code> dataset. We are going to load them in batches, and make sure that the python file you are writing to is in the same directory for less complexity while importing the dataset.</p>
<pre class=" language-lang-python"><code class="language-lang-python"># Loading the dataset
dataset = dset.CIFAR10(root = './data', download = True, transform = transform)
dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)
</code></pre>
<p>We download the training set in the <code>./data</code> folder and we apply the previous transformations on each image. Then use <code>dataLoader</code> to get the images of the training set batch by batch. Almost every element of the above code is self explanatory, the value of <code>num_workers</code> defines the number of threads that must be used to carry out the process of loading the training data.</p>
<hr>
<p><strong>A</strong>s we will be dealing with multiple(2) neural networks here, we will be defining a universal function to initialise the weights of a given neural network by calling the function and passing the NN(Neural Network) into it.</p>
<pre class=" language-lang-python"><code class="language-lang-python">def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)
</code></pre>
<p>The above <code>weights_init</code> function takes as input a neural network <code>m</code> and will initialise all its weights. This function will be called for each iteration during the training process.</p>
<hr>
<p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_NFO8IogPJRf_eGKBZnd-Fg.png" alt="img"></p>
<p><strong>O</strong>ur first big step will be to define a class for our <code>Generator neural network</code>. We’ll start by creating a class that will be holding the architecture of the Generator, which will basically contain a sequence of layers that each input undergoes.</p>
<pre class=" language-lang-python"><code class="language-lang-python">class G(nn.Module):
    def __init__(self):
            super(G, self).__init__()
            self.main = nn.Sequential(
                            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),
                            nn.BatchNorm2d(512),
                            nn.ReLU(True),
                            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),
                            nn.BatchNorm2d(256),
                            nn.ReLU(True),
                            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),
                            nn.BatchNorm2d(128),
                            nn.ReLU(True),
                            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),
                            nn.BatchNorm2d(64),
                            nn.ReLU(True),
                            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),
                            nn.Tanh()
                        )
</code></pre>
<p><strong>B</strong>reaking down the above code :</p>
<ul>
<li>We have created a class ‘G’, referring to the Generator neural network, and inheriting from <code>nn.module</code> which contains all the tools required for building neural networks, which help us is placing different applications and and connections inside a given neural network.</li>
<li>Then we create a meta module of a neural network that will contain a sequence of modules such as convolutions, full connections, etc.</li>
<li>A great thing to observe from the above Fig 1.0 is that the structures of neural networks of both Generator and the Discriminator are inverse to each other, which basically means that <strong>in Generator, the Convolution must be in an inverse way</strong>, where the the input will be random noise vectors. Hence we start with an inverse convolution using <code>ConvTranspose2d</code>.</li>
<li>Then we normalize all the features along the dimension of the batch and apply a <code>ReLU</code> rectification to break the linearity. Click <a href="http://pytorch.org/docs/master/nn.html" target="_blank" rel="noopener">here</a> for more detailed explanation of parameters used in the above functions.</li>
<li>We repeat the above operations again while changing the input nodes from ‘100’ to ‘512’, the number of feature maps from <code>512</code> to <code>256</code> and keeping the bias as False. [ Note: The values i am choosing in the above code are choices of researchers. ]</li>
<li>In the final <code>ConvTranspose2d</code> we will be outputting 3 filters as the output image of the generator is going to be a 3 channel(RGB) and we apply a <code>Tanh</code> rectification to break the linearity and stay between -1 and +1.</li>
</ul>
<hr>
<p><strong>N</strong>ow we need to create a tool which will be a forward function to propogate the signal inside the Generator.</p>
<pre class=" language-lang-python"><code class="language-lang-python">def forward(self, input):
        output = self.main(input)
        return output
</code></pre>
<p>The input of the above function will be some random vector of size <code>100</code> as defined inside the <code>G</code> class. It returns the output containing the generated images. The initial image is made up random vectors.</p>
<hr>
<p><strong>C</strong>reating the generator :</p>
<pre class=" language-lang-python"><code class="language-lang-python">netG = G() 
netG.apply(weights_init)
</code></pre>
<p>Here we are creating a generator object and initialising all the weights of the input neural network.</p>
<hr>
<p><strong>N</strong>ow, lets start defining our <strong>Discriminator</strong> class that will be holding the architecture of a Discriminator.</p>
<pre class=" language-lang-python"><code class="language-lang-python">class D(nn.Module):
def __init__(self):
        super(D, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(3, 64, 4, 2, 1, bias = False),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(64, 128, 4, 2, 1, bias = False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(128, 256, 4, 2, 1, bias = False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(256, 512, 4, 2, 1, bias = False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace = True),
            nn.Conv2d(512, 1, 4, 1, 0, bias = False),
            nn.Sigmoid()
        )
</code></pre>
<p><strong>B</strong>reaking down the Discriminator :</p>
<ul>
<li>Similar to the G class, the <code>D</code> Discriminator class is inheriting from the <code>nn.module</code>. The input of the <strong>Discriminator</strong> will be the image generated by the <strong>Generator</strong>, to which the <strong>Discriminator</strong> will be returning a number between 0 and 1 as output.</li>
<li>Since it takes a generated image of the generator, the first operation is going to be a convolution, hence we start with a convolution and apply <code>LeakyReLU</code>.</li>
<li>Observe that unlike the what we did in <code>G</code> class, we are using <code>LeakyReLU</code> here, which will take the negative slope till <code>0.2</code>, and this comes from frequent experimentation, which i didn’t do, but researchers choice.</li>
<li>We use <code>BatchNorm2d</code> to normalize all the features along the dimension of the batch.</li>
<li>And at the end, we are using the classic old fashioned function, which is the <code>sigmoid</code> function to break the linearity and stay between 0 and 1.</li>
</ul>
<hr>
<p><strong>N</strong>ow, in order to forward propagate the signal into the <strong>Discriminator</strong>, we need to define a <code>Forward</code> class, which is going to carry the output of the generator to the <strong>Discriminator</strong> :</p>
<pre class=" language-lang-python"><code class="language-lang-python">def forward(self, input):
        output = self.main(input)
        return output.view(-1)
</code></pre>
<p>In the final line we return the output which will be a value between 0 and 1, because we need to flatten passed NN to make sure the vectors are in the same dimension.</p>
<hr>
<p><strong>C</strong>reating the Discriminator :</p>
<pre class=" language-lang-python"><code class="language-lang-python">netD = D() 
netD.apply(weights_init)
</code></pre>
<p>We create the discriminator object of the above class <code>D</code> and initialize all the weights of its neural network.</p>
<hr>
<p><strong>N</strong>ow its time we train our Generative Adversarial Network. But before that we need to start by getting a criteria that will measure the error of prediction given by the discriminator. In order to achieve that, we are going to use <strong>BCE Loss</strong>(where BCE means Binary Cross Entropy.), which is perfect for Adversarial Neural Networks. Hence we need optimisers for both the generator as well as the discriminator.</p>
<pre class=" language-lang-python"><code class="language-lang-python">criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))
</code></pre>
<p>We start by creating a criterion object that will measure the error between the prediction and the target. Then we create optimisers for objects of both discriminator and the generator.</p>
<p>We are using <code>Adam</code> optimiser from the <code>optim</code> module, which is a highly advance optimal for stochastic gradient descent.</p>
<hr>
<p><strong>W</strong>e’ll be training our neural nets for <code>25</code> epochs, hence :</p>
<pre class=" language-lang-python"><code class="language-lang-python">for epoch in range(25):
</code></pre>
<p>Then we need to iterate over the images within the dataset, hence :</p>
<pre class=" language-lang-python"><code class="language-lang-python">for i, data in enumerate(dataloader, 0):
</code></pre>
<p>First step is to update the weights of the neural network of the discriminator, hence we initialise the gradients of the discriminator to 0 with respect to the weights :</p>
<pre class=" language-lang-python"><code class="language-lang-python">netD.zero_grad()
</code></pre>
<p><strong>A</strong>s we know that our discriminator must be trained with both the real and fake images at a time. Hence we will train the discriminator with a real image of the dataset first :</p>
<pre class=" language-lang-python"><code class="language-lang-python">real, _ = data
        input = Variable(real)
        target = Variable(torch.ones(input.size()[0]))
        output = netD(input)
        errD_real = criterion(output, target)
</code></pre>
<p>We get a real image of the dataset which will be used to train the discriminator, and then wrap it in a variable. Then we forward propagate this real image into the neural network of the discriminator to get the prediction (a value between 0 and 1) and compute the loss between the predictions (output) and the target (equal to 1).</p>
<hr>
<p><strong>N</strong>ow, training the discriminator with a fake image generated by the generator :</p>
<pre class=" language-lang-python"><code class="language-lang-python">noise = Variable(torch.randn(input.size()[0], 100, 1, 1))
        fake = netG(noise)
        target = Variable(torch.zeros(input.size()[0]))
        output = netD(fake.detach())
        errD_fake = criterion(output, target)
</code></pre>
<p>Here, first we are making a random input vector (noise) of the generator and forward propagate this random input vector into the neural network of the generator to get some fake generated images. Then we forward propagate the fake generated images into the neural network of the discriminator to get the prediction (a value between 0 and 1) and compute the loss between the prediction (output) and the target (equal to 0).</p>
<hr>
<p><strong>B</strong>ack-propagating the total error :</p>
<pre class=" language-lang-python"><code class="language-lang-python">errD = errD_real + errD_fake
        errD.backward()
        optimizerD.step()
</code></pre>
<p>Here we are computing the total error of the discriminator and backpropagating the loss error by computing the gradients of the total error with respect to the weights of the discriminator. At the end we apply the optimizer to update the weights according to how much they are responsible for the loss error of the discriminator.</p>
<hr>
<p><strong>N</strong>ext step is to update the weights of the neural network of the generator :</p>
<pre class=" language-lang-python"><code class="language-lang-python">netG.zero_grad()
        target = Variable(torch.ones(input.size()[0]))
        output = netD(fake)
        errG = criterion(output, target)
        errG.backward()
        optimizerG.step()
</code></pre>
<p><strong>A</strong>s done previously , first we are initialising the gradients of the generator to 0 with respect to the weights. Getting the target. Forward propagating the fake generated images into the neural network of the discriminator to get the prediction (a value between 0 and 1) and then computing the loss between the prediction (output between 0 and 1) and the target (equal to 1). Then back-propagating the loss error by computing the gradients of the total error with respect to the weights of the generator and applying the optimizer to update the weights according to how much they are responsible for the loss error of the generator.</p>
<hr>
<p><strong>N</strong>ow, our final step is to print the losses and save the real images and the generated images of the mini batch every 100 steps. Which is done as followed :</p>
<pre class=" language-lang-python"><code class="language-lang-python">print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.data[0], errG.data[0]))
        if i % 100 == 0:
            vutils.save_image(real, '%s/real_samples.png' % "./results", normalize = True)
            fake = netG(noise)
            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % ("./results", epoch), normalize = True)
</code></pre>
<h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码 :"></a>完整代码 :</h2><pre class=" language-lang-python"><code class="language-lang-python">from __future__ import print_function
import torch
import torch.nn as nn
import torch.nn.parallel
import torch.optim as optim
import torch.utils.data
import torchvision.datasets as dset
import torchvision.transforms as transforms
import torchvision.utils as vutils
from torch.autograd import Variable

batchSize = 64 
imageSize = 64

transform = transforms.Compose([transforms.Scale(imageSize), 
                                transforms.ToTensor(), 
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) # We create a list of transformations (scaling, tensor conversion, normalization) to apply to the input images.

dataset = dset.CIFAR10(root = './data', 
                       download = True, 
                       transform = transform) 

dataloader = torch.utils.data.DataLoader(dataset, 
                                         batch_size = batchSize, 
                                         shuffle = True, num_workers = 2) 

def weights_init(m):
    classname = m.__class__.__name__
    if classname.find('Conv') != -1:
        m.weight.data.normal_(0.0, 0.02)
    elif classname.find('BatchNorm') != -1:
        m.weight.data.normal_(1.0, 0.02)
        m.bias.data.fill_(0)

# Generator
class G(nn.Module):
    def __init__(self):
            super(G, self).__init__()
            self.main = nn.Sequential(
                nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),
                nn.BatchNorm2d(512),
                nn.ReLU(True),
                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),
                nn.BatchNorm2d(256),
                nn.ReLU(True),
                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),
                nn.BatchNorm2d(128),
                nn.ReLU(True),
                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),
                nn.BatchNorm2d(64),
                nn.ReLU(True),
                nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),
                nn.Tanh()
            )

    def forward(self, input):
            output = self.main(input)
            return output
netG = G()
netG.apply(weights_init)


# Discriminator
class D(nn.Module):
    def __init__(self):
            super(D, self).__init__()
            self.main = nn.Sequential(
                nn.Conv2d(3, 64, 4, 2, 1, bias = False),
                nn.LeakyReLU(0.2, inplace = True),
                nn.Conv2d(64, 128, 4, 2, 1, bias = False),
                nn.BatchNorm2d(128),
                nn.LeakyReLU(0.2, inplace = True),
                nn.Conv2d(128, 256, 4, 2, 1, bias = False),
                nn.BatchNorm2d(256),
                nn.LeakyReLU(0.2, inplace = True),
                nn.Conv2d(256, 512, 4, 2, 1, bias = False),
                nn.BatchNorm2d(512),
                nn.LeakyReLU(0.2, inplace = True),
                nn.Conv2d(512, 1, 4, 1, 0, bias = False),
                nn.Sigmoid()
            )

    def forward(self, input):
            output = self.main(input)
            return output.view(-1)
netD = D()
netD.apply(weights_init)

# Create criterion
criterion = nn.BCELoss()
optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))
optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))

# Batch Training
for epoch in range(25):

    for i, data in enumerate(dataloader, 0):

            netD.zero_grad()

            real, _ = data
            input = Variable(real)
            target = Variable(torch.ones(input.size()[0]))
            output = netD(input)
            errD_real = criterion(output, target)

            noise = Variable(torch.randn(input.size()[0], 100, 1, 1))
            fake = netG(noise)
            target = Variable(torch.zeros(input.size()[0]))
            output = netD(fake.detach())
            errD_fake = criterion(output, target)

            errD = errD_real + errD_fake
            errD.backward()
            optimizerD.step()
            netG.zero_grad()
            target = Variable(torch.ones(input.size()[0]))
            output = netD(fake)
            errG = criterion(output, target)
            errG.backward()
            optimizerG.step()

            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i,     len(dataloader), errD.data[0], errG.data[0]))
            if i % 100 == 0:
                vutils.save_image(real, '%s/real_samples.png' % "./results", normalize = True)
                fake = netG(noise)
                vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % ("./results", epoch), normalize = True)
</code></pre>
<p>代码库在此 : <a href="https://github.com/venkateshtata/GAN_Medium" target="_blank" rel="noopener">https://github.com/venkateshtata/GAN_Medium</a></p>

            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://lunyang.github.io" rel="external nofollow noreferrer">lunyang</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://lunyang.github.io">https://lunyang.github.io</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint polocy. If reproduced, please indicate source
                    <a href="https://lunyang.github.io" target="_blank">lunyang</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">

<div id="article-share">
    
    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>
            
        </div>
    </div>

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="../001-li-jie-lstm/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="LSTM">
                        
                        <span class="card-title">LSTM</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            参考资料：https://colah.github.io/posts/2015-08-Understanding-LSTMs/

循环神经网络Humans don’t start their thinking from scratch ev
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2019-12-20
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    深度学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="../vae-bian-fen-zi-bian-ma-qi-vae-yuan-lai-shi-zhe-me-yi-hui-shi/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="变分自编码器VAE是这么一回事">
                        
                        <span class="card-title">变分自编码器VAE是这么一回事</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            参考链接：https://zhuanlan.zhihu.com/p/34998569

过去虽然没有细看，但印象里一直觉得变分自编码器（Variational Auto-Encoder，VAE）是个好东西。趁着最近看概率图模型的三分钟热度，
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2019-12-20
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="../categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" class="post-category">
                                    深度学习
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


<!-- 代码块折行 -->


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>


    <footer class="page-footer bg-color">
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            <span id="year">2019</span>
            <a href="https://lunyang.github.io" target="_blank">lunyang</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:53917181@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>













    <a href="../atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script src="/js/search.js"></script>
<script type="text/javascript">
$(function () {
    searchFunc("/" + "search.xml", 'searchInput', 'searchResult');
});
</script>
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->


    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    

    

    
    
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
