<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>N-Shot 学习</title>
      <link href="/n-shot-learning/"/>
      <url>/n-shot-learning/</url>
      
        <content type="html"><![CDATA[<p>参考连接：<a href="https://blog.floydhub.com/n-shot-learning/" target="_blank" rel="noopener">https://blog.floydhub.com/n-shot-learning/</a></p><hr><blockquote><p><em>Artificial Intelligence is the new electricity - Andrew NG</em></p></blockquote><p>If AI is the new electricity, then data is the new coal.<br>Unfortunately, just as we’ve seen a hazardous depletion in the amount of available coal, many AI applications have little or no data accessible to them.</p><p>New technology has made up for a lack of physical resources; likewise, new techniques are needed to allow applications with little data to perform satisfactorily. This is the issue at the heart of what is becoming a very popular field: <strong>N-shot Learning</strong>.</p><p><img src="/images/N-Shot%20Learning/em.gif" alt="Eminem image surrounded by the intro of Lose Yourself"></p><p>You may be asking, what the heck is a shot, anyway? Fair question. A shot is nothing more than a single example available for training, so in N-shot learning, we have N examples for training. With the term “few-shot learning”, the <em>“few” usually lies between zero and five</em>, meaning that training a model with zero examples is known as zero-shot learning,  one example is one-shot learning, and so on. All of these variants are trying to solve the same problem with differing levels of training material.</p><h3 id="什么是-N-Shot"><a href="#什么是-N-Shot" class="headerlink" title="什么是 N-Shot?"></a>什么是 N-Shot?</h3><p>Why do we need this when we are already getting less than a 4% error in ImageNet?</p><p>To start, ImageNet’s dataset contains a multitude of examples for machine learning, which is not always the case in fields like medical imaging, drug discovery and many others where AI could be crucially important. Typical deep learning architecture relies on substantial data for sufficient outcomes- ImageNet, for example, would need to train on hundreds of hotdog images before accurately assessing new images as hotdogs. And some datasets, much like a fridge after a 4th of July celebration, are greatly lacking in hotdogs.</p><p>There are many use cases for machine learning where data is scarce, and that is where this technology comes in. We need to train a deep learning model which has millions or even billions of parameters, all randomly initialized, to learn to classify an unseen image using no more than 5 images. To put it succinctly, our model has to train using a very limited number of hotdog images.</p><p>To approach an issue as complex as this one, we need to first define it clearly.<br>In the N-shot learning field, we have $n$ labeled examples of each $K$ classes, i.e. $N∗K$ total examples which we call support set $S$ . We also have to classify Query Set $Q$, where each example lies in one of the $K$ classes.  N-shot learning has three major sub-fields: zero-shot learning, one-shot learning, and few-shot learning, which each deserve individual attention.</p><h3 id="Zero-Shot-Learning"><a href="#Zero-Shot-Learning" class="headerlink" title="Zero-Shot Learning"></a>Zero-Shot Learning</h3><p>To me, this is the most interesting sub-field. With zero-shot learning, the target is to classify unseen classes without a single training example.</p><p>How does a machine “learn” without having any data to utilize?</p><p>Think about it this way. Can you classify an object without ever seeing it?</p><p>Yes, you can if you have adequate information about its appearance, properties, and functionality. Think back to how you came to understand the world as a kid. You could spot Mars in the night sky after reading about its color and where it would be that night, or identify the constellation Cassiopeia from only being told “it’s basically a malformed ‘W’”.</p><p>According to this year trend in NLP, <a href="https://blog.floydhub.com/ten-trends-in-deep-learning-nlp/#9-zero-shot-learning-will-become-more-effective" target="_blank" rel="noopener">Zero shot learning will become more effective</a>.</p><p>A machine utilizes the metadata of the images to perform the same task. The metadata is nothing but the features associated with the image. Here is a list of a few papers in this field which gave excellent results.</p><ul><li><a href="https://arxiv.org/pdf/1711.06025v2.pdf" target="_blank" rel="noopener">Learning to Compare: Relation Network for Few-Shot Learning</a></li><li><a href="https://arxiv.org/pdf/1605.05395v1.pdf" target="_blank" rel="noopener">Learning Deep Representations of Fine-Grained Visual Descriptions</a></li><li><a href="https://arxiv.org/abs/1412.6568v3" target="_blank" rel="noopener">Improving zero-shot learning by mitigating the hubness problem</a></li></ul><h3 id="One-Shot-学习"><a href="#One-Shot-学习" class="headerlink" title="One-Shot 学习"></a>One-Shot 学习</h3><p>In one-shot learning, we only have a single example of each class. Now the task is to classify any test image to a class using that constraint. There are many different architectures developed to achieve this goal, such as <a href="https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf" target="_blank" rel="noopener">Siamese Neural Networks</a>, which brought about major progress and led to exceptional results, and then <a href="https://arxiv.org/pdf/1606.04080.pdf" target="_blank" rel="noopener">matching networks</a>, which also helped us make great leaps in this field.</p><p>Now there are many excellent papers for understanding one-shot learning, as below.</p><ul><li><a href="https://arxiv.org/pdf/1703.03400v3.pdf" target="_blank" rel="noopener">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a></li><li><a href="https://arxiv.org/pdf/1605.06065v1.pdf" target="_blank" rel="noopener">One-shot Learning with Memory-Augmented Neural Networks</a></li><li><a href="https://arxiv.org/pdf/1703.05175v2.pdf" target="_blank" rel="noopener">Prototypical Networks for Few-shot Learning</a></li></ul><h3 id="Few-Shot-学习"><a href="#Few-Shot-学习" class="headerlink" title="Few-Shot 学习"></a>Few-Shot 学习</h3><p>Few-shot learning is just a flexible version of one-shot learning, where we have more than one training example (usually two to five images, though most of the above-mentioned models can be used for few-shot learning as well).</p><p>During the 2019 Conference on Computer Vision and Pattern Recognition, <a href="https://arxiv.org/pdf/1812.02391v3.pdf" target="_blank" rel="noopener">Meta-Transfer Learning for Few-Shot Learning</a> was presented. This model set the precedent for future research; it gave state-of-the-art results and paved the path for more sophisticated meta-transfer learning methods.</p><p>Many of these meta-learning and reinforcement-learning algorithms are combined with typical deep learning algorithms to produce remarkable results. Prototypical networks（原型网络） are one of the most popular deep learning algorithms, and are frequently used for this task.</p><p>In this article, we’ll accomplish this task using <a href="https://arxiv.org/pdf/1703.05175v2.pdf" target="_blank" rel="noopener">Prototypical Networks</a> and understand how it works and why it works.</p><h2 id="原型网络背后的思想"><a href="#原型网络背后的思想" class="headerlink" title="原型网络背后的思想"></a>原型网络背后的思想</h2><p><img src="https://lh5.googleusercontent.com/dM2dhO5xN_JAAtPZy4Ns5x1rBuKU-bGZl8Hj6bO71qIP-F48nsCgmaqKVtotqEmunEoyLJIUZWQ2P7l1YqglZ3_XArvZ1yyOmicJdMJ48Bzw9k9jAvRTKL4cHDpHREEM97CwDkES" alt="A diagram of the function of the prototypical network. An encoder maps an image into a vector in the embedding space (N-Shot%20Learning/img1-1577192734392.png). Support images are used to define the prototype (stars). Distances between prototypes and encoded query images are used to classify them. Source"></p><blockquote><p>A diagram of the function of the prototypical network. An encoder maps an image into a vector in the embedding space (dark circles). Support images are used to define the prototype (stars). Distances between prototypes and encoded query images are used to classify them. <a href="https://www.semanticscholar.org/paper/Gaussian-Prototypical-Networks-for-Few-Shot-on-Fort/feaecb5f7a8d29636650db7c0b480f55d098a6a7/figure/1" target="_blank" rel="noopener">Source</a></p></blockquote><p>Unlike typical deep learning architecture, prototypical networks do not classify the image directly, and instead learn the mapping of an image in <a href="https://en.wikipedia.org/wiki/Metric_space" target="_blank" rel="noopener">metric space</a>.</p><p>For anyone needing a mathematics refresher, metric space deals with the notion of “distance”.  It does not have a distinguished “origin” point; instead, in metric space we only compute the distance of one point to another. You therefore lack the operations of addition and scalar multiplication that you have in a vector space (because, unlike with vectors, a point only represents a coordinate, and adding two coordinates or scaling a coordinate makes no sense!). Check out <a href="https://math.stackexchange.com/questions/114940/what-is-the-difference-between-metric-spaces-and-vector-spaces" target="_blank" rel="noopener">this</a> link to learn more about the difference between vector space and metric space.</p><p>Now that we have that background, we can begin to understand how prototypical networks do not classify the image directly, but instead learn the mapping of an image in metric space. As can be seen in the above diagram, the encoder maps the images of the same class within tight proximity to each other, while different classes are spaced at a considerable distance. This means that whenever a new example is given, the network just checks the nearest cluster and classifies the example to its corresponding class. The underlying model in the prototypical net that maps images into metric space can be called an “Image2Vector” model, which is a Convolutional Neural Network (CNN) based architecture.</p><p>Now for those who don’t know a lot about CNNs, you can read more here:</p><ul><li>Check out the list of best deep learning courses <a href="https://blog.floydhub.com/best-deep-learning-courses-updated-for-2019/" target="_blank" rel="noopener">here</a>.</li><li>Check out the list of best deep learning book <a href="https://blog.floydhub.com/best-deep-learning-books-updated-for-2019/" target="_blank" rel="noopener">here</a>.</li><li>To learn and apply it quickly refer to <a href="https://blog.floydhub.com/building-your-first-convnet/" target="_blank" rel="noopener">Building Your First ConvNet</a></li></ul><h3 id="A-brief-Introduction-to-Prototypical-Networks"><a href="#A-brief-Introduction-to-Prototypical-Networks" class="headerlink" title="A brief Introduction to Prototypical Networks"></a>A brief Introduction to Prototypical Networks</h3><p>Simply put, their aim is to train a classifier. This classifier can then make generalizations regarding new classes that are unavailable during training, and only needs a small number of examples of each new class. Hence, the training set contains images of a set of classes, while our test set contains images of another set of classes which is entirely disjointed from the former one. In this model, the examples are divided randomly into the support set and query set.</p><h3 id="Overview-of-Prototypical-Network"><a href="#Overview-of-Prototypical-Network" class="headerlink" title="Overview of Prototypical Network"></a>Overview of Prototypical Network</h3><p><img src="https://lh3.googleusercontent.com/D1r0cQ9QlrF3b-v4PlM1T_8kmdo7adxrTak5JcDZbhPxucxcdME9nHZsvC1qOtjIpj5SqcYVvw8NRrjBj9ryl6deOPJWPlOJqNnwMHM24hSOUIPgh1TkA4ZhGZTosr_PVNPk_lOj" alt="Few-shot prototypes $C_k$ are computed as the mean of embedded support examples for each class. The encoder maps new image(N-Shot%20Learning/img2.png) and classifies it to the closest class like $C_2$ in the above image."></p><blockquote><p>Few-shot prototypes $C_k$ are computed as the mean of embedded support examples for each class. The encoder maps new image($X$) and classifies it to the closest class like $C_2$ in the above image. <a href="https://arxiv.org/pdf/1703.05175.pdf" target="_blank" rel="noopener">Source</a></p></blockquote><p>In the context of few-shot learning, a training iteration is known as an episode. An episode is nothing but a step in which we train the network once, calculate loss and backpropagate the error.  In each episode, we select $Nc$ classes at random from the training set. For each class, we randomly sample $Ns$ images. These images belong to the support set and the learning model is known as NsNs-shot model. Another randomly sampled Nq images are obtained which belongs to the query set. Here NcNc, NsNs &amp; NqNq are just hyperparameters in the model where NcNc is the number of classes per iteration, NsNs is the number of support examples per class and NqNq is the number of query examples per class.</p><p>After that, we retrieve D-dimensional points from the support set images by passing them through “Image2Vector” model. This model encodes an image with its corresponding point in the metric space. For each class we now have multiple points, but we need to represent them as one point for each class. Hence, we compute geometric center, i.e. mean of the points, for each class. After that, we also need to classify the query images.</p><p>To do that, we first need to encode every image in the query set into a point. After that, the distance from each centroid to each query point is calculated. At last, each query image is predicted to lie in the class which is nearest to it. That’s how the model works in general.</p><p>But the question now is, what is the architecture of this “Image2Vector” model?</p><h3 id="Image2Vector-function"><a href="#Image2Vector-function" class="headerlink" title="Image2Vector function"></a>Image2Vector function</h3><p><img src="/images/N-Shot%20Learning/2019090318384447.png" alt="imagessssss"></p><blockquote><p>Image2vector CNN architecture used in the paper.</p></blockquote><p>For all practical purposes, 4–5 CNN blocks are used. As shown in the above image, each block consists of a CNN layer followed by batch normalization, then by a ReLu activation function which leads into a max pool layer. After all the blocks, the remaining output is flattened and returned as a result. This is the architecture used in the <a href="https://arxiv.org/pdf/1703.05175v2.pdf" target="_blank" rel="noopener">paper</a> and you can use any architecture you like. It is necessary to know that though we call it “Image2Vector” model, it actually converts an image into a 64-dimensional point in the metric space. To understand the difference more, check out these <a href="https://math.stackexchange.com/questions/645672/what-is-the-difference-between-a-point-and-a-vector" target="_blank" rel="noopener">math stack exchange</a> answers.</p><h3 id="Loss-function"><a href="#Loss-function" class="headerlink" title="Loss function"></a>Loss function</h3><p><img src="N-Shot%20Learning/nll.jpg" alt="The working of negative log-likelihood. "></p><blockquote><p>The working of negative log-likelihood. <a href="https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/#nll" target="_blank" rel="noopener">Source</a>.</p></blockquote><p>Now that we know how the model is working, you might be wondering how we’re going to calculate loss function. We need a loss function which is robust enough for our model to learn representation quickly and efficiently. Prototypical Nets use log-softmax loss, which is nothing but log over softmax loss. The log-softmax has the effect of heavily penalizing the model when it fails to predict the correct class, which is what we need. To know more about the loss function go<a href="https://ljvmiranda921.github.io/notebook/2017/08/13/softmax-and-the-negative-log-likelihood/" target="_blank" rel="noopener"> here</a>. <a href="https://discuss.pytorch.org/t/logsoftmax-vs-softmax/21386" target="_blank" rel="noopener">Here</a> is a very good discussion about softmax and log-softmax.</p><h3 id="Dataset-overview"><a href="#Dataset-overview" class="headerlink" title="Dataset overview"></a>Dataset overview</h3><p><img src="N-Shot%20Learning/omniglot.jpg" alt="A few classes of images in Omniglot dataset"></p><blockquote><p> A few classes of images in Omniglot dataset. <a href="https://github.com/brendenlake/omniglot" target="_blank" rel="noopener">Source</a>.</p></blockquote><p>The network was trained on the <a href="https://github.com/brendenlake/omniglot" target="_blank" rel="noopener">Omniglot dataset</a>. The Omniglot data set is designed for developing more human-like learning algorithms. It contains 1,623 different handwritten characters from 50 different alphabets. Then, to increase the number of classes, all the images are rotated by 90, 180 and 270 degrees, with each rotation resulting in an additional class. Hence the total count of classes reached to 6,492(1,623 * 4) classes. We split images of 4,200 classes to training data while the rest went to the test set. For each episode, we trained the model on 5 examples from each of the 64 randomly selected classes. We trained our model for 1 hour and got about 88% accuracy. The official paper claimed to achieve the accuracy of 99.7% after training for a few hours and tuning a few parameters.</p><p><strong>Time to get your hands dirty!</strong></p><p>You can easily run <a href="https://github.com/Hsankesara/Prototypical-Networks" target="_blank" rel="noopener">the code</a> by clicking on the button below.</p><p>Let’s dive into the code!</p><pre class=" language-lang-python"><code class="language-lang-python">class Net(nn.Module):    """    Image2Vector CNN which takes the image of dimension (28x28x3) and return column vector length 64    """    def sub_block(self, in_channels, out_channels=64, kernel_size=3):        block = torch.nn.Sequential(            torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=1),            torch.nn.BatchNorm2d(out_channels),            torch.nn.ReLU()            torch.nn.MaxPool2d(kernel_size=2))        return block    def __init__(self):        super(Net, self).__init__()        self.convnet1 = self.sub_block(3)        self.convnet2 = self.sub_block(64)        self.convnet3 = self.sub_block(64)        self.convnet4 = self.sub_block(64)    def forward(self, x):        x = self.convnet1(x)        x = self.convnet2(x)        x = self.convnet3(x)        x = self.convnet4(x)        x = torch.flatten(x, start_dim=1)        return x</code></pre><p>The above snippet is an implementation of image2vector CNN architecture. It takes images of dimensions 28x28x3 and returns a vector of length 64.</p><pre class=" language-lang-python"><code class="language-lang-python">class PrototypicalNet(nn.Module):    def __init__(self, use_gpu=False):        super(PrototypicalNet, self).__init__()        self.f = Net()        self.gpu = use_gpu        if self.gpu:            self.f = self.f.cuda()    def forward(self, datax, datay, Ns,Nc, Nq, total_classes):        """        Implementation of one episode in Prototypical Net        datax: Training images        datay: Corresponding labels of datax        Nc: Number  of classes per episode        Ns: Number of support data per class        Nq:  Number of query data per class        total_classes: Total classes in training set        """        k = total_classes.shape[0]        K = np.random.choice(total_classes, Nc, replace=False)        Query_x = torch.Tensor()        if(self.gpu):            Query_x = Query_x.cuda()        Query_y = []        Query_y_count = []        centroid_per_class  = {}        class_label = {}        label_encoding = 0        for cls in K:            S_cls, Q_cls = self.random_sample_cls(datax, datay, Ns, Nq, cls)            centroid_per_class[cls] = self.get_centroid(S_cls, Nc)            class_label[cls] = label_encoding            label_encoding += 1            Query_x = torch.cat((Query_x, Q_cls), 0) # Joining all the query set together            Query_y += [cls]            Query_y_count += [Q_cls.shape[0]]        Query_y, Query_y_labels = self.get_query_y(Query_y, Query_y_count, class_label)        Query_x = self.get_query_x(Query_x, centroid_per_class, Query_y_labels)        return Query_x, Query_y    def random_sample_cls(self, datax, datay, Ns, Nq, cls):        """        Randomly samples Ns examples as support set and Nq as Query set        """        data = datax[(datay == cls).nonzero()]        perm = torch.randperm(data.shape[0])        idx = perm[:Ns]        S_cls = data[idx]        idx = perm[Ns : Ns+Nq]        Q_cls = data[idx]        if self.gpu:            S_cls = S_cls.cuda()            Q_cls = Q_cls.cuda()        return S_cls, Q_cls    def get_centroid(self, S_cls, Nc):        """        Returns a centroid vector of support set for a class        """        return torch.sum(self.f(S_cls), 0).unsqueeze(1).transpose(0,1) / Nc    def get_query_y(self, Qy, Qyc, class_label):        """        Returns labeled representation of classes of Query set and a list of labels.        """        labels = []        m = len(Qy)        for i in range(m):            labels += [Qy[i]] * Qyc[i]        labels = np.array(labels).reshape(len(labels), 1)        label_encoder = LabelEncoder()        Query_y = torch.Tensor(label_encoder.fit_transform(labels).astype(int)).long()        if self.gpu:            Query_y = Query_y.cuda()        Query_y_labels = np.unique(labels)        return Query_y, Query_y_labels    def get_centroid_matrix(self, centroid_per_class, Query_y_labels):        """        Returns the centroid matrix where each column is a centroid of a class.        """        centroid_matrix = torch.Tensor()        if(self.gpu):            centroid_matrix = centroid_matrix.cuda()        for label in Query_y_labels:            centroid_matrix = torch.cat((centroid_matrix, centroid_per_class[label]))        if self.gpu:            centroid_matrix = centroid_matrix.cuda()        return centroid_matrix    def get_query_x(self, Query_x, centroid_per_class, Query_y_labels):        """        Returns distance matrix from each Query image to each centroid.        """        centroid_matrix = self.get_centroid_matrix(centroid_per_class, Query_y_labels)        Query_x = self.f(Query_x)        m = Query_x.size(0)        n = centroid_matrix.size(0)        # The below expressions expand both the matrices such that they become compatible with each other in order to calculate L2 distance.        centroid_matrix = centroid_matrix.expand(m, centroid_matrix.size(0), centroid_matrix.size(1)) # Expanding centroid matrix to "m".        Query_matrix = Query_x.expand(n, Query_x.size(0), Query_x.size(1)).transpose(0,1) # Expanding Query matrix "n" times        Qx = torch.pairwise_distance(centroid_matrix.transpose(1,2), Query_matrix.transpose(1,2))        return Qx</code></pre><p>The above snippet is an implementation of a single episode in Prototypical Net. It is well commented, but if you have any doubts just ask in the comments or create an issue <a href="https://github.com/Hsankesara/DeepResearch/" target="_blank" rel="noopener">here</a>.</p><p><img src="/images/N-Shot%20Learning/pipeline.jpg" alt="Overview of the  Network"></p><blockquote><p>Overview of the Network. <a href="https://youtu.be/wcKL05DomBU" target="_blank" rel="noopener">Source</a>.</p></blockquote><p>The code is structured in the same format in which the algorithm is explained. We give the prototypical network function the following inputs: input image data, input labels, number of classes per iteration i.e NcNc , number of support examples per class i.e NsNs and number of query examples per class i.e. NqNq. The function returns QueryxQueryx, which is a distance matrix from each Query point to each mean point and QueryyQueryy which is a vector containing labels corresponding to QueryxQueryx. QueryyQueryy stores the class in which images of QueryxQueryx actually belong.  In the above image, we can see that 3 classes are used, i.e. NcNc =3, and that for each class, a total of 5 examples are used for training, i.e. NsNs=5. Above SS represents the support set that contains those 15 (Ns∗NcNs∗Nc ) images and XX represents the query set. Notice that both support set and query set passes through ff, which is nothing but our “Image2Vector” function. It mapped all the images in metric space. Let’s break the whole process down step by step.</p><p>First of all, we choose NcNc classes randomly from the input data. For each class, we randomly select a support set and a query set from the images using the <code>random_sample_cls</code> function. In the above image, SS is the support set and XX is the query set. Now that we chose the classes (C1C1, C2C2, and C3C3), we pass all the support set examples through the “Image2vector” model and compute the centroid for each class using the <code>get_centroid</code> function.  The same can be observed in the nearby image where C1C1 and C2C2 are the center, computed using the neighboring points. Each centroid represents a class and will be used for classifying queries.</p><p><img src="N-Shot%20Learning/helper.png" alt="Centroid calculation in the Network"></p><blockquote><p>Centroid calculation in the Network. <a href="https://youtu.be/wcKL05DomBU" target="_blank" rel="noopener">Source</a>.</p></blockquote><p>After computing centroid for each class, we now have to predict the query image to one of the classes. For that, we need actual labels corresponding to each query, which we get by using the <code>get_query_y</code> function. The QueryyQueryy is categorical data and the function converts this categorical text data into a one-hot vector, which will only be “1” in the row label where the image corresponding to the column point actually belongs, and will be “0” else in the column.</p><p>After that, we need points corresponding to each QueryxQueryx image in order to classify it. We get the points using “Image2Vector” model and now we need to classify them. For that purpose, we calculate the distance between each point in QueryxQueryx to each class center. This gives us a matrix where index ijij represents the distance of the point corresponding to ith query image from the center of jth class. We used the <code>get_query_x</code> function to construct the matrix and save the matrix in the QueryxQueryx variable. The same can be seen in the nearby image. For each example in the query set, The distance it has from C1C1, C2C2 and C3C3 is being calculated. In this case, xx is closest to C2C2 and we can therefore say that xx is predicted to belong to class C2C2.</p><p>Programmatically, we can use a simple argmin function to do the same, i.e. to find out the class where the image was predicted to lie. Then we use the predicted class and actual class to calculate loss and backpropagate the error.</p><p>If you want to use the trained model or just have to retrain again for yourself, <a href="https://github.com/Hsankesara/DeepResearch/tree/master/Prototypical_Nets" target="_blank" rel="noopener">here</a> is my implementation. You can use it as an API and train the model using a couple of lines of code. You can find this network in action <a href="https://www.kaggle.com/hsankesara/prototypical-net/" target="_blank" rel="noopener">here</a>.</p><h3 id="Resources"><a href="#Resources" class="headerlink" title="Resources"></a>Resources</h3><p>Here are a few resources that might help you learn this topic thoroughly:</p><ul><li><a href="https://sorenbouma.github.io/blog/oneshot/" target="_blank" rel="noopener">One Shot Learning with Siamese Networks using Keras</a></li><li><a href="https://towardsdatascience.com/one-shot-learning-face-recognition-using-siamese-neural-network-a13dcf739e" target="_blank" rel="noopener">One-Shot Learning: Face Recognition using Siamese Neural Network</a></li><li><a href="https://github.com/AntreasAntoniou/MatchingNetworks" target="_blank" rel="noopener">Matching network official implementation</a></li><li><a href="https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch" target="_blank" rel="noopener">Prototypical Network official implementation.</a></li><li><a href="https://arxiv.org/abs/1803.00676" target="_blank" rel="noopener">Meta-Learning for Semi-Supervised Few-Shot Classification</a></li></ul><h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>Though prototypical networks produce great results, they still have limitations. The first one is the lack of generalization. It works on the Omniglot dataset well because all the images in there are images of a character, and hence share a few similar characteristics. However, if we were to try using the model to classify different breeds of cats, it wouldn’t give us accurate results. Cats and character images share few characteristics, and the number of common features which can be exploited to map the image on the corresponding metric space is negligible.</p><p>Another limitation to prototypical networks is that they only use mean to decide center, and ignore the variance in support set. This hinders the classifying ability of the model when the images have noise. This limitation is overcome by using <a href="https://arxiv.org/abs/1708.02735" target="_blank" rel="noopener">Gaussian Prototypical Networks</a> which utilizes the variance in the class by modeling the embedded points using Gaussian formulations.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Few-Shot learning has been a topic of active research for a while. There are many novel approaches which use prototypical networks, like this <a href="https://arxiv.org/abs/1803.00676" target="_blank" rel="noopener">meta-learning</a> one, and which show great results. Researchers are also exploring it with reinforcement-learning, which also has great potential. The best thing about this model is that it is simple and easy to understand, and it gives incredible results.</p>]]></content>
      
      
      <categories>
          
          <category> 机器学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre class=" language-lang-bash"><code class="language-lang-bash">$ hexo new "My New Post"</code></pre><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre class=" language-lang-bash"><code class="language-lang-bash">$ hexo server</code></pre><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre class=" language-lang-bash"><code class="language-lang-bash">$ hexo generate</code></pre><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre class=" language-lang-bash"><code class="language-lang-bash">$ hexo deploy</code></pre><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>互怼的艺术：从零直达 WGAN-GP</title>
      <link href="/001-hu-dui-de-yi-zhu-cong-ling-zhi-da-wgan-gp/"/>
      <url>/001-hu-dui-de-yi-zhu-cong-ling-zhi-da-wgan-gp/</url>
      
        <content type="html"><![CDATA[<p>参考资料：PaperWeekly 第41期 | 互怼的艺术：从零直达 WGAN-GP</p><hr><p> <strong>1</strong> <strong>前言</strong></p><p>GAN，全称 Generative Adversarial Nets，中文名是生成对抗式网络。对于 GAN 来说，最通俗的解释就是“造假者-鉴别者”的解释，如艺术画的伪造者和鉴别者。一开始伪造者和鉴别者的水平都不高，但是鉴别者还是比较容易鉴别出伪造者伪造出来的艺术画。但随着伪造者对伪造技术的学习后，其伪造的艺术画会让鉴别者识别错误；或者随着鉴别者对鉴别技术的学习后，能够很简单的鉴别出伪造者伪造的艺术画。这是一个双方不断学习技术，以达到最高的伪造和鉴别水平的过程。 然而，稍微深入了解的读者就会发现，<strong>跟现实中的造假者不同，造假者会与时俱进地使用新材料新技术来造假，而 GAN 最神奇而又让人困惑的地方是它能够将随机噪声映射为我们所希望的正样本，有噪声就有正样本，这不是无本生意吗，多划算。</strong></p><p>另一个情况是，自从 WGAN 提出以来，基本上 GAN 的主流研究都已经变成了 WGAN 上去了，但 WGAN 的形式事实上已经跟“伪造者-鉴别者”差得比较远了。而且 WGAN 虽然最后的形式并不复杂，但是推导过程却用到了诸多复杂的数学，使得我无心研读原始论文。这迫使我要找从一条简明直观的线索来理解 GAN。幸好，经过一段时间的思考，有点收获。 </p><p>在正文之前，先声明：<strong>笔者所有的 GAN 的知识，仅仅从网上的科普文所读而来，我并没有直接读过任何关于 GAN 的论文，因此，文中的结果可能跟主流的结果有雷同，也可能有很大出入，而且本文的讲述方法并不符合 GAN 的历史发展进程。严谨治学者慎入。</strong></p><p>注：如无指明，本文所谈到的 GAN 都是广义的，即包括原始 GAN、WGAN 等等，对它们不作区分。文中出现的正样本、真实样本，都是指预先指定的一批样本，而生成样本则指的是随机噪声通过生成模型 G 变换所得的结果。</p><p> <strong>2</strong> <strong>一道面试题</strong></p><p>一道经典的面试题是：<strong>如果有一个伪随机数程序能够生成 [0,1] 之间的均匀随机数，那么如何由它来生成服从正态分布的伪随机数？比如怎么将 U[0,1] 映射成 N(0,1)？</strong></p><p>这道题不同的角度有不同的做法，工程上的做法有：同时运行 n 个这样的伪随机数程序，每步产生 n 个随机数，那么这 n 个数的和就近似服从正态分布了。不过，这里不关心工程做法，而关心理论上的做法。理论上的做法是：将 X∼U[0,1] 经过函数 Y=f(X) 映射之后，就有 $Y∼N(0,1)$ 了。设 $ρ(x)$ 是 $U[0,1] $是概率密度函数，那么 $[x,x+dx] $和 $[y,y+dy] $这两个区间的概率应该相等，而根据概率密度定义，$ρ(x)$ 不是概率，$ρ(x)dx$ 才是概率，因此有</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640.webp" alt="640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=" style="zoom:67%;" /></p><p>那么：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613337068.webp" alt="img" style="zoom:67%;" /></p><p>这里 Φ(y) 是标准正态分布的累积分布函数，所以：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613349673.webp" alt="img" style="zoom:67%;" /></p><p>注意到累积分布函数是无法用初等函数显式表示出来的，更不用说它的逆函数了。说白了，Y=f(X) 的 f 的确是存在的，但很复杂。正态分布是常见的、相对简单的分布，但这个映射已经这么复杂了。如果换了任意分布，甚至概率密度函数都不能显式写出来，那么复杂度可想而知。</p><p><strong>3. 神经大法好</strong></p><p>现在我们将问题一般化：<strong>如何找到映射 Y=f(X)，把服从均匀分布 X 映射到指定的分布？在一般情形下，这个指定的分布是通过给出一批具体的分布样本 Z=(z1,z2,…,zN) 来描述的（比如，给出一批服从正态分布的随机数，而不是给出概率密度</strong></p><p>这个问题相当一般化，跟 GAN 所做的事情也是一样的。也就是说，GAN 也是希望把均匀的随机噪声映射成特定分布，这个特定分布由一组“正样本”描述。这样的理解就可以回答我们开头的一个小问题了：<strong>为什么 GAN 可以将噪声变换成正样本？事实上 GAN 并不是学习噪声到正样本的变换，而是学习均匀分布到指定分布的变换。</strong>假如学习成功了，那么输入一个随机噪声，那么就变换成指定分布的数据，而通常来说<strong>我们指定的分布是一个比较“窄”的分布</strong>（比如指定的正样本是某一类图片的集合，但事实上图片无穷无尽，某一类的图片是相当窄的），所以都会映射到我们眼中的“正样本”去。</p><p>前面正态分布的例子已经表明，这个映射 f 通常都是很复杂的，因此没必要求它的解析解。这时候“神经大法”就登场了：<strong>熟悉神经网络的读者都知道，我们总可以用一个神经网络来拟合任意函数，因此，不妨用一个带有多个参数的神经网络 G(X,θ) 去拟合它？只要把参数 θ 训练好，就可以认为 Y=G(X,θ) 了。</strong></p><p>可是，问题又来了：拟合什么目标呢？我们怎么知道 Y=G(X,θ) 跟指定的分布是很接近的呢？</p><p> <strong>4</strong> <strong>KL 距离？JS 距离？</strong></p><p>让我们把问题再理清楚一下：<strong>我们现在有一批服从某个指定分布的数据 Z=(z1,z2,…,zN)，我们希望找到一个神经网络 Y=G(X,θ)，将均匀随机数 X 映射到这个指定分布中来。</strong></p><p>需要特别指出，我们是要<strong>比较两个分布的接近程度，而不是比较样本之间的差距。</strong>通常来说，我们会用 KL 距离来描述两个分布的差异：设 p1(x),p2(x) 是两个分布的概率密度（当然，还有其他距离可以选择，比如 Wasserstein 距离，但这不改变下面要讨论的内容的实质），那么：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613394054.webp" alt="img" style="zoom:67%;" /></p><p>如果是离散概率，则将积分换成求和即可。KL 距离并非真正的度量距离，但是它能够描述两个分布之间的差异，当它是 0 时，表明两个分布一致。但因为它不是对称的。有时候将它对称化，得到 JS 距离：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613402498.webp" alt="img" style="zoom:67%;" /></p><p>咦？怎么又回到概率密度了？不是说没给出概率密度吗？没办法，公式就是这样，只好估算一下咯。假设我们可以将实数域分若干个不相交的区间 I1,I2,…,IK，那么就可以估算一下给定分布 Z 的概率分布。</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654039.webp" alt="img" style="zoom: 50%;" /></p><p>其中 #(zj∈Ii) 表示如果 zj∈Ii，那么取值为 1，否则为 0，也就是说大家不要被公式唬住了，上式就是一个简单的计数函数，用频率估计概率罢了。</p><p>接着我们生成 M 个均匀随机数 x1,x2,…,xM（这里不一定要 M=N，还是那句话，我们比较的是分布，不是样本本身，因此多一个少一个样本，对分布的估算也差不了多少。），根据 Y=G(X,θ) 计算对应的 y1,y2,…,yM，然后根据公式可以计算：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654040.webp" alt="img" style="zoom: 50%;" /></p><p>现在有了 pz(Ii) 和 py(Ii)，那么我们就可以算它们的差距了，比如可以选择 JS 距离：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654040-1577180533050.webp" alt="img" style="zoom: 50%;" /></p><p>注意 yi 是由 G(X,θ) 生成的，所以 py(Ii) 是带有参数 θ 的，因此可以通过最小化 Loss 来得到参数 θ 的最优值，从而决定网络 Y=G(X,θ)。</p><p> <strong>5</strong> <strong>神经距离</strong></p><p>假如我们只研究单变量概率分布之间的变换，那上述过程完全够了。然而，很多真正有意义的事情都是多元的，比如在 MNIST 上做实验，想要将随机噪声变换成手写数字图像。要注意 MNIST 的图像是 28*28=784 像素的，假如每个像素都是随机的，那么这就是一个 784 元的概率分布。按照我们前面分区间来计算 KL 距离或者 JS 距离，哪怕每个像素只分两个区间，那么就有 2784≈10236 个区间，这是何其巨大的计算量！</p><p>终于，有人怒了：<strong>“老子干嘛要用你那逗比的 JS 距离，老子自己用神经网络造一个距离！”</strong>于是他写出带参数 Θ 的神经网络：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654040-1577180535246.webp" alt="img" style="zoom: 50%;" /></p><p>也就是说，直接将造出来的 yi 和真实的 zi 都放进去这个神经网络一算，自动出来距离，多方便。<strong>这个思想是里程碑式的，它连距离的定义都直接用神经网络学了，还有什么不可能学的呢？</strong></p><p>我们来看看，要是真有这么个 L 存在，它应该是怎么样的？首先，对于特定的任务来说，<img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654359.webp" alt="img" style="zoom:50%;" />是给定的，因此它并非变量，我们可以把它当做模型本身的一部分，因此简写成：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654408.webp" alt="img" style="zoom: 50%;" /></p><p>接着，别忘记我们是<strong>描述分布之间的距离而不是样本的距离</strong>，而分布本身跟各个 yi 出现的顺序是没有关系的，因此分布之间的距离跟各个 yi 出现的顺序是无关的，也就是说，尽管 L 是各个 yi 的函数，但它必须全对称的！这是个很强的约束，当然，尽管如此，我们的选择也有很多，比如：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654451.webp" alt="img"></p><p>也就是说，我们先找一个有序的函数 D，然后对所有可能的序求平均，那么就得到无序的函数了。当然，这样的计算量是 𝒪(M!)，显然也不靠谱，那么我们就选择最简单的一种：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654493.webp" alt="img" style="zoom:50%;" /></p><p>这便是<strong>无序的最简单实现</strong>，可以简单的理解为：分布之间的距离，等于单个样本的距离的平均。</p><p> <strong>6</strong>  <strong>对抗来了</strong></p><p>“等等，你的标题是 GAN，你讲了那么一大通，我怎么没感觉到半点 GAN 的味道呀？对抗在哪里？” 这位看官您别急，马上就有了。</p><p>前面说到，用神经网络来学习一个距离 L，最终简化版的形式，应该是这样的：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654503.webp" alt="img" style="zoom:50%;" /></p><p>问题是：D(Y,Θ) 怎么训练？别忘了，之前的 G(X,θ) 还没有训练好，现在又弄个 D(Y,Θ) 出来，越搞越复杂，小心跳到坑里出不来了。</p><p>对抗终于来了…</p><p><strong>因为 D(Y,Θ) 的均值，也就是 L，是度量两个分布的差异程度，这就意味着，L 要能够将两个分布区分开来，即 L 越大越好；但是我们最终的目的，是希望通过均匀分布而生成我们指定的分布，所以 G(X,θ) 则希望两个分布越来越接近，即 L 越小越好。这时候，一个天才的想法出现了：互怼！不要怂，gan！</strong></p><p>首先我们随机初始化 $G(X,θ)$，固定它，然后生成一批 Y，这时候我们要训练 $D(Y,Θ)$，既然 L 代表的是“与指定样本 Z 的差异”，那么，如果将指定样本 Z 代入 L，结果应该是越小越好，而将 Y 代入 L，结果应该是越大越好，所以：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654537.webp" alt="img" style="zoom:50%;" /></p><p>然而有两个目标并不容易平衡，所以干脆都取同样的样本数 B（一个 batch），然后一起训练就好：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654540.webp" alt="img" style="zoom:50%;" /></p><p>很自然，G(X,θ) 希望它生成的样本越接近真实样本越好，因此这时候把 Θ 固定，只训练 θ 让 L 越来越小：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654579.webp" alt="img" style="zoom:50%;" /></p><p><strong>这就是天才的对抗网络！</strong></p><p>需要指出的是：</p><ol><li>这里的 Loss 写法跟传统的 GAN 相反，习惯性的做法是让真实样本的LL越大越好，但这只不过跟本文差了个负号而已，不是本质的问题；</li></ol><ol><li>从 GAN 开始，D 这个神经网络就被赋予了“判别器”的意义，但在这里 D 本身是没有意义的（正如我们不能说某个数是不是正态分布的），只有 D 的平均值 L 才代表着与真实分布的差距（我们只能根据一批数据来估计它是否服从正态分布），所以从这里也可以看到，GAN 不能单个样本地训练，至少成批训练，因为有一批样本才能看出统计特征；</li></ol><ol><li>咋看上去 D 只是个二分类问题，而 G 则要把噪声映射为正样本，貌似 D 应该比 G 要简单得多？事实并非如此，它们两者的复杂度至少是相当的。我们可以直观考虑一下它们的工作原理：因为 D 的均值 L 直接就给出了输入的数据与指定分布的差异，而要真的做到这一点，那么 D 要把所有的“正样本”（在某种程度上）都“记住”了才行；而 G 要生成良好的正样本，基本上也是“记住”了所有的正样本，并通过随机数来插值输出。因此两个网络的复杂度应该是相当的（当然这里的“记住”是形象理解，不是真的强行记住了，不然就是过拟合了）；</li></ol><ol><li>既然 L1 是真伪样本的分布差，那么 L1 越大，意味着“伪造”的样本质量越好，所以 L1 同时也指示着 GAN 训练的进程，L1 越大，训练得越好。（D 希望 L1 越小越好，G 希望 L1 越大越好，当然是 G 希望的结果，才是我们希望的。其实也可以这样理解，G 的损失 L2，其实就相当于 −L1，但是因为 D 的权重已经固定了，所以有关真实样本那一项是个常数，因此只剩下伪造样本那一项，即 L2，但 L2 是个绝对值，我们关心的是相对值，所以 −L1 是我们关心的，它越小越好，相当于 L1 越大越好。）</li></ol><p> <strong>7</strong> <strong>别走，还没完</strong></p><p>稍微思考一下，我们就发现，问题还没完。我们目前还没有对 D 做约束，不难发现，无约束的话 Loss 基本上会直接跑到负无穷去了。</p><p>因此，有必要给 D 加点条件，一个比较容易想到的方案是约束 D 的范围，比如能不能给 D 最后的输出加个 Sigmoid 激活函数，让它取值在 0 到 1 之间？事实上这个方案在理论上是没有问题的，然而这会造成训练的困难。因为 Sigmoid 函数具有饱和区，一旦 D 进入了饱和区，就很难传回梯度来更新 G 了。</p><p>最好加什么约束呢？我们应该尽可能从基本原理出发来找寻约束，尽量避免加入人工因素。我们回到距离的作用上来看：距离是为了表明两个对象的差距，而如果对象产生的微小的变化，那么距离的波动也不能太大，这应该是对距离基本的稳定性要求，“失之毫厘，谬以千里”是会产生浑沌的，数学模型不应该是这样。从这个角度来看，那个所谓的“JS 距离”，根据就不是距离了，因为就算对于伯努利分布 {0:0.1,1:0.9} 和 {0:0,1:1}，这两个相似的分布算出来的“距离”居然是无穷大（因为出现了 0.1/0 这一项）。</p><p>放到我们的 D 中，这个约束我们该怎么体现呢？假如某个样本不是 yi 而是 y′i，假设 ‖yi−y′i‖（用两竖表示欧式距离，因为 y 可能是个多元向量）并不是十分大，那么会对分布造成一定的影响。这个影响有多大呢？显然不会大，因为分布是一批样本的统计特征，如果只是稍微改变了一个样本，那么分布的变化显然不能大的。而我们知道，分布的距离用 D 的均值 L 来描述，只改变一个 yi，所造成的分布差正比于：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654621.webp" alt="img" style="zoom:50%;" /></p><p>我们希望 yi′→yi 时，自然地就有<img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654745.webp" alt="img" style="zoom:67%;" />，怎么实现这一点呢？一个简单的方案是 D 满足以下约束：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654647.webp" alt="img" style="zoom:50%;" /></p><p>这里 $α&gt;0$，而最简单的方案就是：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654662.webp" alt="img" style="zoom:50%;" /></p><p>这就是数学中常见的 <strong>Lipschitz 约束</strong>。如果能够满足这个约束，那么距离就能满足稳定性要求。注意这是个充分条件，不是必要条件，也可以使用其他方案。但不得不说，这是个简单明了的方案。而使得函数 D 满足 Lipschitz 约束的一个充分条件就是：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654697.webp" alt="img" style="zoom:50%;" /></p><p> <strong>8</strong> <strong>“罚”出来的成果</strong></p><p>怎么把这个约束加入到模型中去呢？加入个惩罚项就好：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654741.webp" alt="img" style="zoom: 67%;" /></p><p>当然惩罚是“软约束”，最终的结果不一定满足这个约束，但却会在约束上下波动。也就是说虽然我们指定了 C=1，但最终的 C 却不一定等于 1，不过会在 1 上下波动，而这也不过是一个更宽松的 Lipschitz 约束而已，我们不在乎 C 的具体大小，只要 C 有上界就好。另外，约束的加法不是唯一的，WGAN 的作者 Martin Arjovsky 在他的论文中提出的加法为：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654782.webp" alt="img" style="zoom:67%;" /></p><p>哪个好？实验结果好像都差不多。</p><p>不过，上面的惩罚项都是形式而已，我们还没给出具体的计算方法。理论上最好能够对所有的 y（全空间）都算一遍 <img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654793.webp" alt="img" style="zoom:67%;" /> 然后取平均，显然这是做不到的。那么只好用一个退而求其次的方案：只对真实样本 zi 和生成样本 yi 算。但这样约束范围貌似也太小了，所以干脆在真实样本和生成样本之间随机插值，希望这个约束可以“布满”真实样本和生成样本之间的空间，即：</p><p><img src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" alt="img"></p><p>以及：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654814.webp" alt="img" style="zoom:67%;" /></p><p>这里的 εi 是 U[0,1] 的随机数，这应该已经是我们“力所能及”的最优的方案了。后面这个就是 Martin Arjovsky 提出的最新的 Lipschitz 约束的方案，而实验结果表明前一个方案效果也不错。目前它们的大名叫“WGAN-GP”，全称 Wasserstein Generative Adversarial Nets - Gradient Penalty。</p><p>最后，有人会反驳，梯度有上界，只不过是 Lipschitz 约束的充分条件，<strong>为啥不直接将 Lipschitz 约束以差分形式加入到惩罚中去呢？</strong>（其实有这个疑问的最主要的原因，是很多深度学习框架并没有提供梯度函数；另外，尽管 tensorflow 提供了梯度函数，但如果判别器用的是 RNN，那么梯度函数也是不可用的。）事实上，这样做某种意义上更加合理，我觉得 Martin Arjovsky 直接用梯度，不过是想写得简单一点，这时候惩罚是：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654845.webp" alt="img" style="zoom: 80%;" /></p><p>以及：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654847.webp" alt="img"></p><p>这里 yi,j=εi,jyi+(1−εi,j)zi，也就是每步插值两次，然后用插值的结果算差分。</p><p> <strong>9</strong> <strong>然后呢？</strong></p><p>暂时没有然后了，终于写完了。这便是我理解的 GAN。 </p><p>通过本文，我们可以一气呵成地直达 WGAN-GP，而不需要很多的历史知识和数学知识。有趣的是，<strong>我们的推导过程表明，WGAN-GP 其实跟 Wasserstein 距离没有直接的联系</strong>，尽管当初 WGAN 的作者是从 Wasserstein 距离将它们推导出来的。也就是说，WGAN 跟 W 没啥关系，这就尴尬了。另外，有人提问“WGAN 相比原始的 GAN 有什么优势？”，如果根据本文的理论推导，那么原始的 GAN 根本就不是 GAN，因为它不能改写为本文的某个特例。（原因在于，本文的推导基于分布的拟合，而原始 GAN 的推导基于博弈论，出发点不同。） </p><p>这个 Loss 还有一定的改进空间，比如 Loss Sensitive GAN（LS-GAN），还有更广义的 CLS-GAN（将 LS-GAN 和 WGAN 统一起来了），这些推广我们就不讨论了。不过这些推广都建立在 Lipschitz 约束之上，只不过微调了 Loss，也许未来会有人发现比 Lipschitz 约束更好的对 D 的约束。</p><p> <strong>10</strong>  <strong>WGAN-GP 的例子</strong></p><p>最后，分享一个 WGAN-GP 的实现，以 MNIST为 数据集，读者可以自己改着玩：</p><p><em><a href="https://github.com/bojone/gan/" target="_blank" rel="noopener">https://github.com/bojone/gan/</a></em></p><p>训练进度显示：</p><p><img src="/images/001-%E4%BA%92%E6%80%BC%E7%9A%84%E8%89%BA%E6%9C%AF-%E4%BB%8E%E9%9B%B6%E7%9B%B4%E8%BE%BE%20WGAN-GP/640-1572613654894.webp" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>LSTM</title>
      <link href="/001-li-jie-lstm/"/>
      <url>/001-li-jie-lstm/</url>
      
        <content type="html"><![CDATA[<p>参考资料：<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</a></p><hr><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><p>Humans don’t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don’t throw everything away and start thinking from scratch again. Your thoughts have persistence.</p><p>Traditional neural networks can’t do this, and it seems like a major shortcoming. For example, imagine you want to classify what kind of event is happening at every point in a movie. It’s unclear how a traditional neural network could use its reasoning about previous events in the film to inform later ones.</p><p>Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/RNN-rolled.png" alt="img" style="zoom:36%;" /></p><p>​                                <strong>Recurrent Neural Networks have loops.</strong></p><p>In the above diagram, a chunk of neural network, AA, looks at some input xtxt and outputs a value htht. A loop allows information to be passed from one step of the network to the next.</p><p>These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren’t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. Consider what happens if we unroll the loop:</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/RNN-unrolled.png" alt="An unrolled recurrent neural network."></p><p>​                        <strong>An unrolled recurrent neural network.</strong></p><p>This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They’re the natural architecture of neural network to use for such data.</p><p>And they certainly are used! In the last few years, there have been incredible success applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning… The list goes on. I’ll leave discussion of the amazing feats one can achieve with RNNs to Andrej Karpathy’s excellent blog post, <a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a>. But they really are pretty amazing.</p><p>Essential to these successes is the use of “LSTMs,” a very special kind of recurrent neural network which works, for many tasks, much much better than the standard version. Almost all exciting results based on recurrent neural networks are achieved with them. It’s these LSTMs that this essay will explore.</p><h2 id="RNN的长程依赖问题"><a href="#RNN的长程依赖问题" class="headerlink" title="RNN的长程依赖问题"></a>RNN的长程依赖问题</h2><p>One of the appeals of RNNs is the idea that they might be able to connect previous information to the present task, such as using previous video frames might inform the understanding of the present frame. If RNNs could do this, they’d be extremely useful. But can they? It depends.</p><p>Sometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in “the clouds are in the <em>sky</em>,” we don’t need any further context – it’s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it’s needed is small, RNNs can learn to use the past information.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/RNN-shorttermdepdencies.png" alt="img" style="zoom:36%;" /></p><p>But there are also cases where we need more context. Consider trying to predict the last word in the text “I grew up in France… I speak fluent <em>French</em>.” Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It’s entirely possible for the gap between the relevant information and the point where it is needed to become very large.</p><p>Unfortunately, as that gap grows, RNNs become unable to learn to connect the information.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/RNN-longtermdependencies.png" alt="Neural networks struggle with long term dependencies." style="zoom:36%;" /></p><p>In theory, RNNs are absolutely capable of handling such “long-term dependencies.” A human could carefully pick parameters for them to solve toy problems of this form. Sadly, in practice, RNNs don’t seem to be able to learn them. The problem was explored in depth by <a href="http://people.idsia.ch/~juergen/SeppHochreiter1991ThesisAdvisorSchmidhuber.pdf" target="_blank" rel="noopener">Hochreiter (1991) [German]</a> and <a href="http://www-dsi.ing.unifi.it/~paolo/ps/tnn-94-gradient.pdf" target="_blank" rel="noopener">Bengio, et al. (1994)</a>, who found some pretty fundamental reasons why it might be difficult.</p><p>Thankfully, LSTMs don’t have this problem!</p><h2 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h2><p>Long Short Term Memory networks – usually just called “LSTMs” – are a special kind of RNN, capable of learning long-term dependencies. They were introduced by <a href="http://www.bioinf.jku.at/publications/older/2604.pdf" target="_blank" rel="noopener">Hochreiter &amp; Schmidhuber (1997)</a>, and were refined and popularized by many people in following work.<a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/#fn1" target="_blank" rel="noopener">1</a> They work tremendously well on a large variety of problems, and are now widely used.</p><p>LSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!</p><p>All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-SimpleRNN.png" alt="img" style="zoom:36%;" /></p><p>​    <strong>The repeating module in a standard RNN contains a single layer.</strong></p><p>LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-chain.png" alt="A LSTM neural network." style="zoom:36%;" /></p><p> <strong>The repeating module in an LSTM contains four interacting layers.</strong></p><p>Don’t worry about the details of what’s going on. We’ll walk through the LSTM diagram step by step later. For now, let’s just try to get comfortable with the notation we’ll be using.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM2-notation.png" alt="img"></p><p>In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers. Lines merging denote concatenation, while a line forking denote its content being copied and the copies going to different locations.</p><h2 id="LSTM背后的核心思想"><a href="#LSTM背后的核心思想" class="headerlink" title="LSTM背后的核心思想"></a>LSTM背后的核心思想</h2><p>The key to LSTMs is the <strong>cell state</strong>, the horizontal line running through the top of the diagram.</p><p>The cell state is kind of like a conveyor belt(传输带). It runs straight down the entire chain, with only some minor linear interactions. It’s very easy for information to just flow along it unchanged.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-C-line.png" alt="img" style="zoom:36%;" /></p><p>The LSTM does have the ability to remove or add information to the cell state, carefully regulated(控制，管理) by structures called <strong>gates</strong>.</p><p>Gates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-gate.png" alt="img" style="zoom:50%;" /></p><p>The sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means “let nothing through,” while a value of one means “let everything through!”</p><p>An LSTM has three of these gates, to protect and control the <strong>cell state</strong>.</p><h2 id="逐步理解LSTM"><a href="#逐步理解LSTM" class="headerlink" title="逐步理解LSTM"></a>逐步理解LSTM</h2><p>The first step in our LSTM is to decide what information we’re going to throw away from the cell state. This decision is made by a sigmoid layer called the “forget gate layer.” It looks at $h_{t−1}$ and $x_t$, and outputs a number between $0$ and $1$ for each number in the cell state $C_{t−1}$. A $1$ represents “completely keep this” while a $0$ represents “completely get rid of this.”</p><p>Let’s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-focus-f.png" alt="img"></p><p>The next step is to decide what new information we’re going to store in the cell state. This has two parts. First, a <code>sigmoid</code> layer called the “input gate layer” decides which values we’ll update. Next, a <code>tanh</code> layer creates a vector of new candidate values, $\tilde{C}_t$, that could be added to the state. In the next step, we’ll combine these two to create an update to the state.</p><p>In the example of our language model, we’d want to add the gender of the new subject to the cell state, to replace the old one we’re forgetting.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-focus-i.png" alt="img"></p><p>It’s now time to update the old cell state, $C_{t−1}$, into the new cell state $C_t$. The previous steps already decided what to do, we just need to actually do it.</p><p>We multiply the old state by $f_t$, forgetting the things we decided to forget earlier. Then we add $i_t*\tilde{C}_t$. This is the new candidate values, scaled by how much we decided to update each state value.</p><p>In the case of the language model, this is where we’d actually drop the information about the old subject’s gender and add the new information, as we decided in the previous steps.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-focus-C.png" alt="img"></p><p>Finally, we need to decide what we’re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we’re going to output. Then, we put the cell state through <code>tanh</code> (to push the values to be between $−1$ and $1$) and multiply it by the output of the <code>sigmoid</code> gate, so that we only output the parts we decided to.</p><p>For the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that’s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that’s what follows next.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-focus-o.png" alt="img"></p><h2 id="LSTM的变异体"><a href="#LSTM的变异体" class="headerlink" title="LSTM的变异体"></a>LSTM的变异体</h2><p>What I’ve described so far is a pretty normal LSTM. But not all LSTMs are the same as the above. In fact, it seems like almost every paper involving LSTMs uses a slightly different version. The differences are minor, but it’s worth mentioning some of them.</p><p>One popular LSTM variant, introduced by <a href="ftp://ftp.idsia.ch/pub/juergen/TimeCount-IJCNN2000.pdf" target="_blank" rel="noopener">Gers &amp; Schmidhuber (2000)</a>, is adding “peephole connections.” This means that we let the gate layers look at the cell state.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-var-peepholes.png" alt="img"></p><p>The above diagram adds peepholes to all the gates, but many papers will give some peepholes and not others.</p><p>Another variation is to use coupled forget and input gates. Instead of separately deciding what to forget and what we should add new information to, we make those decisions together. We only forget when we’re going to input something in its place. We only input new values to the state when we forget something older.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-var-tied.png" alt="img" style="zoom:36%;" /></p><p>A slightly more dramatic variation on the LSTM is the Gated Recurrent Unit, or GRU, introduced by <a href="http://arxiv.org/pdf/1406.1078v3.pdf" target="_blank" rel="noopener">Cho, et al. (2014)</a>. It combines the forget and input gates into a single “update gate.” It also merges the cell state and hidden state, and makes some other changes. The resulting model is simpler than standard LSTM models, and has been growing increasingly popular.</p><p><img src="/images/001-%E7%90%86%E8%A7%A3LSTM/LSTM3-var-GRU.png" alt="A gated recurrent unit neural network." style="zoom:36%;" /></p><p>These are only a few of the most notable LSTM variants. There are lots of others, like Depth Gated RNNs by <a href="http://arxiv.org/pdf/1508.03790v2.pdf" target="_blank" rel="noopener">Yao, et al. (2015)</a>. There’s also some completely different approach to tackling long-term dependencies, like Clockwork RNNs by <a href="http://arxiv.org/pdf/1402.3511v1.pdf" target="_blank" rel="noopener">Koutnik, et al. (2014)</a>.</p><p>Which of these variants is best? Do the differences matter? <a href="http://arxiv.org/pdf/1503.04069.pdf" target="_blank" rel="noopener">Greff, et al. (2015)</a> do a nice comparison of popular variants, finding that they’re all about the same. <a href="http://jmlr.org/proceedings/papers/v37/jozefowicz15.pdf" target="_blank" rel="noopener">Jozefowicz, et al. (2015)</a> tested more than ten thousand RNN architectures, finding some that worked better than LSTMs on certain tasks.</p><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>Earlier, I mentioned the remarkable results people are achieving with RNNs. Essentially all of these are achieved using LSTMs. They really work a lot better for most tasks!</p><p>Written down as a set of equations, LSTMs look pretty intimidating. Hopefully, walking through them step by step in this essay has made them a bit more approachable.</p><p>LSTMs were a big step in what we can accomplish with RNNs. It’s natural to wonder: is there another big step? A common opinion among researchers is: “Yes! There is a next step and it’s attention!” The idea is to let every step of an RNN pick information to look at from some larger collection of information. For example, if you are using an RNN to create a caption describing an image, it might pick a part of the image to look at for every word it outputs. In fact, <a href="http://arxiv.org/pdf/1502.03044v2.pdf" target="_blank" rel="noopener">Xu, <em>et al.</em> (2015)</a> do exactly this – it might be a fun starting point if you want to explore attention! There’s been a number of really exciting results using attention, and it seems like a lot more are around the corner…</p><p>Attention isn’t the only exciting thread in RNN research. For example, Grid LSTMs by <a href="http://arxiv.org/pdf/1507.01526v1.pdf" target="_blank" rel="noopener">Kalchbrenner, <em>et al.</em> (2015)</a> seem extremely promising. Work using RNNs in generative models – such as <a href="http://arxiv.org/pdf/1502.04623.pdf" target="_blank" rel="noopener">Gregor, <em>et al.</em> (2015)</a>, <a href="http://arxiv.org/pdf/1506.02216v3.pdf" target="_blank" rel="noopener">Chung, <em>et al.</em> (2015)</a>, or <a href="http://arxiv.org/pdf/1411.7610v3.pdf" target="_blank" rel="noopener">Bayer &amp; Osendorfer (2015)</a> – also seems very interesting. The last few years have been an exciting time for recurrent neural networks, and the coming ones promise to only be more so!</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>理解和使用Pytorch搭建GAN</title>
      <link href="/009-li-jie-he-shi-yong-pytorch-da-jian-gan/"/>
      <url>/009-li-jie-he-shi-yong-pytorch-da-jian-gan/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<a href="https://becominghuman.ai/understanding-and-building-generative-adversarial-networks-gans-8de7c1dc0e25" target="_blank" rel="noopener">https://becominghuman.ai/understanding-and-building-generative-adversarial-networks-gans-8de7c1dc0e25</a></p><p>原文标题：Understanding and building Generative Adversarial Networks(GANs)- Deep Learning with PyTorch</p><hr><blockquote><p><em>We’ll be building a Generative Adversarial Network that will be able to generate images of birds that never actually existed in the real world.</em></p></blockquote><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_OshLCyKhDM6bo-MXqfrM9w.jpeg" alt="img"></p><p>-These bird images are purely generated by the Deep Learning Model(GAN)-</p><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_RiLLyBMOagYJktyv5eodIQ.png" alt="img"></p><p>Before we actually start building a GAN, let us first talk about the idea behind GANs. GANs were invented by Ian Goodfellow, he obtained his <a href="https://en.wikipedia.org/wiki/Bachelor_of_Science" target="_blank" rel="noopener">B.S.</a> and <a href="https://en.wikipedia.org/wiki/Master_of_Science" target="_blank" rel="noopener">M.S.</a> in computer science from <a href="https://en.wikipedia.org/wiki/Stanford_University" target="_blank" rel="noopener">Stanford University</a> and his Ph.D. in machine learning from the <a href="https://en.wikipedia.org/wiki/Université_de_Montréal" target="_blank" rel="noopener">Université de Montréal</a>,. This is the new big thing in the field of Deep Learning right now. Yann LeCun, the director of Facebook AI said :</p><blockquote><p><em>“Generative Adversarial Networks is the most interesting idea in the last ten years in Machine Learning.”</em></p></blockquote><h2 id="何谓GANs-它有何用"><a href="#何谓GANs-它有何用" class="headerlink" title="何谓GANs ? 它有何用 ?"></a>何谓GANs ? 它有何用 ?</h2><p>Neural Networks are good at classifying and predicting things, and AI Researchers wanted to make the neural net more human in nature by allowing it to CREATE rather than just letting it see things, and turns out that Ian Goodfellow was successful in inventing a class of Deep Learning Model which could do that.</p><h2 id="GANs如何工作"><a href="#GANs如何工作" class="headerlink" title="GANs如何工作 ?"></a>GANs如何工作 ?</h2><p>GANs contain two separate neural networks. Let us call one neural network as “G”, which stands for <strong>Generator </strong>and the other neural network as “D”, which is a <strong>Discriminator</strong>. The Generator first generates random images and a Discriminator sees those images and tells the Generator how real the generated images are.</p><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_YH3b1fARO-bf6gU3kyzT4A.jpeg" alt="img"></p><h2 id="生成器"><a href="#生成器" class="headerlink" title="生成器 :"></a>生成器 :</h2><p>In the starting phase, a Generator model takes <code>random noise signals</code> as input and generates a random noisy image as the output, gradually with the help of the Discriminator, it starts generating images of a particular class that look real.</p><h2 id="判别器"><a href="#判别器" class="headerlink" title="判别器 :"></a>判别器 :</h2><p>The Discriminator which will be the opponent of Generator is fed with both the generated images as well as a certain class of images at the same time, allowing it to tell the generated how the real image looks like.</p><p>After reaching a certain point, the Discriminator will be unable to tell if the generate image is a real or a fake image, and that is when we can see images of a certain class(class that the discriminator is trained with.) being generated by out Generator that never actually existed before.</p><h2 id="GAN的应用"><a href="#GAN的应用" class="headerlink" title="GAN的应用 :"></a>GAN的应用 :</h2><ul><li><p>超分辨率（Super Resolution）.</p><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_CjlvvAEa800e3asqLWkFpQ.png" alt="img"></p></li></ul><ul><li>Assisting Artists.</li></ul><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_xW7HOxpzO_ZNGyYXX4MMPQ.jpeg" alt="img"></p><ul><li><p>Element Abstraction.</p><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_iRyCj-s28wuupEZjOIcknw.png" alt="img"></p><h1 id="上代码"><a href="#上代码" class="headerlink" title="上代码"></a>上代码</h1><p>NOTE : The below explanation of the code is not prepared for a novice deep learning programmer , i expect you to be comfortable with the deep learning accent in python.</p><p><strong>L</strong>et us start by importing all the required python libraries for building our GAN. Please make sure PyTorch is installed in your computer before you start.</p><pre class=" language-lang-python"><code class="language-lang-python">#importing required librariesfrom __future__ import print_functionimport torchimport torch.nn as nnimport torch.nn.parallelimport torch.optim as optimimport torch.utils.dataimport torchvision.datasets as dsetimport torchvision.transforms as transformsimport torchvision.utils as vutilsfrom torch.autograd import Variable</code></pre><p><strong>N</strong>ow let us set the hyper-parameters which will be the <strong>batch-size</strong> and <strong>image-size</strong> in this case :</p><pre class=" language-lang-python"><code class="language-lang-python"># Setting hyperparametersbatchSize = 64 imageSize = 64</code></pre></li></ul><p>  In the first line, we have set the size of the batch to 64. And in the second line we have set the size of the images generated by the generator to 64 x 64 resolution.</p><hr><p>  <strong>T</strong>hen we are going to create an object to perform image transformations as given below :</p><pre class=" language-lang-python"><code class="language-lang-python"># Creating the transformationstransform = transforms.Compose([transforms.Scale(imageSize),                                 transforms.ToTensor(),                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),])</code></pre><p>The above transformations are necessary to make the image compatible as an input to the neural network of the discriminator.</p><hr><p>NOTE : In order to get the dataset, click here and you will be directed to <a href="https://github.com/venkateshtata/GAN_Medium.git" target="_blank" rel="noopener">https://github.com/venkateshtata/GAN_Medium.git</a> , clone that repository into your local system and replace the <code>dcgan.py</code> file with the python file your writing to. the <code>data</code> folder contains the dataset.</p><hr><p><strong>N</strong>ow lets load our dataset from a respective directory. The type of dataset we are going to be using here is a <code>CIFAR-10</code> dataset. We are going to load them in batches, and make sure that the python file you are writing to is in the same directory for less complexity while importing the dataset.</p><pre class=" language-lang-python"><code class="language-lang-python"># Loading the datasetdataset = dset.CIFAR10(root = './data', download = True, transform = transform)dataloader = torch.utils.data.DataLoader(dataset, batch_size = batchSize, shuffle = True, num_workers = 2)</code></pre><p>We download the training set in the <code>./data</code> folder and we apply the previous transformations on each image. Then use <code>dataLoader</code> to get the images of the training set batch by batch. Almost every element of the above code is self explanatory, the value of <code>num_workers</code> defines the number of threads that must be used to carry out the process of loading the training data.</p><hr><p><strong>A</strong>s we will be dealing with multiple(2) neural networks here, we will be defining a universal function to initialise the weights of a given neural network by calling the function and passing the NN(Neural Network) into it.</p><pre class=" language-lang-python"><code class="language-lang-python">def weights_init(m):    classname = m.__class__.__name__    if classname.find('Conv') != -1:        m.weight.data.normal_(0.0, 0.02)    elif classname.find('BatchNorm') != -1:        m.weight.data.normal_(1.0, 0.02)        m.bias.data.fill_(0)</code></pre><p>The above <code>weights_init</code> function takes as input a neural network <code>m</code> and will initialise all its weights. This function will be called for each iteration during the training process.</p><hr><p><img src="009-%E7%90%86%E8%A7%A3%E5%92%8C%E4%BD%BF%E7%94%A8Pytorch%E6%90%AD%E5%BB%BAGAN/1_NFO8IogPJRf_eGKBZnd-Fg.png" alt="img"></p><p><strong>O</strong>ur first big step will be to define a class for our <code>Generator neural network</code>. We’ll start by creating a class that will be holding the architecture of the Generator, which will basically contain a sequence of layers that each input undergoes.</p><pre class=" language-lang-python"><code class="language-lang-python">class G(nn.Module):    def __init__(self):            super(G, self).__init__()            self.main = nn.Sequential(                            nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),                            nn.BatchNorm2d(512),                            nn.ReLU(True),                            nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),                            nn.BatchNorm2d(256),                            nn.ReLU(True),                            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),                            nn.BatchNorm2d(128),                            nn.ReLU(True),                            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),                            nn.BatchNorm2d(64),                            nn.ReLU(True),                            nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),                            nn.Tanh()                        )</code></pre><p><strong>B</strong>reaking down the above code :</p><ul><li>We have created a class ‘G’, referring to the Generator neural network, and inheriting from <code>nn.module</code> which contains all the tools required for building neural networks, which help us is placing different applications and and connections inside a given neural network.</li><li>Then we create a meta module of a neural network that will contain a sequence of modules such as convolutions, full connections, etc.</li><li>A great thing to observe from the above Fig 1.0 is that the structures of neural networks of both Generator and the Discriminator are inverse to each other, which basically means that <strong>in Generator, the Convolution must be in an inverse way</strong>, where the the input will be random noise vectors. Hence we start with an inverse convolution using <code>ConvTranspose2d</code>.</li><li>Then we normalize all the features along the dimension of the batch and apply a <code>ReLU</code> rectification to break the linearity. Click <a href="http://pytorch.org/docs/master/nn.html" target="_blank" rel="noopener">here</a> for more detailed explanation of parameters used in the above functions.</li><li>We repeat the above operations again while changing the input nodes from ‘100’ to ‘512’, the number of feature maps from <code>512</code> to <code>256</code> and keeping the bias as False. [ Note: The values i am choosing in the above code are choices of researchers. ]</li><li>In the final <code>ConvTranspose2d</code> we will be outputting 3 filters as the output image of the generator is going to be a 3 channel(RGB) and we apply a <code>Tanh</code> rectification to break the linearity and stay between -1 and +1.</li></ul><hr><p><strong>N</strong>ow we need to create a tool which will be a forward function to propogate the signal inside the Generator.</p><pre class=" language-lang-python"><code class="language-lang-python">def forward(self, input):        output = self.main(input)        return output</code></pre><p>The input of the above function will be some random vector of size <code>100</code> as defined inside the <code>G</code> class. It returns the output containing the generated images. The initial image is made up random vectors.</p><hr><p><strong>C</strong>reating the generator :</p><pre class=" language-lang-python"><code class="language-lang-python">netG = G() netG.apply(weights_init)</code></pre><p>Here we are creating a generator object and initialising all the weights of the input neural network.</p><hr><p><strong>N</strong>ow, lets start defining our <strong>Discriminator</strong> class that will be holding the architecture of a Discriminator.</p><pre class=" language-lang-python"><code class="language-lang-python">class D(nn.Module):def __init__(self):        super(D, self).__init__()        self.main = nn.Sequential(            nn.Conv2d(3, 64, 4, 2, 1, bias = False),            nn.LeakyReLU(0.2, inplace = True),            nn.Conv2d(64, 128, 4, 2, 1, bias = False),            nn.BatchNorm2d(128),            nn.LeakyReLU(0.2, inplace = True),            nn.Conv2d(128, 256, 4, 2, 1, bias = False),            nn.BatchNorm2d(256),            nn.LeakyReLU(0.2, inplace = True),            nn.Conv2d(256, 512, 4, 2, 1, bias = False),            nn.BatchNorm2d(512),            nn.LeakyReLU(0.2, inplace = True),            nn.Conv2d(512, 1, 4, 1, 0, bias = False),            nn.Sigmoid()        )</code></pre><p><strong>B</strong>reaking down the Discriminator :</p><ul><li>Similar to the G class, the <code>D</code> Discriminator class is inheriting from the <code>nn.module</code>. The input of the <strong>Discriminator</strong> will be the image generated by the <strong>Generator</strong>, to which the <strong>Discriminator</strong> will be returning a number between 0 and 1 as output.</li><li>Since it takes a generated image of the generator, the first operation is going to be a convolution, hence we start with a convolution and apply <code>LeakyReLU</code>.</li><li>Observe that unlike the what we did in <code>G</code> class, we are using <code>LeakyReLU</code> here, which will take the negative slope till <code>0.2</code>, and this comes from frequent experimentation, which i didn’t do, but researchers choice.</li><li>We use <code>BatchNorm2d</code> to normalize all the features along the dimension of the batch.</li><li>And at the end, we are using the classic old fashioned function, which is the <code>sigmoid</code> function to break the linearity and stay between 0 and 1.</li></ul><hr><p><strong>N</strong>ow, in order to forward propagate the signal into the <strong>Discriminator</strong>, we need to define a <code>Forward</code> class, which is going to carry the output of the generator to the <strong>Discriminator</strong> :</p><pre class=" language-lang-python"><code class="language-lang-python">def forward(self, input):        output = self.main(input)        return output.view(-1)</code></pre><p>In the final line we return the output which will be a value between 0 and 1, because we need to flatten passed NN to make sure the vectors are in the same dimension.</p><hr><p><strong>C</strong>reating the Discriminator :</p><pre class=" language-lang-python"><code class="language-lang-python">netD = D() netD.apply(weights_init)</code></pre><p>We create the discriminator object of the above class <code>D</code> and initialize all the weights of its neural network.</p><hr><p><strong>N</strong>ow its time we train our Generative Adversarial Network. But before that we need to start by getting a criteria that will measure the error of prediction given by the discriminator. In order to achieve that, we are going to use <strong>BCE Loss</strong>(where BCE means Binary Cross Entropy.), which is perfect for Adversarial Neural Networks. Hence we need optimisers for both the generator as well as the discriminator.</p><pre class=" language-lang-python"><code class="language-lang-python">criterion = nn.BCELoss()optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))</code></pre><p>We start by creating a criterion object that will measure the error between the prediction and the target. Then we create optimisers for objects of both discriminator and the generator.</p><p>We are using <code>Adam</code> optimiser from the <code>optim</code> module, which is a highly advance optimal for stochastic gradient descent.</p><hr><p><strong>W</strong>e’ll be training our neural nets for <code>25</code> epochs, hence :</p><pre class=" language-lang-python"><code class="language-lang-python">for epoch in range(25):</code></pre><p>Then we need to iterate over the images within the dataset, hence :</p><pre class=" language-lang-python"><code class="language-lang-python">for i, data in enumerate(dataloader, 0):</code></pre><p>First step is to update the weights of the neural network of the discriminator, hence we initialise the gradients of the discriminator to 0 with respect to the weights :</p><pre class=" language-lang-python"><code class="language-lang-python">netD.zero_grad()</code></pre><p><strong>A</strong>s we know that our discriminator must be trained with both the real and fake images at a time. Hence we will train the discriminator with a real image of the dataset first :</p><pre class=" language-lang-python"><code class="language-lang-python">real, _ = data        input = Variable(real)        target = Variable(torch.ones(input.size()[0]))        output = netD(input)        errD_real = criterion(output, target)</code></pre><p>We get a real image of the dataset which will be used to train the discriminator, and then wrap it in a variable. Then we forward propagate this real image into the neural network of the discriminator to get the prediction (a value between 0 and 1) and compute the loss between the predictions (output) and the target (equal to 1).</p><hr><p><strong>N</strong>ow, training the discriminator with a fake image generated by the generator :</p><pre class=" language-lang-python"><code class="language-lang-python">noise = Variable(torch.randn(input.size()[0], 100, 1, 1))        fake = netG(noise)        target = Variable(torch.zeros(input.size()[0]))        output = netD(fake.detach())        errD_fake = criterion(output, target)</code></pre><p>Here, first we are making a random input vector (noise) of the generator and forward propagate this random input vector into the neural network of the generator to get some fake generated images. Then we forward propagate the fake generated images into the neural network of the discriminator to get the prediction (a value between 0 and 1) and compute the loss between the prediction (output) and the target (equal to 0).</p><hr><p><strong>B</strong>ack-propagating the total error :</p><pre class=" language-lang-python"><code class="language-lang-python">errD = errD_real + errD_fake        errD.backward()        optimizerD.step()</code></pre><p>Here we are computing the total error of the discriminator and backpropagating the loss error by computing the gradients of the total error with respect to the weights of the discriminator. At the end we apply the optimizer to update the weights according to how much they are responsible for the loss error of the discriminator.</p><hr><p><strong>N</strong>ext step is to update the weights of the neural network of the generator :</p><pre class=" language-lang-python"><code class="language-lang-python">netG.zero_grad()        target = Variable(torch.ones(input.size()[0]))        output = netD(fake)        errG = criterion(output, target)        errG.backward()        optimizerG.step()</code></pre><p><strong>A</strong>s done previously , first we are initialising the gradients of the generator to 0 with respect to the weights. Getting the target. Forward propagating the fake generated images into the neural network of the discriminator to get the prediction (a value between 0 and 1) and then computing the loss between the prediction (output between 0 and 1) and the target (equal to 1). Then back-propagating the loss error by computing the gradients of the total error with respect to the weights of the generator and applying the optimizer to update the weights according to how much they are responsible for the loss error of the generator.</p><hr><p><strong>N</strong>ow, our final step is to print the losses and save the real images and the generated images of the mini batch every 100 steps. Which is done as followed :</p><pre class=" language-lang-python"><code class="language-lang-python">print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i, len(dataloader), errD.data[0], errG.data[0]))        if i % 100 == 0:            vutils.save_image(real, '%s/real_samples.png' % "./results", normalize = True)            fake = netG(noise)            vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % ("./results", epoch), normalize = True)</code></pre><h2 id="完整代码"><a href="#完整代码" class="headerlink" title="完整代码 :"></a>完整代码 :</h2><pre class=" language-lang-python"><code class="language-lang-python">from __future__ import print_functionimport torchimport torch.nn as nnimport torch.nn.parallelimport torch.optim as optimimport torch.utils.dataimport torchvision.datasets as dsetimport torchvision.transforms as transformsimport torchvision.utils as vutilsfrom torch.autograd import VariablebatchSize = 64 imageSize = 64transform = transforms.Compose([transforms.Scale(imageSize),                                 transforms.ToTensor(),                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),]) # We create a list of transformations (scaling, tensor conversion, normalization) to apply to the input images.dataset = dset.CIFAR10(root = './data',                        download = True,                        transform = transform) dataloader = torch.utils.data.DataLoader(dataset,                                          batch_size = batchSize,                                          shuffle = True, num_workers = 2) def weights_init(m):    classname = m.__class__.__name__    if classname.find('Conv') != -1:        m.weight.data.normal_(0.0, 0.02)    elif classname.find('BatchNorm') != -1:        m.weight.data.normal_(1.0, 0.02)        m.bias.data.fill_(0)# Generatorclass G(nn.Module):    def __init__(self):            super(G, self).__init__()            self.main = nn.Sequential(                nn.ConvTranspose2d(100, 512, 4, 1, 0, bias = False),                nn.BatchNorm2d(512),                nn.ReLU(True),                nn.ConvTranspose2d(512, 256, 4, 2, 1, bias = False),                nn.BatchNorm2d(256),                nn.ReLU(True),                nn.ConvTranspose2d(256, 128, 4, 2, 1, bias = False),                nn.BatchNorm2d(128),                nn.ReLU(True),                nn.ConvTranspose2d(128, 64, 4, 2, 1, bias = False),                nn.BatchNorm2d(64),                nn.ReLU(True),                nn.ConvTranspose2d(64, 3, 4, 2, 1, bias = False),                nn.Tanh()            )    def forward(self, input):            output = self.main(input)            return outputnetG = G()netG.apply(weights_init)# Discriminatorclass D(nn.Module):    def __init__(self):            super(D, self).__init__()            self.main = nn.Sequential(                nn.Conv2d(3, 64, 4, 2, 1, bias = False),                nn.LeakyReLU(0.2, inplace = True),                nn.Conv2d(64, 128, 4, 2, 1, bias = False),                nn.BatchNorm2d(128),                nn.LeakyReLU(0.2, inplace = True),                nn.Conv2d(128, 256, 4, 2, 1, bias = False),                nn.BatchNorm2d(256),                nn.LeakyReLU(0.2, inplace = True),                nn.Conv2d(256, 512, 4, 2, 1, bias = False),                nn.BatchNorm2d(512),                nn.LeakyReLU(0.2, inplace = True),                nn.Conv2d(512, 1, 4, 1, 0, bias = False),                nn.Sigmoid()            )    def forward(self, input):            output = self.main(input)            return output.view(-1)netD = D()netD.apply(weights_init)# Create criterioncriterion = nn.BCELoss()optimizerD = optim.Adam(netD.parameters(), lr = 0.0002, betas = (0.5, 0.999))optimizerG = optim.Adam(netG.parameters(), lr = 0.0002, betas = (0.5, 0.999))# Batch Trainingfor epoch in range(25):    for i, data in enumerate(dataloader, 0):            netD.zero_grad()            real, _ = data            input = Variable(real)            target = Variable(torch.ones(input.size()[0]))            output = netD(input)            errD_real = criterion(output, target)            noise = Variable(torch.randn(input.size()[0], 100, 1, 1))            fake = netG(noise)            target = Variable(torch.zeros(input.size()[0]))            output = netD(fake.detach())            errD_fake = criterion(output, target)            errD = errD_real + errD_fake            errD.backward()            optimizerD.step()            netG.zero_grad()            target = Variable(torch.ones(input.size()[0]))            output = netD(fake)            errG = criterion(output, target)            errG.backward()            optimizerG.step()            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f' % (epoch, 25, i,     len(dataloader), errD.data[0], errG.data[0]))            if i % 100 == 0:                vutils.save_image(real, '%s/real_samples.png' % "./results", normalize = True)                fake = netG(noise)                vutils.save_image(fake.data, '%s/fake_samples_epoch_%03d.png' % ("./results", epoch), normalize = True)</code></pre><p>代码库在此 : <a href="https://github.com/venkateshtata/GAN_Medium" target="_blank" rel="noopener">https://github.com/venkateshtata/GAN_Medium</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>变分自编码器VAE是这么一回事</title>
      <link href="/vae-bian-fen-zi-bian-ma-qi-vae-yuan-lai-shi-zhe-me-yi-hui-shi/"/>
      <url>/vae-bian-fen-zi-bian-ma-qi-vae-yuan-lai-shi-zhe-me-yi-hui-shi/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<a href="https://zhuanlan.zhihu.com/p/34998569" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/34998569</a></p><hr><p>过去虽然没有细看，但印象里一直觉得<strong>变分自编码器</strong>（Variational Auto-Encoder，VAE）是个好东西。趁着最近看概率图模型的三分钟热度，我决定也争取把 VAE 搞懂。</p><p>于是乎照样翻了网上很多资料，无一例外发现都很含糊，主要的感觉是公式写了一大通，还是迷迷糊糊的，最后好不容易觉得看懂了，再去看看实现的代码，又感觉实现代码跟理论完全不是一回事啊。</p><p>终于，东拼西凑再加上我这段时间对概率模型的一些积累，并反复对比原论文 <em>Auto-Encoding Variational Bayes</em>，最后我觉得我应该是想明白了。</p><p>其实真正的 VAE，跟很多教程说的的还真不大一样，很多教程写了一大通，都没有把模型的要点写出来。于是写了这篇东西，希望通过下面的文字，能把 VAE 初步讲清楚。</p><h2 id="分布变换"><a href="#分布变换" class="headerlink" title="分布变换"></a><strong>分布变换</strong></h2><p>通常我们会拿 VAE 跟 GAN 比较，的确，它们两个的目标基本是一致的——希望<strong>构建一个从隐变量 <em>Z</em> 生成目标数据 <em>X</em> 的模型</strong>，但是实现上有所不同。</p><p>更准确地讲，它们是假设了服从某些常见的分布（比如正态分布或均匀分布），然后希望训练一个模型 <em>X</em>=<em>g</em>(<em>Z</em>)，这个模型能够==将原来的概率分布映射到训练集的概率分布==，也就是说，<strong>它们的目的都是进行分布之间的变换</strong>。</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-d7a52f6f211594a0853993365f51cb82_hd.jpg" alt="img"></p><p>生成模型的难题就是判断生成分布与真实分布的相似度，因为我们只知道两者的采样结果，不知道它们的分布表达式。</p><p>那现在假设服从标准的正态分布，那么我就可以从中采样得到若干个 $Z_1$,$Z_2$,…,$Z_n$，然后对它做变换得到 X̂1=g(Z1),X̂2=g(Z2),…,X̂n=g(Zn)，<strong>我们怎么判断这个通过 f 构造出来的数据集，它的分布跟我们目标的数据集分布是不是一样的呢？</strong></p><p>有读者说不是有 KL 散度吗？当然不行，因为 KL 散度是根据两个概率分布的<strong>表达式</strong>来算它们的相似度的，然而目前我们并不知道它们的概率分布的表达式。</p><p>我们只有一批从构造的分布采样而来的数据 {X̂1,X̂2,…,X̂n}，还有一批从真实的分布采样而来的数据 {X1,X2,…,Xn}（也就是我们希望生成的训练集）。我们只有样本本身，没有分布表达式，当然也就没有方法算 KL 散度。</p><p>虽然遇到困难，但还是要想办法解决的。<strong>GAN 的思路很直接粗犷：既然没有合适的度量，那我干脆把这个度量也用神经网络训练出来吧</strong>。</p><p>就这样，<strong>WGAN</strong> 就诞生了，详细过程请参考<a href="https://link.zhihu.com/?target=http%3A//mp.weixin.qq.com/s%3F__biz%3DMzIwMTc4ODE0Mw%3D%3D%26mid%3D2247484880%26idx%3D1%26sn%3D4b2e976cc715c9fe2d022ff6923879a8%26chksm%3D96e9da50a19e5346307b54f5ce172e355ccaba890aa157ce50fda68eeaccba6ea05425f6ad76%26scene%3D21%23wechat_redirect">互怼的艺术：从零直达 WGAN-GP</a>。而 VAE 则使用了一个精致迂回的技巧。</p><h2 id="VAE慢谈"><a href="#VAE慢谈" class="headerlink" title="VAE慢谈"></a><strong>VAE慢谈</strong></h2><p>这一部分我们先回顾一般教程是怎么介绍 VAE 的，然后再探究有什么问题，接着就自然地发现了 VAE 真正的面目。</p><p><strong>经典回顾</strong></p><p>首先我们有一批数据样本 {<em>X</em>1,…,<em>X</em>n}，其整体用 <em>X</em> 来描述，我们本想根据 {<em>X</em>1,…,<em>X</em>n} 得到 <em>X</em> 的分布 <em>p</em>(<em>X</em>)，如果能得到的话，那我直接根据 <em>p</em>(<em>X</em>) 来采样，就可以得到所有可能的 <em>X</em> 了（包括 {<em>X</em>1,…,<em>X</em>n} 以外的），这是一个终极理想的生成模型了。</p><p>当然，这个理想很难实现，于是我们将分布改一改：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-6d99b17711df7d1fe8efbee2dbce28ff_hd.jpg" alt="img"></p><p>这里我们就不区分求和还是求积分了，意思对了就行。此时 <em>p</em>(<em>X</em>|<em>Z</em>) 就描述了一个由 <em>Z</em> 来生成 <em>X</em>的模型，而我们假设 <em>Z</em> 服从标准正态分布，也就是 <em>p</em>(<em>Z</em>)=<em>N</em>(0,<em>I</em>)。<strong>如果这个理想能实现，那么我们就可以先从标准正态分布中采样一个</strong> <strong>Z，然后根据</strong> <strong><em>Z</em></strong> <strong>来算一个</strong> <strong>X，也是一个很棒的生成模型</strong>。</p><p>接下来就是结合自编码器来实现重构，保证有效信息没有丢失，再加上一系列的推导，最后把模型实现。框架的示意图如下：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-25f257b89b46996fdfaaf3935a9bfb48_hd.jpg" alt="img"></p><p><strong>▲</strong> VAE的传统理解</p><p>看出了什么问题了吗？如果像这个图的话，我们其实完全不清楚：<strong>究竟经过重新采样出来的Zk，是不是还对应着原来的</strong> <strong>Xk，所以我们如果直接最小化</strong> <strong>D(X̂k,Xk)^2（这里</strong> <strong>D 代表某种距离函数）是很不科学的，而事实上你看代码也会发现根本不是这样实现的</strong>。</p><p>也就是说，很多教程说了一大通头头是道的话，然后写代码时却不是按照所写的文字来写，可是他们也不觉得这样会有矛盾。</p><p><strong>VAE初现</strong></p><p>其实，<strong>在整个 VAE 模型中，我们并没有去使用</strong> <strong>p(Z)（先验分布）是正态分布的假设，我们用的是假设</strong> <strong>p(Z|X)（后验分布）是正态分布</strong>。</p><p>具体来说，给定一个真实样本 <em>Xk</em>，我们假设存在<strong>一个专属于</strong> <strong><em>Xk</em></strong> <strong>的分布</strong> <strong>p(Z|Xk)</strong>（学名叫后验分布），并进一步假设这个分布是（独立的、多元的）正态分布。</p><p>为什么要强调“专属”呢？因为我们后面要训练一个生成器 <em>X</em>=<em>g</em>(<em>Z</em>)，希望能够把从分布 <em>p</em>(<em>Z</em>|<em>Xk</em>) 采样出来的一个 <em>Zk</em> 还原为 <em>Xk</em>。</p><p>如果假设 <em>p</em>(<em>Z</em>) 是正态分布，然后从 <em>p</em>(<em>Z</em>) 中采样一个 <em>Z</em>，那么我们怎么知道这个 <em>Z</em> 对应于哪个真实的 <em>X</em> 呢？<strong>现在</strong> <strong>p(Z|Xk) 专属于</strong> <strong>Xk，我们有理由说从这个分布采样出来的</strong> <strong><em>Z</em></strong> <strong>应该要还原到Xk</strong> <strong>中去</strong>。</p><p>事实上，在论文 <em>Auto-Encoding Variational Bayes</em> 的应用部分，也特别强调了这一点：</p><blockquote><p><em>In this case, we can let the variational approximate posterior be a multivariate Gaussian with a diagonal covariance structure:</em></p></blockquote><p><img src="../img/008-变分自编码器VAE-原来是这么一回事/v2-241c1d29c3c8ca890bb27fa7abb98ed6_hd.jpg" alt="img"></p><p>论文中的式 (9) 是实现整个模型的关键，不知道为什么很多教程在介绍 VAE 时都没有把它凸显出来。尽管论文也提到 <em>p</em>(<em>Z</em>) 是标准正态分布，然而那其实并不是本质重要的。</p><p>再次强调，这时候每一个 $X_k$ 都配上了一个专属的正态分布，才方便后面的生成器做还原。但这样有多少个 <em>X</em> 就有多少个正态分布了。我们知道正态分布有两组参数：均值 $μ$ 和方差 $σ^2$（多元的话，它们都是向量）。</p><p><strong>那我怎么找出专属于</strong> $X_k$ <strong>的正态分布</strong> $p(Z|X_k) $的均值和方差呢？好像并没有什么直接的思路。</p><p>那好吧，<strong>我就用神经网络来拟合出来</strong>。这就是神经网络时代的哲学：难算的我们都用神经网络来拟合，在 WGAN 那里我们已经体验过一次了，现在再次体验到了。</p><p>于是我们构建两个神经网络 $μ_k=f_1(X_k)$，$logσ^2=f_2(X_k)$ 来算它们了。我们选择拟合$ logσ^2$ 而不是直接拟合 $σ^2$，是因为 $σ^2$ 总是非负的，需要加激活函数处理，而拟合 $logσ^2$ 不需要加激活函数，因为它可正可负。</p><p>到这里，我能知道专属于 $ X_k$ 的均值和方差了，也就知道它的正态分布长什么样了，然后从这个专属分布中采样一个 $Z_k$ 出来，然后经过一个生成器得到 <em>X̂k</em>=<em>g</em>(<em>Zk</em>)。</p><p>现在我们可以放心地最小化 <em>D</em>(<em>X̂k</em>,<em>Xk</em>)^2，因为 <em>Zk</em> 是从专属 <em>Xk</em> 的分布中采样出来的，这个生成器应该要把开始的 <em>Xk</em> 还原回来。<strong>于是可以画出 VAE 的示意图：</strong></p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-36c7da0b2fe37bd021699532a2cff1e8_hd.jpg" alt="img"></p><p>事实上，VAE 是为每个样本构造专属的正态分布，然后采样来重构。</p><p><strong>分布标准化</strong></p><p>让我们来思考一下，根据上图的训练过程，最终会得到什么结果。</p><p>首先，我们希望重构 <em>X</em>，也就是最小化 <em>D</em>(<em>X̂k</em>,<em>Xk</em>)^2，但是这个重构过程受到噪声的影响，因为<em>Zk</em> 是通过重新采样过的，不是直接由 encoder 算出来的。</p><p>显然噪声会增加重构的难度，不过好在这个噪声强度（也就是方差）通过一个神经网络算出来的，所以最终模型为了重构得更好，肯定会想尽办法让方差为0。</p><p>而方差为 0 的话，也就没有随机性了，所以不管怎么采样其实都只是得到确定的结果（也就是均值），只拟合一个当然比拟合多个要容易，而均值是通过另外一个神经网络算出来的。</p><p>说白了，<strong>模型会慢慢退化成普通的 AutoEncoder，噪声不再起作用</strong>。</p><p>这样不就白费力气了吗？说好的生成模型呢？</p><p>别急别急，<strong>其实 VAE 还让所有的</strong> <strong>p(Z|X) 都向标准正态分布看齐</strong>，这样就防止了噪声为零，同时保证了模型具有生成能力。</p><p>怎么理解“保证了生成能力”呢？如果所有的 <em>p</em>(<em>Z</em>|<em>X</em>) 都很接近标准正态分布 <em>N</em>(0,<em>I</em>)，那么根据定义：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-e162ff5ea26838c18314a351ca166427_hd.jpg" alt="img"></p><p>这样我们就能达到我们的先验假设：$p(Z)$ 是标准正态分布。然后我们就可以放心地从 $N(0,I)$ 中采样来生成图像了。</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-a3f264a40db57e010b7ebf0253198726_hd.jpg" alt="img"></p><p>为了使模型具有生成能力，VAE 要求每个 p(Z_X) 都向正态分布看齐。</p><p>那怎么让所有的 <em>p</em>(<em>Z</em>|<em>X</em>) 都向 <em>N</em>(0,<em>I</em>) 看齐呢？如果没有外部知识的话，其实最直接的方法应该是在重构误差的基础上中加入额外的 loss：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-18ab0eeeeaf3d1adffa235e995521255_hd.jpg" alt="img"></p><p>因为它们分别代表了均值 <em>μk</em> 和方差的对数 log<em>σ</em>^2，达到 <em>N</em>(0,<em>I</em>) 就是希望二者尽量接近于 0 了。不过，这又会面临着这两个损失的比例要怎么选取的问题，选取得不好，生成的图像会比较模糊。</p><p>所以，原论文直接算了一般（各分量独立的）正态分布与标准正态分布的 KL 散度<em>KL</em>(<em>N</em>(<em>μ</em>,<em>σ</em>^2)‖<em>N</em>(0,<em>I</em>))作为这个额外的 loss，计算结果为：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-08091fc4fa1460c9fa611cfcf0608105_hd.jpg" alt="img"></p><p>这里的 <em>d</em> 是隐变量 <em>Z</em> 的维度，而 <em>μ</em>(<em>i</em>) 和 σ_{(i)}^{2} 分别代表一般正态分布的均值向量和方差向量的第 <em>i</em> 个分量。直接用这个式子做补充 loss，就不用考虑均值损失和方差损失的相对比例问题了。</p><p>显然，这个 loss 也可以分两部分理解：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-af1049578e84eddf1c817422aa8a3bbf_hd.jpg" alt="img"></p><p><strong>推导</strong></p><p>由于我们考虑的是各分量独立的多元正态分布，因此只需要推导一元正态分布的情形即可，根据定义我们可以写出：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-7a3c7ea64e7f11c475cf35cd44fa3ca2_hd.jpg" alt="img"></p><p>整个结果分为三项积分，第一项实际上就是 −log<em>σ^</em>2 乘以概率密度的积分（也就是 1），所以结果是 −log<em>σ^</em>2；第二项实际是正态分布的二阶矩，熟悉正态分布的朋友应该都清楚正态分布的二阶矩为 <em>μ</em>^2+<em>σ</em>^2；而根据定义，第三项实际上就是“-方差除以方差=-1”。所以总结果就是：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-603cd66d01ad6bac42ac1d2a38bad61f_hd.jpg" alt="img"></p><p><strong>重参数技巧</strong></p><p>最后是实现模型的一个技巧，英文名是 Reparameterization Trick，我这里叫它做重参数吧。</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-2952f780b506319c0911ab4297440079_hd.jpg" alt="img"></p><p><strong>▲</strong> 重参数技巧</p><p>其实很简单，就是我们要从 <em>p</em>(<em>Z</em>|<em>Xk</em>) 中采样一个 <em>Zk</em> 出来，尽管我们知道了 <em>p</em>(<em>Z</em>|<em>Xk</em>) 是正态分布，但是均值方差都是靠模型算出来的，我们要靠这个过程反过来优化均值方差的模型，但是“采样”这个操作是不可导的，而采样的结果是可导的，于是我们利用了一个事实：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-39d484abe79242a398d6f57ee3d7dc04_hd.jpg" alt="img"></p><p>所以，我们将从 <em>N</em>(<em>μ</em>,<em>σ</em>^2) 采样变成了从 <em>N</em>(<em>μ</em>,<em>σ</em>^2) 中采样，然后通过参数变换得到从<em>N</em>(<em>μ</em>,<em>σ</em>^2) 中采样的结果。这样一来，“采样”这个操作就不用参与梯度下降了，改为采样的结果参与，使得整个模型可训练了。</p><p>具体怎么实现，大家把上述文字对照着代码看一下，一下子就明白了。</p><h2 id="后续分析"><a href="#后续分析" class="headerlink" title="后续分析"></a><strong>后续分析</strong></h2><p>即便把上面的所有内容都搞清楚了，面对 VAE，我们可能还存有很多疑问。</p><p><strong>本质是什么</strong></p><p>VAE 的本质是什么？VAE 虽然也称是 AE（AutoEncoder）的一种，但它的做法（或者说它对网络的诠释）是别具一格的。</p><p>在 VAE 中，它的 Encoder 有两个，一个用来计算均值，一个用来计算方差，这已经让人意外了：Encoder 不是用来 Encode 的，是用来算均值和方差的，这真是大新闻了，还有均值和方差不都是统计量吗，怎么是用神经网络来算的？</p><p>事实上，我觉得 <strong>VAE 从让普通人望而生畏的变分和贝叶斯理论出发，最后落地到一个具体的模型中</strong>，虽然走了比较长的一段路，但最终的模型其实是很接地气的。</p><p><strong>它本质上就是在我们常规的自编码器的基础上，对 encoder 的结果（在VAE中对应着计算均值的网络）加上了“高斯噪声”，使得结果 decoder 能够对噪声有鲁棒性；而那个额外的 KL loss（目的是让均值为 0，方差为 1），事实上就是相当于对 encoder 的一个正则项，希望 encoder 出来的东西均有零均值。</strong></p><p>那另外一个 encoder（对应着计算方差的网络）的作用呢？它是用来<strong>动态调节噪声的强度</strong>的。</p><p>直觉上来想，<strong>当 decoder 还没有训练好时（重构误差远大于 KL loss），就会适当降低噪声（KL loss 增加），使得拟合起来容易一些（重构误差开始下降）</strong>。</p><p>反之，<strong>如果 decoder 训练得还不错时（重构误差小于 KL loss），这时候噪声就会增加（KL loss 减少），使得拟合更加困难了（重构误差又开始增加），这时候 decoder 就要想办法提高它的生成能力了</strong>。</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-784891edddff506ea1670c81767e993c_hd.jpg" alt="img"></p><p><strong>▲</strong> VAE的本质结构</p><p>说白了，<strong>重构的过程是希望没噪声的，而 KL loss 则希望有高斯噪声的，两者是对立的。所以，VAE 跟 GAN 一样，内部其实是包含了一个对抗的过程，只不过它们两者是混合起来，共同进化的</strong>。</p><p>从这个角度看，VAE 的思想似乎还高明一些，因为在 GAN 中，造假者在进化时，鉴别者是安然不动的，反之亦然。当然，这只是一个侧面，不能说明 VAE 就比 GAN 好。</p><p>GAN 真正高明的地方是：它连度量都直接训练出来了，而且这个度量往往比我们人工想的要好（然而 GAN 本身也有各种问题，这就不展开了）。</p><p><strong>正态分布？</strong></p><p>对于 <em>p</em>(<em>Z</em>|<em>X</em>) 的分布，读者可能会有疑惑：是不是必须选择正态分布？可以选择均匀分布吗？</p><p>首先，这个本身是一个实验问题，两种分布都试一下就知道了。但是从直觉上来讲，正态分布要比均匀分布更加合理，因为正态分布有两组独立的参数：均值和方差，而均匀分布只有一组。</p><p>前面我们说，<strong>在 VAE 中，重构跟噪声是相互对抗的，重构误差跟噪声强度是两个相互对抗的指标，而在改变噪声强度时原则上需要有保持均值不变的能力，不然我们很难确定重构误差增大了，究竟是均值变化了（encoder的锅）还是方差变大了（噪声的锅）</strong>。</p><p>而均匀分布不能做到保持均值不变的情况下改变方差，所以正态分布应该更加合理。</p><p><strong>变分在哪里</strong></p><p>还有一个有意思（但不大重要）的问题是：VAE 叫做“变分自编码器”，它跟变分法有什么联系？在VAE 的论文和相关解读中，好像也没看到变分法的存在？</p><p>其实如果读者已经承认了 KL 散度的话，那 VAE 好像真的跟变分没多大关系了，因为 KL 散度的定义是：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-5499a0f15ebef578e25122650a510f2c_hd.jpg" alt="img"></p><p>如果是离散概率分布就要写成求和，我们要证明：<strong>已概率分布</strong> <strong>p(x)（或固定q(x)）的情况下，对于任意的概率分布 q(x)（或</strong> <strong>p(x)），都有</strong> <strong>KLp(x)‖q(x))≥0，而且只有当p(x)=q(x)时才等于零</strong>。</p><p>因为 <em>KL</em>(<em>p</em>(<em>x</em>)‖<em>q</em>(<em>x</em>))实际上是一个泛函，要对泛函求极值就要用到变分法，当然，这里的变分法只是普通微积分的平行推广，还没涉及到真正复杂的变分法。而 VAE 的变分下界，是直接基于 KL 散度就得到的。所以直接承认了 KL 散度的话，就没有变分的什么事了。</p><p>一句话，VAE 的名字中“变分”，是因为它的推导过程用到了 KL 散度及其性质。</p><p><strong>条件VAE</strong></p><p>最后，因为目前的 VAE 是无监督训练的，因此很自然想到：如果有标签数据，那么能不能把标签信息加进去辅助生成样本呢？</p><p>这个问题的意图，往往是希望能够实现控制某个变量来实现生成某一类图像。当然，这是肯定可以的，我们把这种情况叫做 <strong>Conditional VAE</strong>，或者叫 CVAE（相应地，在 GAN 中我们也有个 CGAN）。</p><p>但是，CVAE 不是一个特定的模型，而是一类模型，总之就是把标签信息融入到 VAE 中的方式有很多，目的也不一样。这里基于前面的讨论，给出一种非常简单的 VAE。</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-d148bf520bb386c0c4bb11756e4798ee_hd.jpg" alt="img"></p><p><strong>▲</strong> 一个简单的CVAE结构</p><p>在前面的讨论中，我们希望 <em>X</em> 经过编码后，<em>Z</em> 的分布都具有零均值和单位方差，这个“希望”是通过加入了 KL loss 来实现的。</p><p>如果现在多了类别信息 <em>Y</em>，<strong>我们可以希望同一个类的样本都有一个专属的均值</strong> <strong>μ^Y（方差不变，还是单位方差），这个</strong> <strong><em>μ^Y</em></strong> <strong>让模型自己训练出来</strong>。</p><p>这样的话，有多少个类就有多少个正态分布，而在生成的时候，我们就可以<strong>通过控制均值来控制生成图像的类别</strong>。</p><p>事实上，这样可能也是在 VAE 的基础上加入最少的代码来实现 CVAE 的方案了，因为这个“新希望”也只需通过修改 KL loss 实现：</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-6cfa68ced2a4a089f8db3da7236f7129_hd.jpg" alt="img"></p><p>下图显示这个简单的 CVAE 是有一定的效果的，不过因为 encoder 和 decoder 都比较简单（纯 MLP），所以控制生成的效果不尽完美。</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8VAE-%E5%8E%9F%E6%9D%A5%E6%98%AF%E8%BF%99%E4%B9%88%E4%B8%80%E5%9B%9E%E4%BA%8B/v2-55a120bb7af51c4d99c315f402cb9fb1_hd.jpg" alt="img"></p><p>用这个 CVAE 控制生成数字 9，可以发现生成了多种样式的 9，并且慢慢向 7 过渡，所以初步观察这种 CVAE 是有效的。</p><p>更完备的 CVAE 请读者自行学习了，最近还出来了 CVAE 与 GAN 结合的工作 <em>CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training</em>，模型套路千变万化。</p><h2 id="代码"><a href="#代码" class="headerlink" title="代码"></a><strong>代码</strong></h2><p>我把 Keras 官方的 VAE 代码复制了一份，然后微调并根据前文内容添加了中文注释，也把最后说到的简单的 CVAE 实现了一下，供读者参考。</p><p>代码：<a href="https://link.zhihu.com/?target=https%3A//github.com/bojone/vae">https://github.com/bojone/vae</a></p><h2 id="终点站"><a href="#终点站" class="headerlink" title="终点站"></a><strong>终点站</strong></h2><p>磕磕碰碰，又到了文章的终点了。不知道讲清楚了没，希望大家多提点意见。</p><p>总的来说，VAE 的思路还是很漂亮的。倒不是说它提供了一个多么好的生成模型（因为事实上它生成的图像并不算好，偏模糊），而是它提供了一个将概率图跟深度学习结合起来的一个非常棒的案例，这个案例有诸多值得思考回味的地方。</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>变分自编码器背后的直觉</title>
      <link href="/vae-bian-fen-zi-dong-bian-ma-qi-bei-hou-de-zhi-jue-yu-shi-xian/"/>
      <url>/vae-bian-fen-zi-dong-bian-ma-qi-bei-hou-de-zhi-jue-yu-shi-xian/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<a href="https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/" target="_blank" rel="noopener">https://wiseodd.github.io/techblog/2016/12/10/variational-autoencoder/</a></p><hr><p>There are two generative models facing neck to neck in the data generation business right now: <a href="https://wiseodd.github.io/techblog/2016/09/17/gan-tensorflow/" target="_blank" rel="noopener">Generative Adversarial Nets (GAN)</a> and Variational Autoencoder (VAE). These two models have different take on how the models are trained. GAN is rooted in game theory, its objective is to find the Nash Equilibrium between discriminator net and generator net. On the other hand, VAE is rooted in bayesian inference, i.e. it wants to model the underlying probability distribution of data so that it could sample new data from that distribution.</p><p>In this post, we will look at the intuition of VAE model and its implementation in Keras.</p><h2 id="VAE的公式与直觉"><a href="#VAE的公式与直觉" class="headerlink" title="VAE的公式与直觉"></a>VAE的公式与直觉</h2><p>Suppose we want to generate a data. Good way to do it is first to decide what kind of data we want to generate, then actually generate the data. For example, say, we want to generate an animal. First, we imagine the animal: it must have four legs, and it must be able to swim. Having those criteria, we could then actually generate the animal by sampling from the animal kingdom. 瞧，我们得到一个鸭嘴兽!</p><p>From the story above, our imagination is analogous to <strong>latent variable</strong>. It is often useful to decide the latent variable first in generative models, as latent variable could describe our data. Without latent variable, it is as if we just generate data blindly. And this is the difference between GAN and VAE: VAE uses latent variable, hence it’s an expressive model.</p><p>好吧，扯起来很对，但是我们如何建模呢? 让我们先从概率分布谈起。</p><p>定义一些符号：</p><ol><li>$X$: 我们想要建模的数据，也就是动物</li><li>$z$: 潜变量，也就是我们的想象 a.k.a our imagination</li><li>$P(X)$:数据的概率分布,也就是动物王国</li><li>$P(z)$: 潜变量的概率分布, 也就是我们大脑的自动脑补想象</li><li>$P(X|z)$: 指定潜变量下生成数据的分布, 将想象转化为真是动物</li></ol><p>Our objective here is to model the data, hence we want to find $P(X)$. Using the law of probability, we could find it in relation with $z$ as follows:</p><script type="math/tex; mode=display">P(X) = \int P(X \vert z) P(z) dz</script><p>that is, we marginalize out $z$ from the joint probability distribution $P(X,z)$.</p><p>要是我们知道 $P(X,z)$就好了, 或者等价的, $P(X|z)$ 和 $P(z)$…</p><p>The idea of VAE is to infer $P(z)$ using $P(z|X)$. This is make a lot of sense if we think about it: we want to make our latent variable likely under our data. Talking in term of our fable example, we want to limit our imagination only on animal kingdom domain, so we shouldn’t imagine about things like root, leaf, tyre, glass, GPU, refrigerator, doormat, … as it’s unlikely that those things have anything to do with things that come from the animal kingdom. Right?</p><p>But the problem is, we have to infer that distribution $P(z|X)$, as we don’t know it yet. In VAE, as it name suggests, we infer $P(z|X)$ using a method called <strong>Variational Inference (VI)</strong>. VI is one of the popular choice of method in bayesian inference, the other one being MCMC method. 变分推断的主要思想是通过将其作为一个优化问题来进行推理. How? By modeling the true distribution $P(z|X)$ using simpler distribution that is easy to evaluate, e.g. Gaussian, and minimize the difference between those two distribution using <a href="https://en.wikipedia.org/wiki/Kullback–Leibler_divergence" target="_blank" rel="noopener">KL divergence</a> metric, which tells us how difference it is $P$ and $Q$.</p><p>好鸟, 现在比方说我们要用 $Q(z|X)$推断$P(z|X)$ . 那么，两个分布之间的KL散度定义为:</p><script type="math/tex; mode=display">\begin{align}D_{KL}[Q(z \vert X) \Vert P(z \vert X)] &= \sum_z Q(z \vert X) \, \log \frac{Q(z \vert X)}{P(z \vert X)} \\[10pt]                            &= E \left[ \log \frac{Q(z \vert X)}{P(z \vert X)} \right] \\[10pt]                            &= E[\log Q(z \vert X) - \log P(z \vert X)]\end{align} %]]></script><p>Recall the notations above, there are two things that we haven’t use, namely $P(X)$, $P(X|z)$, and $P(z)$. But, with Bayes’ rule, we could make it appear in the equation:</p><script type="math/tex; mode=display">\begin{align}D_{KL}[Q(z \vert X) \Vert P(z \vert X)] &= E \left[ \log Q(z \vert X) - \log \frac{P(X \vert z) P(z)}{P(X)} \right] \\[10pt]                                        &= E[\log Q(z \vert X) - (\log P(X \vert z) + \log P(z) - \log P(X))] \\[10pt]                                        &= E[\log Q(z \vert X) - \log P(X \vert z) - \log P(z) + \log P(X)]\end{align} %]]></script><p>Notice that the expectation is over $z$ and $P(X)$ doesn’t depend on $z$, so we could move it outside of the expectation.</p><script type="math/tex; mode=display">\begin{align}D_{KL}[Q(z \vert X) \Vert P(z \vert X)] &= E[\log Q(z \vert X) - \log P(X \vert z) - \log P(z)] + \log P(X) \\[10pt]D_{KL}[Q(z \vert X) \Vert P(z \vert X)] - \log P(X) &= E[\log Q(z \vert X) - \log P(X \vert z) - \log P(z)]\end{align} %]]></script><p>And this is it, the VAE objective function:</p><script type="math/tex; mode=display">\log P(X) - D_{KL}[Q(z \vert X) \Vert P(z \vert X)] = E[\log P(X \vert z)] - D_{KL}[Q(z \vert X) \Vert P(z)]</script><p>至此，我们都有了什么，列举一下：</p><ol><li>$Q(z|X)$ that project our data $X$ into latent variable space</li><li>$z$, the latent variable</li><li>$P(X|z)$ that generate data given latent variable</li></ol><p>We might feel familiar with this kind of structure. And guess what, it’s the same structure as seen in <a href="https://wiseodd.github.io/techblog/2016/12/03/autoencoders/" target="_blank" rel="noopener">Autoencoder</a>! That is, $Q(z|X)$ is the encoder net, $z$ is the encoded representation, and $P(X|z)$ is the decoder net! Well, well, no wonder the name of this model is Variational Autoencoder!</p><h2 id="剖析目标"><a href="#剖析目标" class="headerlink" title="剖析目标"></a>剖析目标</h2><p>It turns out, VAE objective function has a very nice interpretation. That is, we want to model our data, which described by $log⁡P(X)$, under some error $D_{KL}[Q(z|X)∥P(z|X)]$. In other words, VAE tries to find the lower bound of $log⁡P(X)$, which in practice is good enough as trying to find the exact distribution is often untractable[难以处理].</p><p>That model then could be found by maximazing over some mapping from latent variable to data $logP(X|z)$ and minimizing the difference between our simple distribution $Q(z|X)$ and the true latent distribution $P(z)$.</p><p>As we might already know, maximizing $E[logP(X|z)]$ is a maximum likelihood estimation. We basically see it all the time in discriminative supervised model, for example Logistic Regression, SVM, or Linear Regression. In the other words, given an input $z$ and an output $X$, we want to maximize the conditional distribution $P(X|z)$ under some model parameters. So we could implement it by using any classifier with input $z$ and output $X$, then optimize the objective function by using for example log loss or regression loss.</p><p>What about $D_{KL}[Q(z \vert X) \Vert P(z)]$? Here, $P(z)$is the latent variable distribution. We might want to sample $P(z)$ later, so the easiest choice is $N(0,1)$. Hence, we want to make $Q(z|X)$ to be as close as possible to $N(0,1)$ so that we could sample it easily.</p><p>Having $P(z)=N(0,1)$ also add another benefit. Let’s say we also want $Q(z|X)$ to be Gaussian with parameters $μ(X)$ and $Σ(X)$, i.e. the mean and variance <strong>given</strong> $X$. Then, the KL divergence between those two distribution could be computed in closed form!</p><script type="math/tex; mode=display">D_{KL}[N(\mu(X), \Sigma(X)) \Vert N(0, 1)] = \frac{1}{2} \, \left( \textrm{tr}(\Sigma(X)) + \mu(X)^T\mu(X) - k - \log \, \det(\Sigma(X)) \right)</script><p>Above, $k$ is the dimension of our Gaussian. $tr(X)$ is trace function, i.e. sum of the diagonal of matrix $X$. The determinant of a diagonal matrix could be computed as product of its diagonal. So really, we could implement $Σ(X)$ as just a vector as it’s a diagonal matrix:</p><script type="math/tex; mode=display">\begin{align}D_{KL}[N(\mu(X), \Sigma(X)) \Vert N(0, 1)] &= \frac{1}{2} \, \left( \sum_k \Sigma(X) + \sum_k \mu^2(X) - \sum_k 1 - \log \, \prod_k \Sigma(X) \right) \\[10pt]                                      &= \frac{1}{2} \, \left( \sum_k \Sigma(X) + \sum_k \mu^2(X) - \sum_k 1 - \sum_k \log \Sigma(X) \right) \\[10pt]                                      &= \frac{1}{2} \, \sum_k \left( \Sigma(X) + \mu^2(X) - 1 - \log \Sigma(X) \right)\end{align} %]]></script><p>In practice, however, it’s better to model $Σ(X)$ as $logΣ(X)$, as it is more numerically stable to take exponent compared to computing <code>log</code>. Hence, our final KL divergence term is:</p><script type="math/tex; mode=display">D_{KL}[N(\mu(X), \Sigma(X)) \Vert N(0, 1)] = \frac{1}{2} \sum_k \left( \exp(\Sigma(X)) + \mu^2(X) - 1 - \Sigma(X) \right)</script><h2 id="使用Keras实现VAE"><a href="#使用Keras实现VAE" class="headerlink" title="使用Keras实现VAE"></a>使用Keras实现VAE</h2><p>First, let’s implement the encoder net $Q(z|X)$, which takes input $X$ and outputting two things: $μ(X)$ and $ Σ(X)$, the parameters of the Gaussian.</p><pre class=" language-lang-python"><code class="language-lang-python">from tensorflow.examples.tutorials.mnist import input_datafrom keras.layers import Input, Dense, Lamdafrom keras.models import Modelfrom keras.objectives import binary_crossentropyfrom keras.callbacks import LearningRateSchedulerimport numpy as npimport matplotlib.pyplot as pltimport keras.backend as Kimport tensorflow as tfm = 50n_z = 2n_epoch =10# Q(z|X) -- encoder inputs = Input(shape=(784,))h_q = Dense(512, activation='relu')(inputs)mu = Dense(n_z, activation='linear')(h_q)log_sigma = Dense(n_z, activation='linear')(h_q)</code></pre><p>That is, our $Q(z|X)$ is a neural net with one hidden layer. In this implementation, our latent variable is two dimensional, so that we could easily visualize it. In practice though, more dimension in latent variable should be better.</p><p>However, we are now facing a problem. How do we get $z$ from the encoder outputs? Obviously we could sample $z$ from a Gaussian which parameters are the outputs of the encoder. Alas, sampling directly won’t do, if we want to train VAE with gradient descent as the sampling operation doesn’t have gradient!</p><p>There is, however a trick called <strong>reparameterization</strong>(重新参数化) trick, which makes the network differentiable. Reparameterization trick basically divert the non-differentiable operation out of the network, so that, even though we still involve a thing that is non-differentiable, at least it is out of the network, hence the network could still be trained.</p><p>The reparameterization trick is as follows. Recall, if we have $x∼N(μ,Σ)$ and then standardize it so that $ μ=0,Σ=1$, we could revert it back to the original distribution by reverting the standardization process. Hence, we have this equation:</p><script type="math/tex; mode=display">x = \mu + \Sigma^{\frac{1}{2}} x_{std}</script><p>With that in mind, we could extend it. If we sample from a standard normal distribution, we could convert it to any Gaussian we want if we know the mean and the variance. Hence we could implement our sampling operation of $z$ by:</p><script type="math/tex; mode=display">z = \mu(X) + \Sigma^{\frac{1}{2}}(X) \, \epsilon</script><p>where $ϵ∼N(0,1)$.</p><p>Now, during backpropagation, we don’t care anymore with the sampling process, as it is now outside of the network, i.e. doesn’t depend on anything in the net, hence the gradient won’t flow through it.</p><pre class=" language-lang-python"><code class="language-lang-python">def sample_z(args):    mu, log_sigma = args    eps = K.random_normal(shape=(m, n_z), mean=0., std=1.)    return mu + K.exp(log_sigma / 2) * eps# Sample z ~ Q(z|X) z = Lambda(sample_z)([mu, log_sigma])</code></pre><p>Now we create the decoder net $P(X|z)$:</p><pre class=" language-lang-python"><code class="language-lang-python"># P(X|z) -- decoder decoder_hidden = Dense(512, activation='relu')decoder_out = Dense(784, activation='sigmoid')h_p = decoder_hidden(z)outputs = decoder_out(h_p)</code></pre><p>Lastly, from this model, we can do three things: reconstruct inputs, encode inputs into latent variables, and generate data from latent variable. So, we have three Keras models:</p><pre class=" language-lang-python"><code class="language-lang-python"># Overall VAE model, for reconstruction and training vae = Model(inputs, outputs)# Encoder model, to encode input into latent variable # We use the mean as the output as it is the center point, the representative of the gaussian encoder = Model(inputs, mu)# Generator model, generate new data given latent variable z d_in = Input(shape=(n_z,))d_h = decoder_hidden(d_in)d_out = decoder_out(d_h)decoder = Model(d_in, d_out)</code></pre><p>Then, we need to translate our loss into Keras code:</p><pre class=" language-lang-python"><code class="language-lang-python">def vae_loss(y_true, y_pred):    """ Calculate loss = reconstruction loss + KL loss for each data in minibatch """    # E[log P(X|z)]         recon = K.sum(K.binary_crossentropy(y_pred, y_true), axis=1)    # D_KL(Q(z|X) || P(z|X)); calculate in closed form as both dist. are Gaussian         kl = 0.5 * K.sum(K.exp(log_sigma) + K.square(mu) - 1. - log_sigma, axis=1)    return recon + kl</code></pre><p>and then train it:</p><pre class=" language-lang-python"><code class="language-lang-python">vae.compile(optimizer='adam', loss=vae_loss)vae.fit(X_train, X_train, batch_size=m, nb_epoch=n_epoch)</code></pre><p>And that’s it, the implementation of VAE in Keras!</p><h2 id="MNIST数据集实践"><a href="#MNIST数据集实践" class="headerlink" title="MNIST数据集实践"></a>MNIST数据集实践</h2><p>We could use any dataset really, but like always, we will use MNIST as an example.</p><p>After we trained our VAE model, we then could visualize the latent variable space $Q(z|X)$:</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E5%8A%A8%E7%BC%96%E7%A0%81%E5%99%A8%E8%83%8C%E5%90%8E%E7%9A%84%E7%9B%B4%E8%A7%89%E4%B8%8E%E5%AE%9E%E7%8E%B0%20/z_dist.png" alt="img"></p><p>As we could see, in the latent space, the representation of our data that have the same characteristic, e.g. same label, are close to each other. Notice that in the training phase, we never provide any information regarding the data.</p><p>We could also look at the data reconstruction by running through the data into overall VAE net:</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E5%8A%A8%E7%BC%96%E7%A0%81%E5%99%A8%E8%83%8C%E5%90%8E%E7%9A%84%E7%9B%B4%E8%A7%89%E4%B8%8E%E5%AE%9E%E7%8E%B0%20/reconstruction.png" alt="img"></p><p>Lastly, we could generate new sample by first sample $z∼N(0,1)$ and feed it into our decoder net:</p><p><img src="VAE%20-%20%E5%8F%98%E5%88%86%E8%87%AA%E5%8A%A8%E7%BC%96%E7%A0%81%E5%99%A8%E8%83%8C%E5%90%8E%E7%9A%84%E7%9B%B4%E8%A7%89%E4%B8%8E%E5%AE%9E%E7%8E%B0%20/generation.png" alt="img"></p><p>If we look closely on the reconstructed and generated data, we would notice that some of the data are ambiguous. For example the digit 5 looks like 3 or 8. That’s because our latent variable space is a continous distribution (i.e. $N(0,1)$), hence there bound to be some smooth transition on the edge of the clusters. And also, the cluster of digits are close to each other if they are somewhat similar. That’s why in the latent space, 5 is close to 3.</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>In this post we looked at the intuition behind Variational Autoencoder (VAE), its formulation, and its implementation in Keras.</p><p>We also saw the difference between VAE and GAN, the two most popular generative models nowadays.</p><p>For more math on VAE, be sure to hit the original paper by Kingma et al., 2014. There is also an excellent tutorial on VAE by Carl Doersch. Check out the references section below.</p><p>The full code is available in my repo: <a href="https://github.com/wiseodd/generative-models" target="_blank" rel="noopener">https://github.com/wiseodd/generative-models</a></p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li>Doersch, Carl. “Tutorial on variational autoencoders.” arXiv preprint arXiv:1606.05908 (2016).</li><li>Kingma, Diederik P., and Max Welling. “Auto-encoding variational bayes.” arXiv preprint arXiv:1312.6114 (2013).</li><li><a href="https://blog.keras.io/building-autoencoders-in-keras.html" target="_blank" rel="noopener">https://blog.keras.io/building-autoencoders-in-keras.html</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>词嵌入</title>
      <link href="/ci-qian-ru/"/>
      <url>/ci-qian-ru/</url>
      
        <content type="html"><![CDATA[<h2 id="1-为何不采用-one-hot-向量"><a href="#1-为何不采用-one-hot-向量" class="headerlink" title="1. 为何不采用 one-hot 向量"></a>1. 为何不采用 one-hot 向量</h2><p>假设词典中不同词的数量（词典大小）为 <code>N</code>，每个词可以和从 <code>0</code> 到<code>N−1</code>的连续整数一一对应。这些与词对应的整数叫做<strong>词的索引</strong>。 假设一个词的索引为<code>i</code>，为了得到该词的 one-hot 向量表示，我们创建一个全 0 的长为 <code>N</code>的向量，并将其第 <code>i</code>位设成 <code>1</code>。这样一来，每个词就表示成了一个长度为 N的向量，可以直接被神经网络使用。</p><p>虽然 one-hot 词向量构造起来很容易，但通常并不是一个好选择。一个主要的原因是，<strong>one-hot 词向量无法准确表达不同词之间的相似度</strong>，例如我们常常使用的余弦相似度。对于向量 x,y∈Rd，它们的余弦相似度是它们之间夹角的余弦值。</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-cdb3732e0bbeeed9.webp" alt="img"></p><p>由于任何两个不同词的 one-hot 向量的余弦相似度都为 0，多个不同词之间的相似度难以通过 one-hot 向量准确地体现出来。</p><p><strong>Word2vec</strong> 工具的提出正是为了解决上面这个问题 [1]。<strong>它将每个词表示成一个定长的向量</strong>，并使得这些向量能较好地表达不同词之间的相似和类比关系。Word2vec 工具包含了两个模型：跳字模型（skip-gram）[2] 和连续词袋模型（continuous bag of words，简称 CBOW）[3]。接下来让我们分别介绍这两个模型以及它们的训练方法。</p><h2 id="2-跳字模型-skip-gram"><a href="#2-跳字模型-skip-gram" class="headerlink" title="2. 跳字模型(skip gram)"></a>2. 跳字模型(skip gram)</h2><h3 id="2-1-跳字模型介绍"><a href="#2-1-跳字模型介绍" class="headerlink" title="2.1 跳字模型介绍"></a>2.1 跳字模型介绍</h3><p>跳字模型假设基于某个词来生成它在文本序列周围的词。举个例子，假设文本序列是“the”、“man”、“loves”、“his”和“son”。以“loves”作为中心词，设背景窗口大小为 2。如图 10.1 所示，跳字模型所关心的是，给定中心词“loves”，生成与它距离不超过 2 个词的背景词“the”、“man”、“his”和“son”的条件概率，即</p><p>P(<code>the&quot;,</code>man”,<code>his&quot;,</code>son”∣``loves”)</p><p>假设给定中心词的情况下，背景词的生成是相互独立的，那么上式可以改写成</p><p>P(<code>the&quot;∣</code>loves”)⋅P(<code>man&quot;∣</code>loves”)⋅P(<code>his&quot;∣</code>loves”)⋅P(<code>son&quot;∣</code>loves”)</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-a3e4af76d81a84a4.webp" alt="img"></p><blockquote id="fn_ footnote"><sup> footnote</sup>. 跳字模型关心给定中心词生成背景词的条件概率<a href="#reffn_ footnote" title="Jump back to footnote [ footnote] in the text."> &#8617;</a></blockquote><p>在跳字模型中，每个词被表示成两个 d维向量用来计算条件概率。假设这个词在词典中索引为 i，当它为中心词时向量表示为 vi∈Rd，而为背景词时向量表示为 ui∈Rd。设中心词 wc在词典中索引为 c，背景词 wo在词典中索引为 o，给定中心词生成背景词的条件概率可以通过对向量内积做 softmax 运算而得到：</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-a907cb2e53de64c6.webp" alt="img"></p><p>其中词典索引集 V={0,1,…,|V|−1}。假设给定一个长度为 T的文本序列，设时间步 t的词为 w(t)。假设给定中心词的情况下背景词的生成相互独立，当背景窗口大小为 m时，跳字模型的似然函数即给定任一中心词生成所有背景词的概率</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-2052ced03e044dad.webp" alt="img"></p><p>这里小于 1 和大于 T的时间步可以忽略。</p><h3 id="2-2-跳字模型训练"><a href="#2-2-跳字模型训练" class="headerlink" title="2.2 跳字模型训练"></a>2.2 跳字模型训练</h3><p>跳字模型的参数是每个词所对应的中心词向量和背景词向量。训练中我们通过最大化似然函数来学习模型参数，即最大似然估计。这等价于最小化以下损失函数：</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-4f7cb4944c503930.webp" alt="img"></p><p>如果使用随机梯度下降，那么在每一次迭代里我们随机采样一个较短的子序列来计算有关该子序列的损失，然后计算梯度来更新模型参数。梯度计算的关键是对数条件概率有关中心词向量和背景词向量的梯度。根据定义，首先看到</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-b27041346b051d61.webp" alt="img"></p><p>通过微分，我们可以得到上式中 vc的梯度</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-753bb313a7e509a0.webp" alt="img"></p><p>它的计算需要词典中所有词以 wc为中心词的条件概率。有关其他词向量的梯度同理可得。</p><p>训练结束后，对于词典中的任一索引为 i的词，我们均得到该词作为中心词和背景词的两组词向量 vi和 ui。在自然语言处理应用中，一般使用跳字模型的中心词向量作为词的表征向量。</p><h2 id="3-连续词袋模型"><a href="#3-连续词袋模型" class="headerlink" title="3 连续词袋模型"></a>3 连续词袋模型</h2><h3 id="3-1-连续词袋模型训练"><a href="#3-1-连续词袋模型训练" class="headerlink" title="3.1 连续词袋模型训练"></a>3.1 连续词袋模型训练</h3><p>连续词袋模型与跳字模型类似。与跳字模型最大的不同在于，连续词袋模型假设基于某中心词在文本序列前后的背景词来生成该中心词。在同样的文本序列“the”、 “man”、“loves”、“his”和“son”里，以“loves”作为中心词，且背景窗口大小为 2 时，连续词袋模型关心的是，给定背景词“the”、“man”、“his”和“son”生成中心词“loves”的条件概率（如图 10.2 所示），也就是</p><p>P(<code>loves&quot;∣</code>the”,<code>man&quot;,</code>his”,``son”)</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-1b0f798de6d8259c.webp" alt="img"></p><p>因为连续词袋模型的背景词有多个，我们将这些背景词向量取平均，然后使用和跳字模型一样的方法来计算条件概率。设 vi∈Rd和 ui∈Rd分别表示词典中索引为 i的词作为背景词和中心词的向量（注意符号和跳字模型中是相反的）。设中心词 wc在词典中索引为 c，背景词 wo1,…,wo2m在词典中索引为 o1,…,o2m，那么给定背景词生成中心词的条件概率</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-da3b99673087cc2d.webp" alt="img"></p><p>给定一个长度为 T的文本序列，设时间步 t的词为 w(t)，背景窗口大小为 m。连续词袋模型的似然函数为由背景词生成任一中心词的概率</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-e5c7e9069b39dd92.webp" alt="img"></p><h3 id="3-2-连续词袋模型训练"><a href="#3-2-连续词袋模型训练" class="headerlink" title="3.2 连续词袋模型训练"></a>3.2 连续词袋模型训练</h3><p>连续词袋模型训练同跳字模型训练基本一致。连续词袋模型的最大似然估计等价于最小化损失函数</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-98b86334af8c0d74.webp" alt="img"></p><p>注意到</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-35d91654a81ee286.webp" alt="img"></p><p>通过微分，我们可以计算出上式中条件概率的对数有关任一背景词向量 voi（i=1,…,2m）的梯度</p><p><img src="%E8%AF%8D%E5%B5%8C%E5%85%A5/10947003-beed3548ece6302e.webp" alt="img"></p><p>有关其他词向量的梯度同理可得。同跳字模型不一样的一点在于，我们一般使用连续词袋模型的背景词向量作为词的表征向量。</p><h2 id="4-word2vec实现"><a href="#4-word2vec实现" class="headerlink" title="4. word2vec实现"></a>4. word2vec实现</h2><h3 id="4-1-python-gensim"><a href="#4-1-python-gensim" class="headerlink" title="4.1 python-gensim"></a>4.1 python-gensim</h3><pre class=" language-lang-python"><code class="language-lang-python">from gensim.models import word2vec  sentences = word2vec.Text8Corpus("C:/traindataw2v.txt")  # 加载语料  model = word2vec.Word2Vec(sentences, size=200)  # 训练skip-gram模型; 默认window=5  #获取“学习”的词向量  print("学习：" + model["学习"])  # 计算两个词的相似度/相关程度  y1 = model.similarity("不错", "好")  # 计算某个词的相关词列表  y2 = model.most_similar("书", topn=20)  # 20个最相关的  # 寻找对应关系  print("书-不错，质量-")  y3 = model.most_similar(['质量', '不错'], ['书'], topn=3)  # 寻找不合群的词  y4 = model.doesnt_match("书 书籍 教材 很".split())  # 保存模型，以便重用  model.save("db.model")  # 对应的加载方式  model = word2vec.Word2Vec.load("db.model")</code></pre><p>默认参数如下：</p><pre class=" language-lang-python"><code class="language-lang-python">sentences=None  size=100  alpha=0.025  window=5  min_count=5  max_vocab_size=None  sample=1e-3  seed=1  workers=3  min_alpha=0.0001  sg=0  hs=0  negative=5  cbow_mean=1  hashfxn=hash  iter=5  null_word=0  trim_rule=None  sorted_vocab=1  batch_words=MAX_WORDS_IN_BATCH</code></pre><p>各个参数的意义:</p><p>sentences：就是每一行每一行的句子，但是句子长度不要过大，简单的说就是上图的样子</p><p>sg：这个是训练时用的算法，当为0时采用的是CBOW算法，当为1时会采用skip-gram</p><p>size：这个是定义训练的向量的长度</p><p>window：是在一个句子中，当前词和预测词的最大距离</p><p>alpha：是学习率，是控制梯度下降算法的下降速度的</p><p>seed：用于随机数发生器。与初始化词向量有关</p><p>min_count： 字典截断.，词频少于min_count次数的单词会被丢弃掉</p><p>max_vocab_size：词向量构建期间的RAM限制。如果所有不重复单词个数超过这个值，则就消除掉其中最不频繁的一个,None表示没有限制</p><p>sample：高频词汇的随机负采样的配置阈值，默认为1e-3，范围是(0,1e-5)</p><p>workers：设置多线程训练模型，机器的核数越多，训练越快</p><p>hs：如果为1则会采用hierarchica·softmax策略，Hierarchical Softmax是一种对输出层进行优化的策略，输出层从原始模型的利用softmax计算概率值改为了利用Huffman树计算概率值。如果设置为0（默认值），则负采样策略会被使用</p><p>negative：如果大于0，那就会采用负采样，此时该值的大小就表示有多少个“noise words”会被使用，通常设置在（5-20），默认是5，如果该值设置成0，那就表示不采用负采样</p><p>cbow_mean：在采用cbow模型时，此值如果是0，就会使用上下文词向量的和，如果是1（默认值），就会采用均值</p><p>hashfxn：hash函数来初始化权重。默认使用python的hash函数</p><p>iter： 迭代次数，默认为5</p><p>trim_rule： 用于设置词汇表的整理规则，指定那些单词要留下，哪些要被删除。可以设置为None（min_count会被使用）或者一个接受(word, count, min_count)并返回utils.RULE_DISCARD，utils.RULE_KEEP或者utils.RULE_DEFAULT，这个设置只会用在构建词典的时候，不会成为模型的一部分</p><p>sorted_vocab： 如果为1（defau·t），则在分配word index 的时候会先对单词基于频率降序排序。</p><p>batch_words：每一批传递给每个线程单词的数量，默认为10000，如果超过该值，则会被截断</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference:"></a>Reference:</h2><p>[1] Word2vec 工具。<a href="https://code.google.com/archive/p/word2vec/" target="_blank" rel="noopener">https://code.google.com/archive/p/word2vec/</a></p><p>[2] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., &amp; Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems (pp. 3111-3119).</p><p>[3] Mikolov, T., Chen, K., Corrado, G., &amp; Dean, J. (2013). Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</p><p>[4] <a href="https://zh.gluon.ai/chapter_natural-language-processing/word2vec.html" target="_blank" rel="noopener">词嵌入（word2vec）</a></p><p>[5] <a href="https://www.jianshu.com/p/972d0db609f2" target="_blank" rel="noopener">word2vec的几种实现</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>探幽深度生成模型的两种方法</title>
      <link href="/tan-you-shen-du-sheng-cheng-mo-xing-de-liang-chong-fang-fa-vae-he-gan/"/>
      <url>/tan-you-shen-du-sheng-cheng-mo-xing-de-liang-chong-fang-fa-vae-he-gan/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<a href="https://www.zybuluo.com/sambodhi/note/1040483" target="_blank" rel="noopener">https://www.zybuluo.com/sambodhi/note/1040483</a></p><hr><blockquote><p>近年来，深度生成模型（Deep Generative Models）取得了令人瞩目的成功。其中有两种强大的深度生成模型学习框架：变分自编码器（Variational Autoencoders，VAE）和生成对抗网络（Generative Adversarial Networks，GAN），这是两种不同的范式。VAE的好处是可以通过编码解码的步骤，直接比较重建图片和原始图片的差异，而这一点GAN做不到。VAE的劣势是没有使用对抗网络，因此会更趋向于产生模糊的图片。</p></blockquote><p>生成模型是一种利用无监督学习来学习任何类型的数据分布的强有力方法，它在短短几年内取得了巨大的成功。所有类型的生成模型都致力于学习训练集的真实数据分布，从而产生具有一些变化的新数据点。但我们并不总能够隐式或显式地了解我们数据的确切分布。因此，我们要试图建立一个与真实数据分布尽可能相似的分布建模。为此，我们可以利用神经网络的能力来学习一个函数，它可以将模型分布逼近真实分布。</p><p>最常用、最有效的两种方法是变分自编码器（Variational Autoencoders，VAE）和生成对抗网络（Generative Adversarial Networks，GAN）。VAE的目标是最大限度降低<strong>数据对数似然</strong>（log-likelihood）的下限，而GAN的目标是实现生成器（Generator）和判别器（Discriminator）之间的平衡。在本文中，作者将解释VAE和GAN的工作及它们背后的直觉。</p><h2 id="变分自编码器（Variational-Autoencoder）"><a href="#变分自编码器（Variational-Autoencoder）" class="headerlink" title="变分自编码器（Variational Autoencoder）"></a><strong>变分自编码器（Variational Autoencoder）</strong></h2><p>假设读者已经熟悉vanilla autoencoder的工作机制。我们知道，我们可以使用自编码器将输入图像编码为更小的维度表示，它可以存储关于输入数据分布的潜在信息。但是在一个vanilla autoencoder中，编码向量只能通过解码器映射到相应的输入。它当然不能用于生成具有可变性的相似图像。</p><blockquote><p> <strong>Vanilla</strong>是神经网络领域的常见词汇，比如Vanilla Neural Networks、Vanilla CNN等。Vanilla本意是香草，在这里基本等同于raw。比如Vanilla Neural Networks实际上就是BP神经网络，而Vanilla CNN实际上就是最原始的CNN。</p></blockquote><p>为了实现这一点，模型需要学习训练数据的概率分布。VAE是一种最流行的学习复杂数据分布的方法，它使用无监督的方式使用神经网络。这是一个基于贝叶斯推理（Bayesian inference）的概率图模型。该模型的目的是了解训练数据集数据的潜在概率的分布，以便能够很容易地从所学的分布中采样新的数据。我们的想法是学习一种被称为<strong>隐变量</strong>（latent variables）的训练数据的低维潜在表示（这些变量不是直接观察到的，而是通过数学模型推导出来的），我们假设这些变量产生了我们实际的训练数据。这些隐变量可以存储模型需要生成的输出类型的有用信息。隐变量$z$的概率分布用$P(z)$表示。选择高斯分布（Gaussian distribution）作为学习分布$P(z)$的先验，以便在推理时方便采样新的数据点。</p><p>现在主要目标是用一些参数对数据进行建模，这最大化了训练数据$X$的可能性。简而言之，我们假设一个低维的特征向量（latent vector）产生了我们的数据$x(x∈X)$，我们可以用一个确定函数$f(z;θ)$将这个特征向量映射到数据$x$上然后评估（见图1）。在这种生成过程中，我们的目标是最大化$X$中每个数据的概率，</p><p>$Pө(X) = ∫Pө(X, z)dz = ∫Pө(X|z)Pө(z)dz$                                                               (1)​</p><p>在这里，$f(z;θ)$已被分布$Pө(X|z)$取代了。</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3iv2yftuj20a408nglp.jpg" alt="img"></p><p>这个极大似然估计（maximum likelihood estimation）背后的直觉是，如果模型可以从这些隐变量产生训练样本，那么它也可以产生具有一些变化的相似样本。换句话说，如果我们从$P(z)$中抽取大量的隐变量，并从这些变量中生成$x$，则生成的$x$应与数据分布$P_{data}(x)$相匹配。现在我们有两个问题需要回答。如何捕捉隐变量的分布以及如何将方程1整合到$z$的所有维上？</p><p>显然，手动指定我们想要在特征向量中编码的相关信息以生成输出图像是一项繁琐的任务。相反，我们依靠神经网络来计算$z$，假设这个特征向量可以很好地近似为正态分布，以便在推理时很容易地进行采样。如果我们在$n$维空间中有$z$的正态分布，那么就可以用一个足够复杂的函数来生成任何类型的分布，并且可以使用此函数的逆来学习隐变量本身。</p><p>在方程1中，积分在z的所有维上进行，因此难以处理。但是，它可以使用蒙特卡罗积分（Monte-Carlo integration）方法来计算，这不容易实现。所以我们采用另一种方法来近似地最大化方程1中的$Pө(X)$ 。VAE的想法是使用我们不知道的$P(z|X)$来推断$P(z)$。我们使用一种称为<strong>变分推断</strong>（variational inference）的方法来推断$P(z|X)$，这种方法基本上是贝叶斯统计（Bayesian statistics）中的一个优化问题。我们首先用易于发现的简单分布$Q(z|X)$对$P(z|X)$进行建模，我们试着用KL散度度量（KL-divergence metric）方法来尽量减小$P(z|X)$和$Q(z|X)$之间的差异，从而使我们的假设接近真实的分布。接下来是大量的数学方程，笔者不再赘述，如你有兴趣可在原文中找到它。如果你有了VAE的直觉，这些方程就不难理解了。</p><p>VAE的最终目标是：</p><p><img src="/images/%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3ivp74d8j20kt01v3ye.jpg" alt="img"></p><p>上面的方程有一个非常好的解释。术语$Q(z|X)$基本上是我们的编码器网络，$z$是我们对数据$x(x∈X)$的编码表示，$P(X|z)$是我们的解码器网络。因此，在上面的方程中，我们的目标是在$ D_{KL}[Q(z|X)||P(z|X)] $，在某些误差下，极大似然估计数据分布。由于$P(z|X)$不易处理，但KL散度项≥0，因此很容易看出VAE试图最小化$log(P(X))$的下界。这和最大化$E[logP(X|z)]$和最小化$D_{KL}[Q(z|X)||P(z|X)]$是一样的。我们知道最大化$E[logP(X|z)]$是一个极大似然估计，并使用解码器网络进行建模。正如我前面说过的，我们希望我们的潜在表示接近于高斯函数，因此我们假设$P(z)$为$N(0,1)$。按照这个假设，$Q(z|X)$也应该接近这个分布。如果我们假设它是具有参数$μ(X)$和$Ʃ(X)$的高斯分布，则由KL散度给出的这两个分布（即$P(z)$和$Q(z|X)$）之间的差异导致的误差的封闭形式的解，解决方案如下：</p><p><img src="/images/%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3iw6bbyaj20ky02bt8o.jpg" alt="img"></p><p>我们优化了较低的变分边界，优化函数是：</p><p>$log(P(X|z))−D_{KL}[Q(z|X)‖P(z)]$，第二个解如上图所示。</p><p>因此，我们的损失函数将包含两项。第一个是输入到输出的<strong>重建损失</strong>，第二个损失是<strong>KL散度项</strong>。现在我们可以使用反向传播（Backpropagation）算法来训练网络。但是有一个问题，第一项不仅依赖于P的参数，也依赖于Q的参数，但是这个依赖性并没有出现在上面的方程中。所以我们如何从分布$Q(z|X)$或$N[μ(X), Ʃ(X)]$中随机穿过我们抽样的层z，以便P可以解码。渐变不能流过随机节点。我们使用<strong>重新参数化技巧</strong>（见图所示）使网络可微。我们从$N(μ(X), Σ(X))$中抽样$ε∼N(0,I)$，然后计算$z=μ(X)+Σ1/2(X)∗ε$。</p><p>图2中显示的非常完美。应该注意的是，前馈步骤对于这两个网络（左侧和右侧）都是相同的，但是渐变只能通过正确的网络进行反向传播。</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3iwngvudj20ic0b63z4.jpg" alt="img"></p><p>在推断时，我们可以简单地从$N(0,1)$中采样$z$并将其馈送到解码器网络以生成新的数据点。由于我们正在优化较低的变分边界，因此生成的图像的质量相对于像生成对抗网络（Generative Adversarial Networks，GAN）这样的最新技术来说是比较差的。</p><p>VAE最好的一点是它同时学习生成模型和推理模型。虽然VAE和GAN都是非常令人兴奋的方法，它们都可以使用无监督学习来学习基础数据分布，但与VAE相比，GAN能产生更好的结果。在VAE中，我们优化了较低的变分边界；而在GAN中，没有这样的假设。事实上，GAN并不处理任何显式的概率密度估计。VAE在生成清晰图像方面的失败意味着模型无法学习真实的后验分布。VAN和GAN主要在训练方式上有所不同。现在让我们进入生成对抗网络。</p><h2 id="生成对抗网络（Generative-Adversarial-Networks）"><a href="#生成对抗网络（Generative-Adversarial-Networks）" class="headerlink" title="生成对抗网络（Generative Adversarial Networks）"></a><strong>生成对抗网络（Generative Adversarial Networks）</strong></h2><p>Yann LeCun说，对抗训练是有史以来最酷的东西。我想大多数人都会同意他的观点，因为我们都看到了对抗网络的广为流行，以及它们所产生的的结果和质量。对抗训练完全改变了我们教会神经网络做特定任务的方式。生成对抗网络不使用任何显式的密度估计，如变分自编码器。相反，它是基于博弈论（game theory）的方法，目的是在两个网络，生成器和判别器之间的纳什均衡（Nash equilibrium）。这个想法是从一个简单的分布，比如高斯分布，然后学习利用通用函数逼近器（如神经网络）将噪声转化为数据分布。</p><p>这是通过这两个网络的对抗训练来实现的。生成器（Generator）模型G学习捕捉数据分布，判别器（Discriminator）模型D估计样本来自数据分布而非模型分布的概率。基本上，生成器的主要任务是生成自然的图像，而判别器的任务是判断图像是假的还是真实的。这可以认为是一款迷你max的双人游戏，随着时间的推移，两个网络的性能都会提高。在这个游戏中，生成器试图通过生成真实图像来欺骗判别器，并通过提高其识别能力来避免被判别器迷惑。下图显示了GAN的基本架构。</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3ix3jigbj20m80gfmxs.jpg" alt="img"></p><p>我们定义一个先验输入噪声变量P(z)，然后生成器将其映射到使用具有参数өg的复微分函数的数据分布。除此之外，我们还有另一个网络称为判别器，它接受输入x并使用另一个带参数的微分函数。输出表示x来自真实数据分布Pdata(x)的概率的单个标量值。GAN的目标函数被定义为：</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3jopefm2j20i801jaa2.jpg" alt="img"></p><p>在上面的方程中，如果判别器的输入来自真实的数据分布，那么D(x)应该输出1来最大化上述关于D的目标函数，如果图像是由生成器生成的，那么D(G(z))应该输出1，以使关于G的目标函数最小化。从本质上说，G应该生成这样的显示图像，它可以欺骗D。采用梯度上升法（Gradient Ascent）使有关判别器的参数最大化，采用梯度下降法（Gradient Descent）最小化有关生成器的参数。但是在优化生成器目标方面存在一个问题，在游戏开始时，生成器还没有学到任何东西时，梯度通常非常小，当运行良好时，梯度非常高（见图4）。但我们想要的是相反的行为。因此，我们将E[log(D(G(z))]最大化，而不是最小化E[log(1-D(G(z))]。</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3jp2qwnjj20ko09iwf0.jpg" alt="img"></p><p>训练过程包括随机梯度下降（Stochastic Gradient Descent）对判别器和生成器的同步应用。在训练过程中，我们交替优化D的k级步骤和小批量上优化G的一步。当判别器无法区分ρg和ρdata时，即D(x,өd)=½或者ρg=ρdata时，则停止训练过程。</p><p>GAN应用卷积神经网络最早的模型之一是DCGAN，它代表了深度卷积生成对抗网络（Deep Convolutional Generative Adversarial Networks，DCGAN）。该网络从均匀分布中提取的100个随机数作为输入，并输出所需形状的图像。该网络由许多卷积、反卷积和完全连通的层组成。网络使用许多反卷积层将输入噪声映射到所需的输出图像。批量标准化用于稳定网络的训练。除了使用tanh层和Leaky ReLU的输出层外，所有层都使用ReLU激活。该网络使用小批量随机梯度下降法进行训练，并使用Adam优化器来加速训练，对超参数进行优化。这篇论文的结果很有趣。作者指出，这些生成器具有又去的向量运算性质，可以用我们想要的方式来处理图像。</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3jphktgaj20lj09ogmo.jpg" alt="img"></p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3jpzkwdaj20el06y0ta.jpg" alt="img"></p><p>GAN使用最广泛的变体之一是有条件的GAN（conditional GAN，cGAN），它是通过简单地将条件向量与噪声向量一起添加而构成的（见图7）。在cGAN之前，我们从随机的噪声样本z中随机生成图像。如果我们想要生成具有某些所需特征的图像，有没有什么方法可以为模型提供额外的信息，无论我们想要生成什么样的图像？答案是肯定的，有条件的GAN是这样做的。通过对提供给生成器和判别器的附加信息调整模型，可以指导数据生成过程。有条件的GAN用于各种任务，如文本到图像的生成、图像到图像的转换、图像的自动标记等。下图显示了这两个网络的统一结构。</p><p><img src="%E6%8E%A2%E5%B9%BD%E6%B7%B1%E5%BA%A6%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%20-%20VAE%E5%92%8CGAN/7dcbe4ffly1fo3jq9swe9j20jr0ffwfm.jpg" alt="img"></p><p>GAN的一个很酷的地方就是，即使训练数据很小，也可以进行训练。确实，GAN的结果是有希望的，但训练过程并不简单，尤其是建立网络的超参数。此外，GAN很难进行优化，因为它们不容易收敛。当然，有一些技巧和窍门来破解GAN，但它们可能并非总是有用的。你可以访问<code>https://github.com/soumith/ganhacks</code>找到一些建议。另外，除了检查生成的图像是否看上去很真实之外，我们对结果的定量评价没有任何标准。</p><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a><strong>结论</strong></h2><p>深度学习模型在监督学习中确实达到了人类水平的表现，但在无监督学习中却不是这样。尽管如此，研究深度学习的科学家们正在努力改进无监督模型的性能。在这篇博文中，我们看到了两个最著名的无监督学习框架的生成模型是如何工作的。我们了解了变分自编码器的问题，以及为什么对抗网络能更好地生成逼真的图像。但是GAN也存在一些问题，比如稳定它们的训练，这仍然是一个活跃的研究领域。然而GAN非常强大，目前它们正被用于高质量图像（参见以下视频）和视频生成、文本到图像的转换、图像增强、图像中物体3D模型重建、音乐生成、发现抗癌药物等等。除此之外，许多深度学习研究人员也在努力统一这两种模型，并使这两种模型得到最好的结果。随着深度学习的不断提高，我相信GAN将会打开人工智能的封闭之门。在接下来的几年里，生成模型将对于图形设计、设计有吸引力的用户界面等非常有帮助。也可能会使用生成对抗网络来生成自然语言文本。</p><p>[1]: <em>Deep Generative Models\</em><br><a href="https://towardsdatascience.com/deep-generative-models-25ab2821afd3" target="_blank" rel="noopener">https://towardsdatascience.com/deep-generative-models-25ab2821afd3</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>从图嵌入算法到图神经网络</title>
      <link href="/cong-tu-qian-ru-suan-fa-dao-tu-shen-jing-wang-luo/"/>
      <url>/cong-tu-qian-ru-suan-fa-dao-tu-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<a href="https://blog.csdn.net/weixin_43269174/article/details/98492487" target="_blank" rel="noopener">https://blog.csdn.net/weixin_43269174/article/details/98492487</a></p><hr><p>一、引言<br>近几年来，伴随着计算机算力的急剧提升，神经网络从历史的尘埃中走出，横扫各大领域，完成一次次颠覆性的创新。依托高度弹性的参数结构，线性与非线性的矩阵变换，神经网络能适用于各式各样的数学场景，在各个类别的应用上我们都能看到神经网络的影子。其中著名的应用方向，包括自然语言处理、计算机视觉、机器学习、生物医疗、推荐系统、自动驾驶等等。图神经网络，广泛应用于社交关系、知识图谱、推荐系统、蛋白质分子建模，同样源自于对传统领域的创新，它的前身是图嵌入算法；而图嵌入算法又以图数据作为载体。这一关系，将贯穿本文始末，成为我们的展开线索。</p><p>二、图<br>在进入图嵌入算法前，本节将详细介绍该领域下的基础知识，包括各类图的概念以及路径相关算法。希望直入主题的读者可直接跳到下一节。</p><p>相关概念</p><h2 id="gt-图-Graph-是最基础的几种计算机-数据结构-之一，由若干个-节点-Node-or-Vertex-构成；节点与节点相连，构成-边-Edge-，代表了两者之间的依赖关系。根据图中边的方向，概念上可将图分为两种：有向图-Directed-Graph-or-Digraph-和-无向图-Undirected-Graph-or-Undigraph-，如下所示，左侧为无向图，右侧为有向图："><a href="#gt-图-Graph-是最基础的几种计算机-数据结构-之一，由若干个-节点-Node-or-Vertex-构成；节点与节点相连，构成-边-Edge-，代表了两者之间的依赖关系。根据图中边的方向，概念上可将图分为两种：有向图-Directed-Graph-or-Digraph-和-无向图-Undirected-Graph-or-Undigraph-，如下所示，左侧为无向图，右侧为有向图：" class="headerlink" title="&gt; 图 (Graph) 是最基础的几种计算机 数据结构 之一，由若干个 节点 (Node, or Vertex) 构成；节点与节点相连，构成 边 (Edge)，代表了两者之间的依赖关系。根据图中边的方向，概念上可将图分为两种：有向图 (Directed Graph, or Digraph) 和 无向图 (Undirected Graph, or Undigraph)，如下所示，左侧为无向图，右侧为有向图："></a>&gt; 图 (Graph) 是最基础的几种计算机 数据结构 之一，由若干个 节点 (Node, or Vertex) 构成；节点与节点相连，构成 边 (Edge)，代表了两者之间的依赖关系。根据图中边的方向，概念上可将图分为两种：有向图 (Directed Graph, or Digraph) 和 无向图 (Undirected Graph, or Undigraph)，如下所示，左侧为无向图，右侧为有向图：</h2><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2019080517150678.png" alt="在这里插入图片描述"></p><p>当边被赋予权重，则图可称为 <strong>权重图</strong> (Weighted Graph)：</p><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805171650651.png" alt="在这里插入图片描述"></p><p>一个形象的例子是城市地图，每一个交叉路口是一个节点，道路是一条边，而权重指的则是道路的长度。但如果我们希望用权重大小代表拥挤程度，在地图上看到每条道路的拥堵情况，那么一条边显然不足以满足我们的要求。这时就引申出了 <strong>多重图</strong> (Multigraph)：</p><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805171912926.png" alt="在这里插入图片描述"></p><p>概念上，多重图必然是有向图和权重图；但需要注意的是，多重图中两个节点之间的边，既可以单向，也可以双向，i.e. 节点 AAA 和 BBB 之间可以有两条或以上 A→BA\rightarrow BA→B 的边；两条或两条以上的单向边成为 平行边 (Parallel Edges)，而平行边的数量称为 重数 (Multiplicity)。</p><p>此外，还有一些其他类型图的定义，包括 混合图 (Mixed Graph)，指的是既包含无向边也包含有向边的图；连通图 (Connected Graph)，指的是任意两个节点都有路径 (一个或多个边相连) 相连的无向图；强连通图 (Strongly-connected Graph)，指的是任意两个节点都有路径相连的有向图；循环图 (Cyclic Graph)，指的是存在首尾相连的路径，可以串起所有节点的图；以及最后的 完全图 (Complete Graph)，指的是所有节点之间都有边相连的无向图。</p><p>清楚这些图的概念，是我们理解算法、熟悉算法应用场景的前提。</p><p>路径相关算法<br>伴随着图一起诞生的，是与路径相关的算法，其中部分算法可以帮助我们从图中提取更多的特征信息融入到节点中，从而丰富图的架构，在图嵌入或图神经网络算法中达到更好的效果。</p><ul><li>拓扑排序 (Topological Sorting)：<br><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805175452934.png" alt="在这里插入图片描述"></li></ul><p>应用于有向非循环图，是对图中的所有节点 ViV_iV<br>i</p><p>  (i=1,…,n)(i=1,…,n)(i=1,…,n) 进行统一排序，使得对于任意边 (Va→Vb)(V_a\rightarrow V_b)(V<br>a</p><p> →V<br>b</p><p> )，满足 a&lt;ba&lt;ba&lt;b。经过拓扑排序的图，能加速目标检索的效率，同时能够快速获取两个节点间的上下游位置，应用场景包括学位课程之间的先修关系、面对对象程序类之间的继承，以及工程项目之间的调度等。需要注意的是，一个有向非循环图可能存在不止一种拓扑排序的结果。算法原理在于通过迭代，将无入度的节点从原图中抽出放入排序序列中，直至所有节点全部抽出。</p><ul><li>深度优先搜索 (DFS, abbr. Depth-First Searching)：<br><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2019080517580351.png" alt="在这里插入图片描述"></li></ul><p>通过遍历检测两个节点是否连通，或检测一个图是否为连通图。其过程类似于牵着绳子走入迷宫，每一个拐角是一个节点，当走到死角时，记录来过这里，沿着绳子的路线返回寻找下一个拐角；这将用到两个栈，分别记录走访过的节点，以及绳子沿路的拐角。实际应用中，全程只用一根绳子无疑是低效的，因此常常引入递归的思想，每到一个拐点切出多个绳头分头搜索。</p><ul><li><strong>广度优先搜索</strong> (BFS, abbr. Breadth-First Searching)：<br><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805180358782.png" alt="在这里插入图片描述"></li></ul><p>依据从源点出发，路径上的节点数量，将全图分为不同的层级，逐层向下检查。相对于深度优先搜索，广度优先搜索能够保证在边的数量上两个节点间检索到的路径最短。</p><ul><li><p><strong>Dijkstra 算法</strong>：<br><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805185252730.png" alt="在这里插入图片描述"></p><p>算法思想在于从源点出发，构建一个逐步扩张的“云”，每次迭代将云外离源点最近的节点拉入到云内来，使云逐渐遍布全图，从而检索到两个节点间的最短路径。时间复杂度为 O(n2)O(n^2)O(n<br>2<br> )，是贪心算法应用在路径问题上的绝佳案例。</p></li><li><p><strong>Floyd-Warshall 算法</strong>：<br><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805184921399.png" alt="在这里插入图片描述"></p></li></ul><p>假如我们不希望每次检索两个节点是否连通，或计算最短路径时，都从头开始遍历，可以使用该算法生成 传递闭包 (Transitive Closure)，以加速后续检索，一劳永逸。该算法的原理在于每次迭代时，将所有满足连通要求的 Vk−1→Vk→Vk+1V_{k-1}\rightarrow V_k\rightarrow V_{k+1}V<br>k−1</p><p> →V<br>k</p><p> →V<br>k+1</p><p>  的 Vk−1V_{k-1}V<br>k−1</p><p>  和 Vk+1V_{k+1}V<br>k+1</p><p>  单独建立联系，构建新的边 Vk−1→Vk+1V_{k-1}\rightarrow V_{k+1}V<br>k−1</p><p> →V<br>k+1</p><p> 。如此一来，多次迭代过后，所有可连通的节点对 (VaV_aV<br>a</p><p> ,VbV_bV<br>b</p><p> ) 都将拥有直接关系。需要注意的是，该算法的时间复杂度为 O(kn3)O(kn^3)O(kn<br>3<br> )，kkk 为迭代次数，为保证所有可达节点配对存在直接相连的边，算法的运算消耗最高可接近 O(n4)O(n^4)O(n<br>4<br> )。显而易见，当节点的数量 nnn 逐渐增加时，算法运行的时间消耗将呈灾难性地增加。</p><ul><li><strong>Prim-Jarnik 算法</strong>：<br><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805190412487.png" alt="在这里插入图片描述" style="zoom:33%;" /></li></ul><p>归属于 最小生成树 (MST, abbr. Minimum-Spanning-Tree) 一类的算法，旨在求解连通所有节点的最短路径。由 Dijkstra 算法调整而来，以所有零入度节点作为云的初始状态，不断找寻离云内节点最近的邻点拉入到云内来，以此迭代，直至所有节点访问完毕。如果不存在零入度点，则随机挑选一个加入到云中。</p><h1 id="三、图嵌入算法"><a href="#三、图嵌入算法" class="headerlink" title="三、图嵌入算法"></a>三、图嵌入算法</h1><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190805200423616.png" alt="在这里插入图片描述"></p><p>abbr. Graph Embedding Algorithms，目的在于学习图的结构或节点之间的邻接关系，对节点进行编码 (或对固有特征进行降维)，将所有节点映射为等维度的向量，使其能够方便地应用于下游的聚类、分类、关联分析或可视化任务。因此，在实际应用中，图嵌入属于预处理工作，绝大多数图嵌入算法皆为无监督学习算法。</p><p>常见概念</p><ul><li>图 (Graph)：$G(V,E)$</li><li><p>节点 (Node, or Vertex)：$V={v1,…,vn}$，包含全部节点<br>度 (Degree)：D={deg1,…,degn}，包含每个节点的入度数量<br>边 (Edge)：$E=\{e_{ij}\}_{i,j=1}^n$，包含所有的边；如果边是双向的，则分别表达为两条，e.g. $v_i\leftrightarrow v_j$</p><p>  关系将对应$e_{ij}$与$e_{ji}$ ；如果边$v_i\rightarrow v_j$不存在，则不会出现在 EEE 里面<br>邻点 (Neighbors)：N(vi)\mathcal{N}(v_i)N(v<br>i</p><p> )，包含节点 viv_iv<br>i</p><p>  的所有邻点<br>邻接矩阵 (Adjacency Matrix)：A={wij∣wij≥0}ni,j=1∈Rn×nA=\{w_{ij}|w_{ij}\ge 0\}_{i,j=1}^n\in\mathbb{R}^{n\times n}A={w<br>ij</p><p> ∣w<br>ij</p><p> ≥0}<br>i,j=1<br>n</p><p> ∈R<br>n×n<br> ，记录图中边的权重信息；对于无向图，wij=wjiw_{ij}=w_{ji}w<br>ij</p><p> =w<br>ji</p><p> ；要求所有的边权重不得小于 0；对于不相邻的节点，wij=wji=0w_{ij}=w_{ji}=0w<br>ij</p><p> =w<br>ji</p><p> =0<br>一阶相似度 (First-order Proximity)：边的权重 wijw_{ij}w<br>ij</p><p> ，代表两个节点的直接依赖关系<br>二阶相似度 (Second-order Proximity)：对于节点 viv_iv<br>i</p><p>  和 vjv_jv<br>j</p><p> ，从邻接矩阵分别获取相应的一阶相似性 wi=[wi1,…,win]\mathrm{w_i}=[w_{i1},…,w_{in}]w<br>i</p><p> =[w<br>i1</p><p> ,…,w<br>in</p><p> ]，sj=[wj1,…,wjn]\mathrm{s_j}=[w_{j1},…,w_{jn}]s<br>j</p><p> =[w<br>j1</p><p> ,…,w<br>jn</p><p> ]；wi\mathrm{w_i}w<br>i</p><p>  与 wj\mathrm{w_j}w<br>j</p><p>  的相似度即为二阶相似度，代表两个节点的邻居相似性</p></li><li>图嵌入 (Graph Embedding)：映射关系$ f:vi→zi∈R^d,∀i∈[1,n]$, $d$ 为超参数，决定最终的编码长度</li><li>特征表示 (Feature Representation)：$Xi∈R^{d0}$    ，对节点 $v_i$ 的固有特征 (不包含边及其他节点信息) 进行简单编码后形成的向量，因此又称为特征向量。</li></ul><h3 id="演变历程"><a href="#演变历程" class="headerlink" title="演变历程"></a>演变历程</h3><p>图嵌入算法初步诞生于 21 世纪初，彼时的模型将更多的焦点放在降维上，嵌入的同时使得相邻的节点在最终的向量空间上更为接近，代表性的包括 Locally Linear Embedding (2000) 和 Laplacian Eigenmaps (2001) ，这一类算法充分利用所有的样本间权重，时间复杂度通常较高，最高可达 O(n2)O(n^2)O(n<br>2<br> )，因此并不适合大规模图数据。2010 年以后，新诞生的图嵌入算法逐渐在时间复杂度上得到优化，转而应对现实生活中广泛存在的特征稀疏性问题，这其中的翘楚便是 Graph Factorization (2013)，该算法旨在于邻接矩阵以及正则项之间寻求一个平衡点，使得生成的向量保留邻接矩阵的绝大多数信息；LINE (2015) 将该思想延续下去，并努力在嵌入向量中维持节点的一阶和二阶相似度；HOPE (2016) 更是引入了更高阶的相似度矩阵，通过广义奇异值分解保留高阶相似性。以上所有算法皆可归类于矩阵分解，又称为因子分解，其中心思想在于生成相似度矩阵，通过数学方法将矩阵中包含的邻接信息融入节点向量中。</p><p>另一个知名的流派是基于随机游走，以 DeepWalk (2014) 和 node2vec (2016) 作为代表。前者在节点的上下游随机走动，生成长度为 2k+12k+12k+1 的等长序列，作为节点的邻接特征导入 skip-gram 模型训练；后者在前者的基础上对随机游走在 DFS 和 BFS 的方向上施加权重，使生成的序列更为真实地体现节点的结构信息。</p><p>在这之后，图嵌入算法逐渐过渡到神经网络时代，涌现出一大批优质的图神经网络模型，包括 SDNE (2016) 与 GraphSAGE (2017) 等等，在工业界大放异彩。从此，基于神经网络的图嵌入算法不再仅仅局限于节点的邻接信息，而开始将节点本身的特征纳入模型考量，并逐渐从静态的直推式 (transductive) 学习向动态的归纳式 (inductive) 学习演变，无论是拟合能力还是泛化能力，都大大提升；部分图神经网络直接针对下游任务进行建模，已不再属于图嵌入的范畴。依据 Wu et. al (2019) 的定义，图神经网络可分为五大类：</p><p>图卷积网络 (Graph Convolution Networks)：简称为 GCN，是目前最主流的图神经网络算法，其余四种图神经网络皆由 GCN 演化而来。依据建模过程中是否应用到傅里叶变换，可将其分为基于谱 (Spectral-based) 和基于空间 (Spatial-based) 两个流派。<br>图注意力网络 (Graph Attention Networks)：引入注意力机制，将图网络整合为端到端的模型；具体的做法，是在 GCN 的聚合函数中加入可训练的权重参数，使得训练后的模型将更多的重心放在关键的邻点上。<br>图自编码器 (Graph Auto-encoders)：由一个编码器 (encoder) 和一个解码器 (decorder) 构成；在应对无固有特征的图时，编码器对邻接矩阵进行一定的预处理，包括融入更丰富的邻接信息 (e.g. 高阶相似度) 或是将邻接矩阵输入一套神经网络；在应对包含固有特征的图时，则直接使用 GCN 作为编码器对邻接矩阵进行编码；解码器对编码结果进行后续处理获得一阶及二阶相似度，通过计算损失函数对模型参数进行更新。<br>图生成网络 (Graph Generative Networks)：2018 年以后出现的新的研究方向，目的是在图的节点和边经验分布的基础上，生成新的图，进行对抗式训练。<br>图时空网络 (Graph Spatial-Temporal Network)：旨在于时空图中学习模式 (pattern)，应用在分类或是对未来特征的预测。<br>GNNPapers 详细列示了图神经网络诞生以来里程碑式的优秀模型，以及其在具体场景中的应用。</p><hr><h1 id="四、图卷积网络"><a href="#四、图卷积网络" class="headerlink" title="四、图卷积网络"></a>四、图卷积网络</h1><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190806163559729.png" alt="在这里插入图片描述"></p><p>abbr. Graph Convolution Networks。在节点嵌入这一下游任务上，基于空间的 GCNs 从彼时大热的卷积神经网络中汲取思想，直接在原图的拓扑序列上进行卷积操作；而考虑到图结构的不稳定性，基于谱的 GCNs 则将所有节点映射到傅里叶域后进行卷积乘积，再经由傅里叶逆变换得到空间域下的嵌入向量。以下是 Wu et. al (2019) 对近年来图卷积网络的总结：</p><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190811165703970.png" alt="在这里插入图片描述"></p><h3 id="GNN-The-Graph-Neural-Network-Model-2009"><a href="#GNN-The-Graph-Neural-Network-Model-2009" class="headerlink" title="GNN: The Graph Neural Network Model (2009)"></a>GNN: The Graph Neural Network Model (2009)</h3><blockquote><p>论文地址：<a href="https://ieeexplore.ieee.org/document/4700287" target="_blank" rel="noopener">https://ieeexplore.ieee.org/document/4700287</a></p></blockquote><p>这篇论文首次提出图神经网络 (Graph Neural Network) 的概念，并将模型设计为有目的的监督学习模型，分为 转换 (Transition) 和 输出 (Output) 两个部分。转换部分为每一个节点提取邻点信息，生成向量表示的 状态 (state)；输出则将该状态映射至等维的向量表示，通过 softmax 归一化进行多分类预测。相关公式如下：</p><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190811170553982.png" alt="在这里插入图片描述"></p><p>其中 $f$ 和 $g$ 皆为可训练的全连接层，$l_n$为节点的标签 (可以理解为特征)，$l_{co}$ 为与节点相接的边的标签 (即我们常谈的权重)，$x_{ne}$ 代表邻点转换过后的状态 (向量)，$l_{ne}$为邻点的标签 (特征)。由于转换部分的输入 $x_n$包含了该部分邻点的输出，因而需要通过交互性的多轮迭代实现训练和推理，论文中将其称呼为 扩散机制 (Diffusion Mechanism)：</p><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190811172629419.png" alt="在这里插入图片描述"></p><p>相关的数学定理 Banach’s Theorm 证实，经过扩散机制后，对于满足$∣∣f w(x,l)−f w(y,l)∣∣≤μ∣∣x−y∣∣,0≤μ&lt;1$ 的 $w$，有仅有唯一的解。因而在训练完成后，我们可以提取 $f_w(x,l)$ 作为节点的嵌入表示。</p><p>该模型除了可用于节点级别的分类，同样可用于图的级别，只需要为每张输入的图添加一个代表全局的特殊节点即可。由于模型应用到了在节点级别进行邻点采样作为输入的思想，与后来的图卷积神经网络不谋而合，论文作者虽没有自行提出卷积的概念，但本篇论文后来被认为是第一个图卷积网络的提出者。模型采用顺时针的方式为每个节点提取固定长度的邻点列表，对相对位置上空缺的邻点采取统一的无意义填充策略；这样的做法将算法的应用场景限制在了 2D 空间，且需要使用者进行更为繁琐的数据预处理，因而成为饱受诟病的之处，也为后续优化指引了方向。</p><h3 id="GraphSAGE-Inductive-Representation-Learning-on-Large-Graphs-2017"><a href="#GraphSAGE-Inductive-Representation-Learning-on-Large-Graphs-2017" class="headerlink" title="GraphSAGE: Inductive Representation Learning on Large Graphs (2017)"></a>GraphSAGE: Inductive Representation Learning on Large Graphs (2017)</h3><blockquote><p>论文链接：<a href="https://arxiv.org/abs/1706.02216" target="_blank" rel="noopener">https://arxiv.org/abs/1706.02216</a></p></blockquote><p>初代 GNN 中邻点采样的思想一直保留了下来，但 GraphSAGE 并不将采样信息局限在节点的拓扑结构里，而是使用节点的固有特征取而代之，对造成庞大参数量的扩散机制也选择了摒弃处理。根据下游任务的不同，GraphSAGE 采用不同的训练策略：应用于图嵌入时，使用负采样技术计算二阶相似度实现参数收敛；应用于分类任务时，使用 softmax 进行有监督学习。其中，无监督学习的表达式如下：</p><p> $\mathcal{J}_{\mathcal{G}}(z_u)=-\log \big(\sigma(z_u^Tz_v)\big)-Q\cdot \mathbb{E}_{v_n\sim P_n(v)}\log\big(\sigma(-z_u^Tz_{v_n})\big)$</p><p>模型的特别之处，在于每一次迭代时，都重新对邻点进行采样，前馈公式如下：</p><p>$h_v^k=\sigma\big(W^k\cdot \text{Concat}(h_v^{k-1},h_{\mathcal{N}(v)}^k)\big) $</p><p>$h_{\mathcal{N}(v)}^k=\text{Aggregate}(\{h_u^{k-1},\forall u\in\mathcal{N}(v) \})$</p><p>其中$k=1,…,K$ 为迭代次数；$h_v^kh$ 为前馈层输出的隐藏向量，无监督学习使用最后一层计算损失函数。</p><p><img src="%E4%BB%8E%E5%9B%BE%E5%B5%8C%E5%85%A5%E7%AE%97%E6%B3%95%E5%88%B0%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/20190812004554131.png" alt="在这里插入图片描述"></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>零基础入门深度学习-递归神经网络</title>
      <link href="/ling-ji-chu-ru-men-shen-du-xue-xi-7-di-gui-shen-jing-wang-luo/"/>
      <url>/ling-ji-chu-ru-men-shen-du-xue-xi-7-di-gui-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<p>参考链接：<a href="https://www.zybuluo.com/hanbingtao/note/626300" target="_blank" rel="noopener">https://www.zybuluo.com/hanbingtao/note/626300</a></p><hr><h2 id="往期回顾"><a href="#往期回顾" class="headerlink" title="往期回顾"></a>往期回顾</h2><p>在前面的文章中，我们介绍了<strong>循环神经网络</strong>，它可以用来处理包含序列结构的信息。然而，除此之外，信息往往还存在着诸如树结构、图结构等更复杂的结构。对于这种复杂的结构，<strong>循环神经网络</strong>就无能为力了。本文介绍一种更为强大、复杂的神经网络：<strong>递归神经网络 (Recursive Neural Network, RNN)</strong>，以及它的训练算法<strong>BPTS (Back Propagation Through Structure)</strong>。顾名思义，<strong>递归神经网络</strong>（巧合的是，它的缩写和<strong>循环神经网络</strong>一样，也是RNN）可以处理诸如树、图这样的<strong>递归结构</strong>。在文章的最后，我们将实现一个<strong>递归神经网络</strong>，并介绍它的几个应用场景。</p><h2 id="递归神经网络是啥"><a href="#递归神经网络是啥" class="headerlink" title="递归神经网络是啥"></a>递归神经网络是啥</h2><p>因为神经网络的输入层单元个数是固定的，因此必须用循环或者递归的方式来处理长度可变的输入。<strong>循环神经网络</strong>实现了前者，通过将长度不定的输入分割为等长度的小块，然后再依次的输入到网络中，从而实现了神经网络对变长输入的处理。一个典型的例子是，当我们处理一句话的时候，我们可以把一句话看作是词组成的序列，然后，每次向<strong>循环神经网络</strong>输入一个词，如此循环直至整句话输入完毕，<strong>循环神经网络</strong>将产生对应的输出。如此，我们就能处理任意长度的句子了。入下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-a87286a58fc03563.png)</p><p>然而，有时候把句子看做是词的序列是不够的，比如下面这句话『两个外语学院的学生』：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-1d69d9ea35f55af0.png)</p><p>上图显示了这句话的两个不同的语法解析树。可以看出来这句话有歧义，不同的语法解析树则对应了不同的意思。一个是『两个外语学院的/学生』，也就是学生可能有许多，但他们来自于两所外语学校；另一个是『两个/外语学院的学生』，也就是只有两个学生，他们是外语学院的。为了能够让模型区分出两个不同的意思，我们的模型必须能够按照树结构去处理信息，而不是序列，这就是<strong>递归神经网络</strong>的作用。当面对按照树/图结构处理信息更有效的任务时，<strong>递归神经网络</strong>通常都会获得不错的结果。</p><p><strong>递归神经网络</strong>可以把一个树/图结构信息编码为一个向量，也就是把信息映射到一个语义向量空间中。这个语义向量空间满足某类性质，比如语义相似的向量距离更近。也就是说，如果两句话（尽管内容不同）它的意思是相似的，那么把它们分别编码后的两个向量的距离也相近；反之，如果两句话的意思截然不同，那么编码后向量的距离则很远。如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-712ec37a73b854c1.png)</p><p>从上图我们可以看到，<strong>递归神经网络</strong>将所有的词、句都映射到一个2维向量空间中。句子『the country of my birth』和句子『the place where I was born』的意思是非常接近的，所以表示它们的两个向量在向量空间中的距离很近。另外两个词『Germany』和『France』因为表示的都是地点，它们的向量与上面两句话的向量的距离，就比另外两个表示时间的词『Monday』和『Tuesday』的向量的距离近得多。这样，通过向量的距离，就得到了一种语义的表示。</p><p>上图还显示了自然语言<strong>可组合</strong>的性质：词可以组成句、句可以组成段落、段落可以组成篇章，而更高层的语义取决于底层的语义以及它们的组合方式。<strong>递归神经网络</strong>是一种表示学习，它可以将词、句、段、篇按照他们的语义映射到同一个向量空间中，也就是把可组合（树/图结构）的信息表示为一个个有意义的向量。比如上面这个例子，<strong>递归神经网络</strong>把句子”the country of my birth”表示为二维向量[1,5]。有了这个『编码器』之后，我们就可以以这些有意义的向量为基础去完成更高级的任务（比如情感分析等）。如下图所示，<strong>递归神经网络</strong>在做情感分析时，可以比较好的处理否定句，这是胜过其他一些模型的：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-1f91307ac606ba00.png)</p><p>在上图中，蓝色表示正面评价，红色表示负面评价。每个节点是一个向量，这个向量表达了以它为根的子树的情感评价。比如”intelligent humor”是正面评价，而”care about cleverness wit or any other kind of intelligent humor”是中性评价。我们可以看到，模型能够正确的处理doesn’t的含义，将正面评价转变为负面评价。</p><p>尽管<strong>递归神经网络</strong>具有更为强大的表示能力，但是在实际应用中并不太流行。其中一个主要原因是，<strong>递归神经网络</strong>的输入是树/图结构，而这种结构需要花费很多人工去标注。想象一下，如果我们用<strong>循环神经网络</strong>处理句子，那么我们可以直接把句子作为输入。然而，如果我们用<strong>递归神经网络</strong>处理句子，我们就必须把每个句子标注为语法解析树的形式，这无疑要花费非常大的精力。很多时候，相对于<strong>递归神经网络</strong>能够带来的性能提升，这个投入是不太划算的。</p><p>我们已经基本了解了<strong>递归神经网络</strong>是做什么用的，接下来，我们将探讨它的算法细节。</p><h2 id="递归神经网络的前向计算"><a href="#递归神经网络的前向计算" class="headerlink" title="递归神经网络的前向计算"></a>递归神经网络的前向计算</h2><p>接下来，我们详细介绍一下<strong>递归神经网络</strong>是如何处理树/图结构的信息的。在这里，我们以处理树型信息为例进行介绍。</p><p><strong>递归神经网络</strong>的输入是两个子节点（也可以是多个），输出就是将这两个子节点编码后产生的父节点，父节点的维度和每个子节点是相同的。如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-f2ea8885320110a5.png)</p><p>$\mathbf{c}_1$和$\mathbf{c}_2$分别是表示两个子节点的向量，$\mathbf{p}$是表示父节点的向量。子节点和父节点组成一个全连接神经网络，也就是子节点的每个神经元都和父节点的每个神经元两两相连。我们用矩阵$W$表示这些连接上的权重，它的维度将是$d\times 2d$，其中，$d$表示每个节点的维度。父节点的计算公式可以写成：</p><p>$\begin{align} \mathbf{p} = tanh(W\begin{bmatrix}\mathbf{c}_1\\\mathbf{c}_2\end{bmatrix}+\mathbf{b})\qquad(式1)\end {align} $</p><p>在上式中，tanh是激活函数（当然也可以用其它的激活函数），$\mathbf{b}$是偏置项，它也是一个维度为$d$的向量。如果读过前面的文章，相信大家已经非常熟悉这些计算了，在此不做过多的解释了。</p><p>然后，我们把产生的父节点的向量和其他子节点的向量再次作为网络的输入，再次产生它们的父节点。如此递归下去，直至整棵树处理完毕。最终，我们将得到根节点的向量，我们可以认为它是对整棵树的表示，这样我们就实现了把树映射为一个向量。在下图中，我们使用<strong>递归神经网络</strong>处理一棵树，最终得到的向量$\mathbf{p}_3$，就是对整棵树的表示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-2e300754026038f5.png)</p><p>举个例子，我们使用<strong>递归神将网络</strong>将『两个外语学校的学生』映射为一个向量，如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-577b3ccc7c34eb34.png)</p><p>最后得到的向量$\mathbf{p}_3$就是对整个句子『两个外语学校的学生』的表示。由于整个结构是递归的，不仅仅是根节点，事实上每个节点都是以其为根的子树的表示。比如，在左边的这棵树中，向量$\mathbf{p}_2$是短语『外语学院的学生』的表示，而向量$\mathbf{p}_1$是短语『外语学院的』的表示。</p><p><strong>式1</strong>就是<strong>递归神经网络</strong>的前向计算算法。它和全连接神经网络的计算没有什么区别，只是在输入的过程中需要根据输入的树结构依次输入每个子节点。</p><p>需要特别注意的是，<strong>递归神经网络</strong>的权重$W$和偏置项$\mathbf{b}$在所有的节点都是<strong>共享</strong>的。</p><h2 id="递归神经网络的训练"><a href="#递归神经网络的训练" class="headerlink" title="递归神经网络的训练"></a>递归神经网络的训练</h2><p><strong>递归神经网络</strong>的训练算法和<strong>循环神经网络</strong>类似，两者不同之处在于，前者需要将残差$\delta$从根节点反向传播到各个子节点，而后者是将残差$\delta$从当前时刻$t_k$反向传播到初始时刻$t_{1}$。</p><p>下面，我们介绍适用于<strong>递归神经网络</strong>的训练算法，也就是<strong>BPTS</strong>算法。</p><h3 id="误差项的传递"><a href="#误差项的传递" class="headerlink" title="误差项的传递"></a>误差项的传递</h3><p>首先，我们先推导将误差从父节点传递到子节点的公式，如下图：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-9ab001431eb2f2a4.png)</p><p>定义$\delta_p$为误差函数E相对于父节点的加权输入$\mathbf{net}_p$的导数，即：</p><p>$\begin {align} \delta_p\overset{def}{=}\frac{\partial{E}}{\partial{\mathbf{net}_p}} \end{align} $</p><p>设$\mathbf{net}_p$是父节点的<strong>加权输入</strong>，则</p><p>$\begin{align} \mathbf{net}_p=W\begin{bmatrix}\mathbf{c}_1\\\mathbf{c}_2\end{bmatrix}+\mathbf{b} \end{align} $</p><p>在上述式子里，$\mathbf{net}_p$、$\mathbf{c}_1$、$\mathbf{c}_2$都是向量，而$\mathbf W$是矩阵。为了看清楚它们的关系，我们将其展开：</p><p>$\begin{align} \begin{bmatrix} net_{p_1}\\ net_{p_2}\\ …\\ net_{p_n} \end{bmatrix}&amp;= \begin{bmatrix} w_{p_1c_{11}}&amp;w_{p_1c_{12}}&amp;…&amp;w_{p_1c_{1n}}&amp;w_{p_1c_{21}}&amp;w_{p_1c_{22}}&amp;…&amp;w_{p_1c_{2n}}\\ w_{p_2c_{11}}&amp;w_{p_2c_{12}}&amp;…&amp;w_{p_2c_{1n}}&amp;w_{p_2c_{21}}&amp;w_{p_2c_{22}}&amp;…&amp;w_{p_2c_{2n}}\\ …\\ w_{p_nc_{11}}&amp;w_{p_nc_{12}}&amp;…&amp;w_{p_nc_{1n}}&amp;w_{p_nc_{21}}&amp;w_{p_nc_{22}}&amp;…&amp;w_{p_nc_{2n}}\\ \end{bmatrix} \begin{bmatrix} c_{11}\\ c_{12}\\ …\\ c_{1n}\\ c_{21}\\ c_{22}\\ …\\ c_{2n} \end{bmatrix}+\begin{bmatrix}\\ b_1\\ b_2\\ …\\ b_n\\ \end{bmatrix} \end{align} $</p><p>在上面的公式中，$p_i$表示父节点p的第i个分量；$c_{1i}$表示$c_{1}$子节点的第i个分量；$c_{2i}$表示$c_2$子节点的第i个分量；$w_{p_ic_{jk}}$表示子节点$c_j$的第k个分量到父节点p的第i个分量的的权重。根据上面展开后的矩阵乘法形式，我们不难看出，对于子节点$c_{jk}$来说，它会影响父节点所有的分量。因此，我们求误差函数E对$c_{jk}$的导数时，必须用到全导数公式，也就是：</p><p>$\begin{align} \frac{\partial{E}}{\partial{c_{jk}}}&amp;=\sum_i{\frac{\partial{E}}{\partial{net_{p_i}}}}\frac{\partial{net_{p_i}}}{\partial{c_{jk}}}\\ &amp;=\sum_i{\delta_{p_i}}w_{p_ic_{jk}} \end{align} $</p><p>有了上式，我们就可以把它表示为矩阵形式，从而得到一个向量化表达：</p><p>$\begin{align} \frac{\partial{E}}{\partial{\mathbf{c}_j}}&amp;=U_j\delta_p \end{align} $</p><p>其中，矩阵$U_j$是从矩阵W中提取部分元素组成的矩阵。其单元为：</p><p>$\begin {align} u_{j_{ik}}=w_{p_kc_{ji}} \end{align} $</p><p>上式看上去可能会让人晕菜，从下图，我们可以直观的看到$U_j$到底是啥。首先我们把W矩阵拆分为两个矩阵$W_1$和$W_2$，如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-fb58d74fbc7e9ce5.png)</p><p>显然，子矩阵$W_1$和$W_2$分别对应子节点$\mathbf{c}_1$和$\mathbf{c}_2$的到父节点$\mathbf{p}$权重。则矩阵$U_j$为：</p><p>$\begin {align} U_j=W_j^T \end{align} $</p><p>也就是说，将误差项反向传递到相应子节点$\mathbf{c}_j$的矩阵$U_j$就是其对应权重矩阵$W_j$的转置。</p><p>现在，我们设$\mathbf{net}_{c_j}$是子节点$\mathbf{c}_j$的加权输入，$f$是子节点c的激活函数，则：</p><p>$\begin{align} \mathbf{c}_j=f(\mathbf{net}_{c_j})\\ \end{align} $</p><p>这样，我们得到：</p><p>$\begin{align} \delta_{c_j}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{c_j}}}\\ &amp;=\frac{\partial{E}}{\partial{\mathbf{c}_j}}\frac{\partial{\mathbf{c}_j}}{\partial{\mathbf{net}_{c_j}}}\\ &amp;=W_j^T\delta_p\circ f’(\mathbf{net}_{c_j}) \end{align} $</p><p>如果我们将不同子节点$\mathbf{c}_j$对应的误差项$\delta_{c_j}$连接成一个向量$\delta_c=\begin{bmatrix}\delta_{c_1}\\\delta_{c_2}\end{bmatrix}$。那么，上式可以写成：</p><p>$\begin{align} \delta_c=W^T\delta_p\circ f’(\mathbf{net}_c)\qquad(式2)\end{align} $</p><p><strong>式2</strong>就是将误差项从父节点传递到其子节点的公式。注意，上式中的$\mathbf{net}_c$也是将两个子节点的加权输入$\mathbf{net}_{c_1}$和$\mathbf{net}_{c_2}$连在一起的向量。</p><p>有了传递一层的公式，我们就不难写出逐层传递的公式。</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-02c71c9fade90557.png)</p><p>上图是在树型结构中反向传递误差项的全景图，反复应用<strong>式2</strong>，在已知$\delta_p^{(3)}$的情况下，我们不难算出$\delta_p^{(1)}$为：</p><p>$\begin{align} \delta^{(2)}&amp;=W^T\delta_p^{(3)}\circ f’(\mathbf{net}^{(2)})\\ \delta_p^{(2)}&amp;=[\delta^{(2)}]_p\\ \delta^{(1)}&amp;=W^T\delta_p^{(2)}\circ f’(\mathbf{net}^{(1)})\\ \delta_p^{(1)}&amp;=[\delta^{(1)}]_p\\ \end{align} $</p><p>在上面的公式中，$\delta^{(2)}=\begin{bmatrix}\delta_c^{(2)}\\\delta_p^{(2)}\end{bmatrix}$，$[\delta^{(2)}]_p$表示取向量$\delta^{(2)}$属于节点p的部分。</p><h3 id="权重梯度的计算"><a href="#权重梯度的计算" class="headerlink" title="权重梯度的计算"></a>权重梯度的计算</h3><p>根据加权输入的计算公式：</p><p>$\begin {align} \mathbf{net}_p^{(l)}=W\mathbf{c}^{(l)}+\mathbf{b} \end{align} $</p><p>其中，$\mathbf{net}_p^{(l)}$表示第l层的父节点的加权输入，$\mathbf{c}^{(l)}$表示第l层的子节点。$W$是权重矩阵，$\mathbf{b}$是偏置项。将其展开可得：</p><p>$\begin {align} \mathbf{net}_{p_j}^l=\sum_i{w_{ji}c_i^l}+b_j \end{align} $</p><p>那么，我们可以求得误差函数在第l层对权重的梯度为：</p><p>$\begin{align} \frac{\partial{E}}{\partial{w_{ji}^{(l)}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{p_j}^{(l)}}}\frac{\partial{\mathbf{net}_{p_j}^{(l)}}}{\partial{w_{ji}^{(l)}}}\\ &amp;=\delta_{p_j}^{(l)}c_i^{(l)}\\ \end{align} $</p><p>上式是针对一个权重项$w_{ji}$的公式，现在需要把它扩展为对所有的权重项的公式。我们可以把上式写成矩阵的形式（在下面的公式中，m=2n）：</p><p>$\begin{align} \frac{\partial{E}}{\partial{W^{(l)}}}&amp;= \begin{bmatrix} \frac{\partial{E}}{\partial{w_{11}^{(l)}}}&amp; \frac{\partial{E}}{\partial{w_{12}^{(l)}}}&amp; …&amp; \frac{\partial{E}}{\partial{w_{1m}^{(l)}}}\\ \frac{\partial{E}}{\partial{w_{21}^{(l)}}}&amp; \frac{\partial{E}}{\partial{w_{22}^{(l)}}}&amp; …&amp; \frac{\partial{E}}{\partial{w_{2m}^{(l)}}}\\ \\\\\...\\\\ \frac{\partial{E}}{\partial{w_{n1}^{(l)}}}&amp; \frac{\partial{E}}{\partial{w_{n2}^{(l)}}}&amp; …&amp; \frac{\partial{E}}{\partial{w_{nm}^{(l)}}}\\ \end{bmatrix}\\ &amp;= \begin{bmatrix} \delta_{p_1}^{(l)}c_1^l&amp;\delta_{p_1}^{(l)}c_2^l&amp;…&amp;\delta_{p_1}^lc_m^{(l)}\\ \delta_{p_2}^{(l)}c_1^l&amp;\delta_{p_2}^{(l)}c_2^l&amp;…&amp;\delta_{p_2}^lc_m^{(l)}\\ \\\\\...\\\\ \delta_{p_n}^{(l)}c_1^l&amp;\delta_{p_n}^{(l)}lc_2^l&amp;…&amp;\delta_{p_n}^lc_m^{(l)}\\ \end{bmatrix}\\ &amp;=\delta^(\mathbf{c}^{(l)})^T\qquad(式3) \end{align} $</p><p><strong>式3</strong>就是第l层权重项的梯度计算公式。我们知道，由于权重$W$是在所有层共享的，所以和<strong>循环神经网络</strong>一样，<strong>递归神经网络</strong>的最终的<strong>权重梯度是各个层权重梯度之和</strong>。即：</p><p>$\begin {align} \frac{\partial{E}}{\partial{W}}=\sum_l\frac{\partial{E}}{\partial{W^{(l)}}}\qquad(式4) \end{align} $</p><p>因为<strong>循环神经网络</strong>的证明过程已经在<a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="noopener">零基础入门深度学习(4) - 卷积神经网络</a>一文中给出，因此，<strong>递归神经网络</strong>『为什么最终梯度是各层梯度之和』的证明就留给读者自行完成啦。</p><p>接下来，我们求偏置项$\mathbf{b}$的梯度计算公式。先计算误差函数对第l层偏置项$\mathbf{b}^{(l)}$的梯度：</p><p>$\begin{align} \frac{\partial{E}}{\partial{b_j^{(l)}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{p_j}^{(l)}}}\frac{\partial{\mathbf{net}_{p_j}^{(l)}}}{\partial{b_j^{(l)}}}\\ &amp;=\delta_{p_j}^{(l)}\\ \end{align} $</p><p>把上式扩展为矩阵的形式：</p><p>$\begin{align} \frac{\partial{E}}{\partial{\mathbf{b}^{(l)}}}&amp;= \begin{bmatrix} \frac{\partial{E}}{\partial{b_1^{(l)}}}\\ \frac{\partial{E}}{\partial{b_2^{(l)}}}\\ \\\\\...\\\\ \frac{\partial{E}}{\partial{b_n^{(l)}}}\\ \end{bmatrix}\\ &amp;= \begin{bmatrix} \delta_{p_1}^{(l)}\\ \delta_{p_2}^{(l)}\\ \\\\\...\\\\ \delta_{p_n}^{(l)}\\ \end{bmatrix}\\ &amp;=\delta_p^\qquad(式5) \end{align} $</p><p><strong>式5</strong>是第$l$层偏置项的梯度，那么最终的偏置项梯度是各个层偏置项梯度之和，即：</p><p>$\begin {align}\frac{\partial{E}}{\partial{\mathbf{b}}}=\sum_l\frac{\partial{E}}{\partial{\mathbf{b}^{(l)}}}\qquad(式6) \end {align} $</p><h3 id="权重更新"><a href="#权重更新" class="headerlink" title="权重更新"></a>权重更新</h3><p>如果使用梯度下降优化算法，那么权重更新公式为：</p><p>$\begin {align} W\gets W + \eta\frac{\partial{E}}{\partial{W}} \end{align}  $</p><p>其中，$\eta$是学习速率常数。把<strong>式4</strong>带入到上式，即可完成权重的更新。同理，偏置项的更新公式为：</p><p>$\begin {align} \mathbf{b}\gets \mathbf{b} + \eta\frac{\partial{E}}{\partial{\mathbf{b}}} \end {align} $</p><p>把<strong>式6</strong>带入到上式，即可完成偏置项的更新。</p><p>这就是<strong>递归神经网络</strong>的训练算法BPTS。由于我们有了前面几篇文章的基础，相信读者们理解BPTS算法也会比较容易。</p><h2 id="递归神经网络的实现"><a href="#递归神经网络的实现" class="headerlink" title="递归神经网络的实现"></a>递归神经网络的实现</h2><blockquote><p>完整代码请参考GitHub: <a href="https://github.com/hanbt/learn_dl/blob/master/recursive.py" target="_blank" rel="noopener">https://github.com/hanbt/learn_dl/blob/master/recursive.py</a> (python2.7)</p></blockquote><p>现在，我们实现一个处理树型结构的<strong>递归神经网络</strong>。</p><p>在文件的开头，加入如下代码：</p><pre class=" language-lang-python"><code class="language-lang-python">#!/usr/bin/env python# -*- coding: UTF-8 -*-import numpy as npfrom cnn import IdentityActivator</code></pre><p>上述四行代码非常简单，没有什么需要解释的。IdentityActivator激活函数是在我们介绍<strong>卷积神经网络</strong>时写的，现在引用一下它。</p><p>我们首先定义一个树节点结构，这样，我们就可以用它保存卷积神经网络生成的整棵树：</p><pre class=" language-lang-python"><code class="language-lang-python">class TreeNode(object):    def __init__(self, data, children=[], children_data=[]):        self.parent = None        self.children = children        self.children_data = children_data        self.data = data        for child in children:            child.parent = self</code></pre><p>接下来，我们把<strong>递归神经网络</strong>的实现代码都放在RecursiveLayer类中，下面是这个类的构造函数：</p><pre class=" language-lang-python"><code class="language-lang-python"># 递归神经网络实现class RecursiveLayer(object):    def __init__(self, node_width, child_count,                  activator, learning_rate):        '''        递归神经网络构造函数        node_width: 表示每个节点的向量的维度        child_count: 每个父节点有几个子节点        activator: 激活函数对象        learning_rate: 梯度下降算法学习率        '''        self.node_width = node_width        self.child_count = child_count        self.activator = activator        self.learning_rate = learning_rate        # 权重数组W        self.W = np.random.uniform(-1e-4, 1e-4,            (node_width, node_width * child_count))        # 偏置项b        self.b = np.zeros((node_width, 1))        # 递归神经网络生成的树的根节点        self.root = None</code></pre><p>下面是前向计算的实现：</p><pre class=" language-lang-python"><code class="language-lang-python">    def forward(self, *children):        '''        前向计算        '''        children_data = self.concatenate(children)        parent_data = self.activator.forward(            np.dot(self.W, children_data) + self.b        )        self.root = TreeNode(parent_data, children                            , children_data)</code></pre><p>forward函数接收一系列的树节点对象作为输入，然后，<strong>递归神经网络</strong>将这些树节点作为子节点，并计算它们的父节点。最后，将计算的父节点保存在self.root变量中。</p><p>上面用到的concatenate函数，是将各个子节点中的数据拼接成一个长向量，其代码如下：</p><pre class=" language-lang-python"><code class="language-lang-python">    def concatenate(self, tree_nodes):        '''        将各个树节点中的数据拼接成一个长向量        '''        concat = np.zeros((0,1))        for node in tree_nodes:            concat = np.concatenate((concat, node.data))        return concat</code></pre><p>下面是反向传播算法BPTS的实现：</p><pre class=" language-lang-python"><code class="language-lang-python">    def backward(self, parent_delta):        '''        BPTS反向传播算法        '''        self.calc_delta(parent_delta, self.root)        self.W_grad, self.b_grad = self.calc_gradient(self.root)    def calc_delta(self, parent_delta, parent):        '''        计算每个节点的delta        '''        parent.delta = parent_delta        if parent.children:            # 根据式2计算每个子节点的delta            children_delta = np.dot(self.W.T, parent_delta) * (                self.activator.backward(parent.children_data)            )            # slices = [(子节点编号，子节点delta起始位置，子节点delta结束位置)]            slices = [(i, i * self.node_width,                         (i + 1) * self.node_width)                        for i in range(self.child_count)]            # 针对每个子节点，递归调用calc_delta函数            for s in slices:                self.calc_delta(children_delta[s[1]:s[2]],                                 parent.children[s[0]])    def calc_gradient(self, parent):        '''        计算每个节点权重的梯度，并将它们求和，得到最终的梯度        '''        W_grad = np.zeros((self.node_width,                             self.node_width * self.child_count))        b_grad = np.zeros((self.node_width, 1))        if not parent.children:            return W_grad, b_grad        parent.W_grad = np.dot(parent.delta, parent.children_data.T)        parent.b_grad = parent.delta        W_grad += parent.W_grad        b_grad += parent.b_grad        for child in parent.children:            W, b = self.calc_gradient(child)            W_grad += W            b_grad += b        return W_grad, b_grad</code></pre><p>在上述算法中，calc_delta函数和calc_gradient函数分别计算各个节点的误差项以及最终的梯度。它们都采用递归算法，先序遍历整个树，并逐一完成每个节点的计算。</p><p>下面是梯度下降算法的实现（没有weight decay），这个非常简单：</p><pre class=" language-lang-python"><code class="language-lang-python">    def update(self):        '''        使用SGD算法更新权重        '''        self.W -= self.learning_rate * self.W_grad        self.b -= self.learning_rate * self.b_grad</code></pre><p>以上就是<strong>递归神经网络</strong>的实现，总共100行左右，和上一篇文章的LSTM相比简单多了。</p><p>最后，我们用梯度检查来验证程序的正确性：</p><pre class=" language-lang-python"><code class="language-lang-python">def gradient_check():    '''    梯度检查    '''    # 设计一个误差函数，取所有节点输出项之和    error_function = lambda o: o.sum()    rnn = RecursiveLayer(2, 2, IdentityActivator(), 1e-3)    # 计算forward值    x, d = data_set()    rnn.forward(x[0], x[1])    rnn.forward(rnn.root, x[2])    # 求取sensitivity map    sensitivity_array = np.ones((rnn.node_width, 1),                                dtype=np.float64)    # 计算梯度    rnn.backward(sensitivity_array)    # 检查梯度    epsilon = 10e-4    for i in range(rnn.W.shape[0]):        for j in range(rnn.W.shape[1]):            rnn.W[i,j] += epsilon            rnn.reset_state()            rnn.forward(x[0], x[1])            rnn.forward(rnn.root, x[2])            err1 = error_function(rnn.root.data)            rnn.W[i,j] -= 2*epsilon            rnn.reset_state()            rnn.forward(x[0], x[1])            rnn.forward(rnn.root, x[2])            err2 = error_function(rnn.root.data)            expect_grad = (err1 - err2) / (2 * epsilon)            rnn.W[i,j] += epsilon            print 'weights(%d,%d): expected - actural %.4e - %.4e' % (                i, j, expect_grad, rnn.W_grad[i,j])    return rnn</code></pre><p>下面是梯度检查的结果，完全正确，OH YEAH！</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-bea78770357e735a.png)</p><h2 id="递归神经网络的应用"><a href="#递归神经网络的应用" class="headerlink" title="递归神经网络的应用"></a>递归神经网络的应用</h2><h3 id="自然语言和自然场景解析"><a href="#自然语言和自然场景解析" class="headerlink" title="自然语言和自然场景解析"></a>自然语言和自然场景解析</h3><p>在自然语言处理任务中，如果我们能够实现一个解析器，将自然语言解析为语法树，那么毫无疑问，这将大大提升我们对自然语言的处理能力。解析器如下所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-6b7f075645c12c92.png)</p><p>可以看出，<strong>递归神经网络</strong>能够完成句子的语法分析，并产生一个语法解析树。</p><p>除了自然语言之外，自然场景也具有<strong>可组合</strong>的性质。因此，我们可以用类似的模型完成自然场景的解析，如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-7ed5b7d06a8cc583.png)</p><p>两种不同的场景，可以用相同的<strong>递归神经网络</strong>模型来实现。我们以第一个场景，自然语言解析为例。</p><p>我们希望将一句话逐字输入到神经网络中，然后，神经网络返回一个解析好的树。为了做到这一点，我们需要给神经网络再加上一层，负责打分。分数越高，说明两个子节点结合更加紧密，分数越低，说明两个子节点结合更松散。如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-2f0393edbc04c30e.png)</p><p>一旦这个打分函数训练好了（也就是矩阵U的各项值变为合适的值），我们就可以利用贪心算法来实现句子的解析。第一步，我们先将词按照顺序两两输入神经网络，得到第一组打分：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-be0eb2d1a3527bc6.png)</p><p>我们发现，现在分数最高的是第一组，The cat，说明它们的结合是最紧密的。这样，我们可以先将它们组合为一个节点。然后，再次两两计算相邻子节点的打分：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-bb8f87bc4f56f5ee.png)</p><p>现在，分数最高的是最后一组，the mat。于是，我们将它们组合为一个节点，再两两计算相邻节点的打分：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-9c3332923237d11c.png)</p><p>这时，我们发现最高的分数是on the mat，把它们组合为一个节点，继续两两计算相邻节点的打分……最终，我们就能够得到整个解析树：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-14f0140e4eafa5ca.png)</p><p>现在，我们困惑这样牛逼的打分函数score是怎样训练出来的呢？我们需要定义一个目标函数。这里，我们使用Max-Margin目标函数。它的定义如下：</p><p>$\begin {align} J(\theta)=max(0, \sum_i\underset{y\in A(x_i)}{max}(s(x_i,y)+\Delta(y,y_i))-s(x_i,y_i)) \end{align} $</p><p>在上式中，$x_i$、$y_i$分别表示第i个训练样本的输入和标签，注意这里的标签$y_i$是一棵解析树。$s(x_i,y_i)$就是打分函数s对第i个训练样本的打分。因为训练样本的标签肯定是正确的，我们希望s对它的打分越高越好，也就是$s(x_i,y_i)$越大越好。$A(x_1)$是所有可能的解析树的集合，而$s(x_i,y)$则是对某个可能的解析树$y$的打分。$\Delta(y,y_i)$是对错误的惩罚。也就是说，如果某个解析树$y$和标签$y_{i}$是一样的，那么$\Delta(y,y_i)$为0，如果网络的输出错的越离谱，那么惩罚项$\Delta(y,y_i)$的值就越高。$max(s(x_i,y)+\Delta(y,y_i))$表示所有树里面最高得分。在这里，惩罚项相当于Margin，也就是我们虽然希望打分函数s对正确的树打分比对错误的树打分高，但也不要高过Margin的值。我们优化$\theta$，使目标函数取最小值，即：</p><p>$\theta=\underset{\theta}{argmin}J(\theta)$</p><p>下面是惩罚函数$\Delta$的定义：</p><script type="math/tex; mode=display">\begin {align} \Delta(y,y_i)=k\sum_{d\in N(y)}\mathbf{1}{\{subTree(d)\notin y_i\}} \end{align}</script><p>上式中，N(y)是树y节点的集合；subTree(d)是以d为节点的子树。上式的含义是，如果以d为节点的子树没有出现在标签中，那么函数值+1。最终，惩罚函数的值，是树y中没有出现在树中的子树的个数，再乘上一个系数k。其实也就是关于两棵树差异的一个度量。</p><p>$s(x,y)$是对一个样本最终的打分，它是对树y每个节点打分的总和。</p><p>$\begin {align} s(x,y)=\sum_{n\in nodes(y)}s_n \end{align} $</p><p>具体细节，读者可以查阅『参考资料3』的论文。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们在系列文章中已经介绍的<strong>全连接神经网络</strong>、<strong>卷积神经网络</strong>、<strong>循环神经网络</strong>和<strong>递归神经网络</strong>，在训练时都使用了<strong>监督学习(Supervised Learning)</strong>作为训练方法。在<strong>监督学习</strong>中，每个训练样本既包括输入特征$\mathbf{x}$，也包括标记$\mathbf{y}$，即样本$d^{(i)}=\{\mathbf{x}^{(i)},\mathbf{y}^{(i)}\}$。然而，很多情况下，我们无法获得形如$\{\mathbf{x}^{(i)},\mathbf{y}^{(i)}\}$的样本，这时，我们就不能采用<strong>监督学习</strong>的方法。在接下来的几篇文章中，我们重点介绍另外一种学习方法：<strong>增强学习(Reinforcement Learning)</strong>。在了解<strong>增强学习</strong>的主要算法之后，我们还将介绍著名的围棋软件<strong>AlphaGo</strong>，它是一个把<strong>监督学习</strong>和<strong>增强学习</strong>进行完美结合的案例。</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(7" alt="img">%20-%20%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-9f3e58723eee0af3.jpg)</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="http://cs224d.stanford.edu/" target="_blank" rel="noopener">CS224d: Deep Learning for Natural Language Processing</a></li><li><a href="https://pdfs.semanticscholar.org/794e/6ed81d21f1bf32a0fd3be05c44c1fa362688.pdf" target="_blank" rel="noopener">Learning Task-Dependent Distributed Representations by Back Propagation Through Structure</a></li><li><a href="http://ai.stanford.edu/~ang/papers/icml11-ParsingWithRecursiveNeuralNetworks.pdf" target="_blank" rel="noopener">Parsing Natural Scenes and Natural Language with Recursive Neural Networks</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>零基础入门深度学习-循环神经网络</title>
      <link href="/ling-ji-chu-ru-men-shen-du-xue-xi-5-xun-huan-shen-jing-wang-luo/"/>
      <url>/ling-ji-chu-ru-men-shen-du-xue-xi-5-xun-huan-shen-jing-wang-luo/</url>
      
        <content type="html"><![CDATA[<p>参考资料：<a href="https://www.zybuluo.com/hanbingtao/note/541458" target="_blank" rel="noopener">https://www.zybuluo.com/hanbingtao/note/541458</a></p><hr><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-06627c71f0d8c0dc.jpg)</p><blockquote><p>无论即将到来的是大数据时代还是人工智能时代，亦或是传统行业使用人工智能在云上处理大数据的时代，作为一个有理想有追求的程序员，不懂深度学习（Deep Learning）这个超热的技术，会不会感觉马上就out了？现在救命稻草来了，《零基础入门深度学习》系列文章旨在讲帮助爱编程的你从零基础达到入门级水平。零基础意味着你不需要太多的数学知识，只要会写程序就行了，没错，这是专门为程序员写的文章。虽然文中会有很多公式你也许看不懂，但同时也会有更多的代码，程序员的你一定能看懂的（我周围是一群狂热的Clean Code程序员，所以我写的代码也不会很差）。</p></blockquote><h2 id="往期回顾"><a href="#往期回顾" class="headerlink" title="往期回顾"></a>往期回顾</h2><p>在前面的文章系列文章中，我们介绍了全连接神经网络和卷积神经网络，以及它们的训练和使用。他们都只能单独的取处理一个个的输入，前一个输入和后一个输入是完全没有关系的。但是，某些任务需要能够更好的处理<strong>序列</strong>的信息，即前面的输入和后面的输入是有关系的。比如，当我们在理解一句话意思时，孤立的理解这句话的每个词是不够的，我们需要处理这些词连接起来的整个<strong>序列</strong>；当我们处理视频的时候，我们也不能只单独的去分析每一帧，而要分析这些帧连接起来的整个<strong>序列</strong>。这时，就需要用到深度学习领域中另一类非常重要神经网络：<strong>循环神经网络(Recurrent Neural Network)</strong>。RNN种类很多，也比较绕脑子。不过读者不用担心，本文将一如既往的对复杂的东西剥茧抽丝，帮助您理解RNNs以及它的训练算法，并动手实现一个<strong>循环神经网络</strong>。</p><h2 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h2><p>RNN是在<strong>自然语言处理</strong>领域中最先被用起来的，比如，RNN可以为<strong>语言模型</strong>来建模。那么，什么是语言模型呢？</p><p>我们可以和电脑玩一个游戏，我们写出一个句子前面的一些词，然后，让电脑帮我们写下接下来的一个词。比如下面这句：</p><blockquote><p>我昨天上学迟到了，老师批评了____。</p></blockquote><p>我们给电脑展示了这句话前面这些词，然后，让电脑写下接下来的一个词。在这个例子中，接下来的这个词最有可能是『我』，而不太可能是『小明』，甚至是『吃饭』。</p><p><strong>语言模型</strong>就是这样的东西：给定一个一句话前面的部分，预测接下来最有可能的一个词是什么。</p><p><strong>语言模型</strong>是对一种语言的特征进行建模，它有很多很多用处。比如在语音转文本(STT)的应用中，声学模型输出的结果，往往是若干个可能的候选词，这时候就需要<strong>语言模型</strong>来从这些候选词中选择一个最可能的。当然，它同样也可以用在图像到文本的识别中(OCR)。</p><p>使用RNN之前，语言模型主要是采用N-Gram。N可以是一个自然数，比如2或者3。它的含义是，假设一个词出现的概率只与前面N个词相关。我们以2-Gram为例。首先，对前面的一句话进行切词：</p><blockquote><p>我 昨天 上学 迟到 了 ，老师 批评 了 ____。</p></blockquote><p>如果用2-Gram进行建模，那么电脑在预测的时候，只会看到前面的『了』，然后，电脑会在语料库中，搜索『了』后面最可能的一个词。不管最后电脑选的是不是『我』，我们都知道这个模型是不靠谱的，因为『了』前面说了那么一大堆实际上是没有用到的。如果是3-Gram模型呢，会搜索『批评了』后面最可能的词，感觉上比2-Gram靠谱了不少，但还是远远不够的。因为这句话最关键的信息『我』，远在9个词之前！</p><p>现在读者可能会想，可以提升继续提升N的值呀，比如4-Gram、5-Gram…….。实际上，这个想法是没有实用性的。因为我们想处理任意长度的句子，N设为多少都不合适；另外，模型的大小和N的关系是指数级的，4-Gram模型就会占用海量的存储空间。</p><p>所以，该轮到RNN出场了，RNN理论上可以往前看(往后看)任意多个词。</p><h2 id="循环神经网络是啥"><a href="#循环神经网络是啥" class="headerlink" title="循环神经网络是啥"></a>循环神经网络是啥</h2><p>循环神经网络种类繁多，我们先从最简单的基本循环神经网络开始吧。</p><h3 id="基本循环神经网络"><a href="#基本循环神经网络" class="headerlink" title="基本循环神经网络"></a>基本循环神经网络</h3><p>下图是一个简单的循环神经网络如，它由输入层、一个隐藏层和一个输出层组成：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-479f2a7488b91671.jpg)</p><p>纳尼？！相信第一次看到这个玩意的读者内心和我一样是崩溃的。因为<strong>循环神经网络</strong>实在是太难画出来了，网上所有大神们都不得不用了这种抽象艺术手法。不过，静下心来仔细看看的话，其实也是很好理解的。如果把上面有W的那个带箭头的圈去掉，它就变成了最普通的<strong>全连接神经网络</strong>。x是一个向量，它表示<strong>输入层</strong>的值（这里面没有画出来表示神经元节点的圆圈）；s是一个向量，它表示<strong>隐藏层</strong>的值（这里隐藏层面画了一个节点，你也可以想象这一层其实是多个节点，节点数与向量s的维度相同）；U是输入层到隐藏层的<strong>权重矩阵</strong>（读者可以回到第三篇文章<a href="https://www.zybuluo.com/hanbingtao/note/476663" target="_blank" rel="noopener">零基础入门深度学习(3) - 神经网络和反向传播算法</a>，看看我们是怎样用矩阵来表示<strong>全连接神经网络</strong>的计算的）；o也是一个向量，它表示<strong>输出层</strong>的值；V是隐藏层到输出层的<strong>权重矩阵</strong>。那么，现在我们来看看W是什么。<strong>循环神经网络</strong>的<strong>隐藏层</strong>的值s不仅仅取决于当前这次的输入x，还取决于上一次<strong>隐藏层</strong>的值s。<strong>权重矩阵</strong> W就是<strong>隐藏层</strong>上一次的值作为这一次的输入的权重。</p><p>如果我们把上面的图展开，<strong>循环神经网络</strong>也可以画成下面这个样子：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-cf18bb1f06e750a4.jpg)</p><p>现在看上去就比较清楚了，这个网络在t时刻接收到输入之后，隐藏层的值是，输出值是。关键一点是，的值不仅仅取决于，还取决于。我们可以用下面的公式来表示<strong>循环神经网络</strong>的计算方法：</p><p>$\begin{align} \mathrm{o}_t&amp;=g(V\mathrm{s}_t)\qquad\qquad\quad(式1)\\ \mathrm{s}_t&amp;=f(U\mathrm{x}_t+W\mathrm{s}_{t-1})\qquad(式2)\\ \end{align} $</p><p><strong>式1</strong>是<strong>输出层</strong>的计算公式，输出层是一个<strong>全连接层</strong>，也就是它的每个节点都和隐藏层的每个节点相连。V是输出层的<strong>权重矩阵</strong>，g是<strong>激活函数</strong>。式2是隐藏层的计算公式，它是<strong>循环层</strong>。U是输入x的权重矩阵，W是上一次的值$\mathrm{s}_{t-1}$作为这一次的输入的<strong>权重矩阵</strong>，f是<strong>激活函数</strong>。</p><p>从上面的公式我们可以看出，<strong>循环层</strong>和<strong>全连接层</strong>的区别就是<strong>循环层</strong>多了一个<strong>权重矩阵</strong> W。</p><p>如果反复把<strong>式2</strong>带入到<strong>式1</strong>，我们将得到：</p><p>$\begin {align}\mathrm{o}_t&amp;=g(V\mathrm{s}_t)\\ &amp;=Vf(U\mathrm{x}_t+W\mathrm{s}_{t-1})\\ &amp;=Vf(U\mathrm{x}_t+Wf(U\mathrm{x}_{t-1}+W\mathrm{s}_{t-2}))\\ &amp;=Vf(U\mathrm{x}_t+Wf(U\mathrm{x}_{t-1}+Wf(U\mathrm{x}_{t-2}+W\mathrm{s}_{t-3})))\\ &amp;=Vf(U\mathrm{x}_t+Wf(U\mathrm{x}_{t-1}+Wf(U\mathrm{x}_{t-2}+Wf(U\mathrm{x}_{t-3}+…)))) \end{align}$</p><p>从上面可以看出，<strong>循环神经网络</strong>的输出值，是受前面历次输入值$\mathrm{x}_{t}$, $\mathrm{x}_{t-1}$…影响的，这就是为什么<strong>循环神经网络</strong>可以往前看任意多个<strong>输入值</strong>的原因。</p><h3 id="双向循环神经网络"><a href="#双向循环神经网络" class="headerlink" title="双向循环神经网络"></a>双向循环神经网络</h3><p>对于<strong>语言模型</strong>来说，很多时候光看前面的词是不够的，比如下面这句话：</p><blockquote><p>我的手机坏了，我打算____一部新手机。</p></blockquote><p>可以想象，如果我们只看横线前面的词，手机坏了，那么我是打算修一修？换一部新的？还是大哭一场？这些都是无法确定的。但如果我们也看到了横线后面的词是『一部新手机』，那么，横线上的词填『买』的概率就大得多了。</p><p>在上一小节中的<strong>基本循环神经网络</strong>是无法对此进行建模的，因此，我们需要<strong>双向循环神经网络</strong>，如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-039a45251aa5d220.png)</p><p>当遇到这种从未来穿越回来的场景时，难免处于懵逼的状态。不过我们还是可以用屡试不爽的老办法：先分析一个特殊场景，然后再总结一般规律。我们先考虑上图中$\mathrm{y}_2$的计算。</p><p>从上图可以看出，<strong>双向卷积神经网络</strong>的隐藏层要保存两个值，一个A参与正向计算，另一个值A’参与反向计算。最终的输出值$\mathrm{y}_2$取决于$A_2$和$A_2’$。其计算方法为：</p><p>$\mathrm{y}_2=g(VA_2+V’A_2’)$</p><p>$A_2$和$A_2’$则分别计算：</p><p>$\begin{align} A_2&amp;=f(WA_1+U\mathrm{x}_2)\\ A_2’&amp;=f(W’A_3’+U’\mathrm{x}_2)\\ \end {align}$</p><p>现在，我们已经可以看出一般的规律：正向计算时，隐藏层的值$s_t$与$s_{t-1}$有关；反向计算时，隐藏层的值$s_t’$与$s_{t+1}’$有关；最终的输出取决于正向和反向计算的<strong>加和</strong>。现在，我们仿照<strong>式1</strong>和<strong>式2</strong>，写出双向循环神经网络的计算方法：</p><p>$\begin{align} \mathrm{o}_t&amp;=g(V\mathrm{s}_t+V’\mathrm{s}_t’)\\ \mathrm{s}_t&amp;=f(U\mathrm{x}_t+W\mathrm{s}_{t-1})\\ \mathrm{s}_t’&amp;=f(U’\mathrm{x}_t+W’\mathrm{s}_{t+1}’)\\ \end {align}$</p><p>从上面三个公式我们可以看到，正向计算和反向计算<strong>不共享权重</strong>，也就是说U和U’、W和W’、V和V’都是不同的<strong>权重矩阵</strong>。</p><h3 id="深度循环神经网络"><a href="#深度循环神经网络" class="headerlink" title="深度循环神经网络"></a>深度循环神经网络</h3><p>前面我们介绍的<strong>循环神经网络</strong>只有一个隐藏层，我们当然也可以堆叠两个以上的隐藏层，这样就得到了<strong>深度循环神经网络</strong>。如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-df137de8007c3d26.png)</p><p>我们把第i个隐藏层的值表示为$\mathrm{s}_t^{(i)}$、$\mathrm{s}_t’^{(i)}$，则<strong>深度循环神经网络</strong>的计算方式可以表示为：</p><p>$\begin{align} \mathrm{o}_t&amp;=g(V^{(i)}\mathrm{s}_t^{(i)}+V’^{(i)}\mathrm{s}_t’^{(i)})\\ \mathrm{s}_t^{(i)}&amp;=f(U^{(i)}\mathrm{s}_t^{(i-1)}+W^{(i)}\mathrm{s}_{t-1})\\ \mathrm{s}_t’^{(i)}&amp;=f(U’^{(i)}\mathrm{s}_t’^{(i-1)}+W’^{(i)}\mathrm{s}_{t+1}’)\\ …\\ \mathrm{s}_t^{(1)}&amp;=f(U^{(1)}\mathrm{x}_t+W^{(1)}\mathrm{s}_{t-1})\\ \mathrm{s}_t’^{(1)}&amp;=f(U’^{(1)}\mathrm{x}_t+W’^{(1)}\mathrm{s}_{t+1}’)\\ \end {align}$</p><h2 id="循环神经网络的训练"><a href="#循环神经网络的训练" class="headerlink" title="循环神经网络的训练"></a>循环神经网络的训练</h2><h3 id="循环神经网络的训练算法：BPTT"><a href="#循环神经网络的训练算法：BPTT" class="headerlink" title="循环神经网络的训练算法：BPTT"></a>循环神经网络的训练算法：BPTT</h3><p>BPTT算法是针对<strong>循环层</strong>的训练算法，它的基本原理和BP算法是一样的，也包含同样的三个步骤：</p><ol><li>前向计算每个神经元的输出值；</li><li>反向计算每个神经元的<strong>误差项</strong>$\delta_j$值，它是误差函数E对神经元j的<strong>加权输入</strong>$net_j$的偏导数；</li><li>计算每个权重的梯度。</li></ol><p>最后再用<strong>随机梯度下降</strong>算法更新权重。</p><p>循环层如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-3b20294694c3904b.png)</p><h4 id="前向计算"><a href="#前向计算" class="headerlink" title="前向计算"></a>前向计算</h4><p>使用前面的<strong>式2</strong>对循环层进行前向计算：</p><p>$ \mathrm{s}_t=f(U\mathrm{x}_t+W\mathrm{s}_{t-1}) $</p><p>注意，上面的$\mathrm{s}_t$、$\mathrm{x}_t$、$\mathrm{s}_{t-1}$都是向量，用<strong>黑体字母</strong>表示；而U、V是<strong>矩阵</strong>，用大写字母表示。<strong>向量的下标</strong>表示<strong>时刻</strong>，例如，${s}_t$表示在t时刻向量s的值。</p><p>我们假设输入向量x的维度是m，输出向量s的维度是n，则矩阵U的维度是$n\times m$，矩阵W的维度是$n\times n$。下面是上式展开成矩阵的样子，看起来更直观一些：</p><p>$\begin{align} \begin{bmatrix} s_1^t\\ s_2^t\\ .\.\\ s_n^t\\ \end{bmatrix}=f( \begin{bmatrix} u_{11} u_{12} … u_{1m}\\ u_{21} u_{22} … u_{2m}\\ .\.\\ u_{n1} u_{n2} … u_{nm}\\ \end{bmatrix} \begin{bmatrix} x_1\\ x_2\\ .\.\\ x_m\\ \end{bmatrix}+ \begin{bmatrix} w_{11} w_{12} … w_{1n}\\ w_{21} w_{22} … w_{2n}\\ .\.\\ w_{n1} w_{n2} … w_{nn}\\ \end{bmatrix} \begin{bmatrix} s_1^{t-1}\\ s_2^{t-1}\\ .\.\\ s_n^{t-1}\\ \end{bmatrix}) \end {align}$</p><p>在这里我们用<strong>手写体字母</strong>表示向量的一个<strong>元素</strong>，它的下标表示它是这个向量的第几个元素，它的上标表示第几个<strong>时刻</strong>。例如，$s_j^t$表示向量s的第j个元素在t时刻的值。$u_{ji}$表示<strong>输入层</strong>第i个神经元到<strong>循环层</strong>第j个神经元的权重。$w_{ji}$表示<strong>循环层</strong>第t-1时刻的第i个神经元到<strong>循环层</strong>第t个时刻的第j个神经元的权重。</p><h4 id="误差项的计算"><a href="#误差项的计算" class="headerlink" title="误差项的计算"></a>误差项的计算</h4><p>BTPP算法将第l层t时刻的<strong>误差项</strong>$\delta_t^l$值沿两个方向传播，一个方向是其传递到上一层网络，得到$\delta_t^{l-1}$，这部分只和权重矩阵U有关；另一个是方向是将其沿时间线传递到初始$t_1$时刻，得到$\delta_1^l$，这部分只和权重矩阵W有关。</p><p>我们用向量$\mathrm{net}_t$表示神经元在t时刻的<strong>加权输入</strong>，因为：</p><p>$\begin{align} \mathrm{net}_t&amp;=U\mathrm{x}_t+W\mathrm{s}_{t-1}\\ \mathrm{s}_{t-1}&amp;=f(\mathrm{net}_{t-1})\\ \end {align} $</p><p>因此：</p><script type="math/tex; mode=display">\begin{align} \frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{net}_{t-1}}}&=\frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{s}_{t-1}}}\frac{\partial{\mathrm{s}_{t-1}}}{\partial{\mathrm{net}_{t-1}}}\\ \end {align}</script><p>我们用a表示列向量，用表示$\mathrm{a}^T$行向量。上式的第一项是向量函数对向量求导，其结果为Jacobian矩阵：</p><p>$\begin{align} \frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{s}_{t-1}}}&amp;= \begin{bmatrix} \frac{\partial{net_1^t}}{\partial{s_1^{t-1}}}&amp; \frac{\partial{net_1^t}}{\partial{s_2^{t-1}}}&amp; …&amp;  \frac{\partial{net_1^t}}{\partial{s_n^{t-1}}}\\ \frac{\partial{net_2^t}}{\partial{s_1^{t-1}}}&amp; \frac{\partial{net_2^t}}{\partial{s_2^{t-1}}}&amp; …&amp;  \frac{\partial{net_2^t}}{\partial{s_n^{t-1}}}\\ &amp;.\\&amp;.\\ \frac{\partial{net_n^t}}{\partial{s_1^{t-1}}}&amp; \frac{\partial{net_n^t}}{\partial{s_2^{t-1}}}&amp; …&amp;  \frac{\partial{net_n^t}}{\partial{s_n^{t-1}}}\\ \end{bmatrix}\\ &amp;=\begin{bmatrix} w_{11} &amp; w_{12} &amp; … &amp; w_{1n}\\ w_{21} &amp; w_{22} &amp; … &amp; w_{2n}\\ &amp;.\\&amp;.\\ w_{n1} &amp; w_{n2} &amp; … &amp; w_{nn}\\ \end{bmatrix}\\ &amp;=W \end {align}$</p><p>同理，上式第二项也是一个Jacobian矩阵：</p><p>$\begin{align} \frac{\partial{\mathrm{s}_{t-1}}}{\partial{\mathrm{net}_{t-1}}}&amp;= \begin{bmatrix} \frac{\partial{s_1^{t-1}}}{\partial{net_1^{t-1}}}&amp; \frac{\partial{s_1^{t-1}}}{\partial{net_2^{t-1}}}&amp; …&amp;  \frac{\partial{s_1^{t-1}}}{\partial{net_n^{t-1}}}\\ \frac{\partial{s_2^{t-1}}}{\partial{net_1^{t-1}}}&amp; \frac{\partial{s_2^{t-1}}}{\partial{net_2^{t-1}}}&amp; …&amp;  \frac{\partial{s_2^{t-1}}}{\partial{net_n^{t-1}}}\\ &amp;.\\&amp;.\\ \frac{\partial{s_n^{t-1}}}{\partial{net_1^{t-1}}}&amp; \frac{\partial{s_n^{t-1}}}{\partial{net_2^{t-1}}}&amp; …&amp;  \frac{\partial{s_n^{t-1}}}{\partial{net_n^{t-1}}}\\ \end{bmatrix}\\ &amp;=\begin{bmatrix} f’(net_1^{t-1}) &amp; 0 &amp; … &amp; 0\\ 0 &amp; f’(net_2^{t-1}) &amp; … &amp; 0\\ &amp;.\\&amp;.\\ 0 &amp; 0 &amp; … &amp; f’(net_n^{t-1})\\ \end{bmatrix}\\ &amp;=diag[f’(\mathrm{net}_{t-1})] \end {align}$</p><p>其中，diag[a]表示根据向量a创建一个对角矩阵，即</p><p>$diag(\mathrm{a})=\begin{bmatrix} a_1 &amp; 0 &amp; … &amp; 0\\ 0 &amp; a_2 &amp; … &amp; 0\\ &amp;.\\&amp;.\\ 0 &amp; 0 &amp; … &amp; a_n\\ \end{bmatrix}\\ $ </p><p>最后，将两项合在一起，可得：</p><p>$\begin{align} \frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{net}_{t-1}}}&amp;=\frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{s}_{t-1}}}\frac{\partial{\mathrm{s}_{t-1}}}{\partial{\mathrm{net}_{t-1}}}\\ &amp;=Wdiag[f’(\mathrm{net}_{t-1})]\\ &amp;=\begin{bmatrix} w_{11}f’(net_1^{t-1}) &amp; w_{12}f’(net_2^{t-1}) &amp; … &amp; w_{1n}f(net_n^{t-1})\\ w_{21}f’(net_1^{t-1}) &amp; w_{22} f’(net_2^{t-1}) &amp; … &amp; w_{2n}f(net_n^{t-1})\\ &amp;.\\&amp;.\\ w_{n1}f’(net_1^{t-1}) &amp; w_{n2} f’(net_2^{t-1}) &amp; … &amp; w_{nn} f’(net_n^{t-1})\\ \end{bmatrix}\\ \end {align}$</p><p>上式描述了将沿时间往前传递一个时刻的规律，有了这个规律，我们就可以求得任意时刻k的<strong>误差项</strong>$\delta_k$：</p><p>$\begin{align} \delta_k^T=&amp;\frac{\partial{E}}{\partial{\mathrm{net}_k}}\\ =&amp;\frac{\partial{E}}{\partial{\mathrm{net}_t}}\frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{net}_k}}\\ =&amp;\frac{\partial{E}}{\partial{\mathrm{net}_t}}\frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{net}_{t-1}}}\frac{\partial{\mathrm{net}_{t-1}}}{\partial{\mathrm{net}_{t-2}}}…\frac{\partial{\mathrm{net}_{k+1}}}{\partial{\mathrm{net}_{k}}}\\ =&amp;Wdiag[f’(\mathrm{net}_{t-1})] Wdiag[f’(\mathrm{net}_{t-2})] … Wdiag[f’(\mathrm{net}_{k})] \delta_t^l\\ =&amp;\delta_t^T\prod_{i=k}^{t-1}Wdiag[f’(\mathrm{net}_{i})]\qquad(式3) \end {align}$</p><p><strong>式3</strong>就是将误差项沿时间反向传播的算法。</p><p><strong>循环层</strong>将<strong>误差项</strong>反向传递到上一层网络，与普通的<strong>全连接层</strong>是完全一样的，这在前面的文章<a href="https://www.zybuluo.com/hanbingtao/note/476663" target="_blank" rel="noopener">零基础入门深度学习(3) - 神经网络和反向传播算法</a>中已经详细讲过了，在此仅简要描述一下。</p><p><strong>循环层</strong>的<strong>加权输入</strong>$\mathrm{net}^l$与上一层的<strong>加权输入</strong>$\mathrm{net}^{l-1}$关系如下：</p><p>$\begin{align} \mathrm{net}_t^l=&amp;U\mathrm{a}_t^{l-1}+W\mathrm{s}_{t-1}\\ \mathrm{a}_t^{l-1}=&amp;f^{l-1}(\mathrm{net}_t^{l-1}) \end {align}$</p><p>上式中$\mathrm{net}_t^l$是第$l$层神经元的<strong>加权输入</strong>(假设第l层是<strong>循环层</strong>)；$\mathrm{net}_t^{l-1}$是第$l-1$层神经元的<strong>加权输入</strong>；$\mathrm{a}_t^{l-1}$是第$l-1$层神经元的输出；$f^{l-1}$是第$l-1$层的<strong>激活函数</strong>。</p><p>$\begin{align} \frac{\partial{\mathrm{net}_t^l}}{\partial{\mathrm{net}_t^{l-1}}}=&amp;\frac{\partial{\mathrm{net}^l}}{\partial{\mathrm{a}_t^{l-1}}}\frac{\partial{\mathrm{a}_t^{l-1}}}{\partial{\mathrm{net}_t^{l-1}}}\\ =&amp;Udiag[f’^{l-1}(\mathrm{net}_t^{l-1})] \end {align}$</p><p>所以，</p><p>$\begin{align} (\delta_t^{l-1})^T=&amp;\frac{\partial{E}}{\partial{\mathrm{net}_t^{l-1}}}\\ =&amp;\frac{\partial{E}}{\partial{\mathrm{net}_t^l}}\frac{\partial{\mathrm{net}_t^l}}{\partial{\mathrm{net}_t^{l-1}}}\\ =&amp;(\delta_t^l)^TUdiag[f’^{l-1}(\mathrm{net}_t^{l-1})]\qquad(式4) \end {align}$</p><p><strong>式4</strong>就是将误差项传递到上一层算法。</p><h4 id="权重梯度的计算"><a href="#权重梯度的计算" class="headerlink" title="权重梯度的计算"></a>权重梯度的计算</h4><p>现在，我们终于来到了BPTT算法的最后一步：计算每个权重的梯度$\frac{\partial{E}}{\partial{W}}$。</p><p>首先，我们计算误差函数E对权重矩阵W的梯度。</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-f7d034c8f05812f7.png)</p><p>上图展示了我们到目前为止，在前两步中已经计算得到的量，包括每个时刻t <strong>循环层</strong>的输出值$s_t$，以及误差项$\sigma_t$。</p><p>回忆一下我们在文章<a href="https://www.zybuluo.com/hanbingtao/note/476663" target="_blank" rel="noopener">零基础入门深度学习(3) - 神经网络和反向传播算法</a>介绍的全连接网络的权重梯度计算算法：只要知道了任意一个时刻的<strong>误差项</strong>$\sigma_t$，以及上一个时刻循环层的输出值$s_{t-1}$，就可以按照下面的公式求出权重矩阵在$t$时刻的梯度$\nabla_{Wt}E$：</p><p>$\begin{align}\nabla_{W_t}E=\begin{bmatrix} \delta_1^ts_1^{t-1} &amp; \delta_1^ts_2^{t-1} &amp; … &amp;  \delta_1^ts_n^{t-1}\\ \delta_2^ts_1^{t-1} &amp; \delta_2^ts_2^{t-1} &amp; … &amp;  \delta_2^ts_n^{t-1}\\ .\.\\ \delta_n^ts_1^{t-1} &amp; \delta_n^ts_2^{t-1} &amp; … &amp;  \delta_n^ts_n^{t-1}\\ \end{bmatrix}\qquad(式5)\end {align}$</p><p>在<strong>式5</strong>中，$\delta_i^t$表示t时刻<strong>误差项</strong>向量的第$i$个分量；$s_i^{t-1}$表示$t-1$时刻<strong>循环层</strong>第$i$个神经元的输出值。</p><p>我们下面可以简单推导一下<strong>式5</strong>。</p><p>我们知道：</p><p>$\begin{align} \mathrm{net}_t=&amp;U\mathrm{x}_t+W\mathrm{s}_{t-1}\\ \begin{bmatrix} net_1^t\\ net_2^t\\ .\.\\ net_n^t\\ \end{bmatrix}=&amp;U\mathrm{x}_t+ \begin{bmatrix} w_{11} &amp; w_{12} &amp; … &amp; w_{1n}\\ w_{21} &amp; w_{22} &amp; … &amp; w_{2n}\\ .\.\\ w_{n1} &amp; w_{n2} &amp; … &amp; w_{nn}\\ \end{bmatrix} \begin{bmatrix} s_1^{t-1}\\ s_2^{t-1}\\ .\.\\ s_n^{t-1}\\ \end{bmatrix}\\ =&amp;U\mathrm{x}_t+ \begin{bmatrix} w_{11}s_1^{t-1}+w_{12}s_2^{t-1}…w_{1n}s_n^{t-1}\\ w_{21}s_1^{t-1}+w_{22}s_2^{t-1}…w_{2n}s_n^{t-1}\\ .\.\\ w_{n1}s_1^{t-1}+w_{n2}s_2^{t-1}…w_{nn}s_n^{t-1}\\ \end{bmatrix}\\ \end {align}$</p><p>因为对W求导与$U\mathrm{x}_t$无关，我们不再考虑。现在，我们考虑对权重项$w_{ji}$求导。通过观察上式我们可以看到$w_{ji}$只与$net_j^t$有关，所以：</p><p>$\begin{align} \frac{\partial{E}}{\partial{w_{ji}}}=&amp;\frac{\partial{E}}{\partial{net_j^t}}\frac{\partial{net_j^t}}{\partial{w_{ji}}}\\ =&amp;\delta_j^ts_i^{t-1} \end {align}$</p><p>按照上面的规律就可以生成<strong>式5</strong>里面的矩阵。</p><p>我们已经求得了权重矩阵W在t时刻的梯度$\nabla_{Wt}E$，最终的梯度$\nabla_WE$是各个时刻的梯度<strong>之和</strong>：</p><p>$\begin{align} \nabla_WE=&amp;\sum_{i=1}^t\nabla_{W_i}E\\ =&amp;\begin{bmatrix} \delta_1^ts_1^{t-1} &amp; \delta_1^ts_2^{t-1} &amp; … &amp;  \delta_1^ts_n^{t-1}\\ \delta_2^ts_1^{t-1} &amp; \delta_2^ts_2^{t-1} &amp; … &amp;  \delta_2^ts_n^{t-1}\\ .\.\\ \delta_n^ts_1^{t-1} &amp; \delta_n^ts_2^{t-1} &amp; … &amp;  \delta_n^ts_n^{t-1}\\ \end{bmatrix} +…+ \begin{bmatrix} \delta_1^1s_1^0 &amp; \delta_1^1s_2^0 &amp; … &amp;  \delta_1^1s_n^0\\ \delta_2^1s_1^0 &amp; \delta_2^1s_2^0 &amp; … &amp;  \delta_2^1s_n^0\\ .\.\\ \delta_n^1s_1^0 &amp; \delta_n^1s_2^0 &amp; … &amp;  \delta_n^1s_n^0\\ \end{bmatrix}\qquad(式6) \end{align} $</p><p><strong>式6</strong>就是计算<strong>循环层</strong>权重矩阵W的梯度的公式。</p><pre><code>----------数学公式超高能预警----------</code></pre><p>前面已经介绍了$\nabla_WE$的计算方法，看上去还是比较直观的。然而，读者也许会困惑，为什么最终的梯度是各个时刻的梯度<strong>之和</strong>呢？我们前面只是直接用了这个结论，实际上这里面是有道理的，只是这个数学推导比较绕脑子。感兴趣的同学可以仔细阅读接下来这一段，它用到了矩阵对矩阵求导、张量与向量相乘运算的一些法则。</p><p>我们还是从这个式子开始：</p><p>$ \begin {align}\mathrm{net}_t=U\mathrm{x}_t+Wf(\mathrm{net}_{t-1}) \end {align} $</p><p>因为$U\mathrm{x}_t$与W完全无关，我们把它看做常量。现在，考虑第一个式子加号右边的部分，因为W和$f(\mathrm{net}_{t-1})$都是W的函数，因此我们要用到大学里面都学过的导数乘法运算：</p><p>$ \begin{align}(uv)’=u’v+uv’ \end {align}$</p><p>因此，上面第一个式子写成：</p><p>$ \begin{align} \frac{\partial{\mathrm{net}_t}}{\partial{W}}=\frac{\partial{W}}{\partial{W}}f(\mathrm{net}_{t-1})+W\frac{\partial{f(\mathrm{net}_{t-1})}}{\partial{W}}\\ \end{align} $</p><p>我们最终需要计算的是$\nabla_WE$：</p><p>$\begin{align} \nabla_WE=&amp;\frac{\partial{E}}{\partial{W}}\\ =&amp;\frac{\partial{E}}{\partial{\mathrm{net}_t}}\frac{\partial{\mathrm{net}_t}}{\partial{W}}\\ =&amp;\delta_t^T\frac{\partial{W}}{\partial{W}}f(\mathrm{net}_{t-1})+ \delta_t^TW\frac{\partial{f(\mathrm{net}_{t-1})}}{\partial{W}}\qquad(式7)\\ \end{align} $</p><p>我们先计算<strong>式7</strong>加号左边的部分。$\frac{\partial{W}}{\partial{W}}$是<strong>矩阵对矩阵求导</strong>，其结果是一个四维<strong>张量(tensor)</strong>，如下所示：</p><p>$\begin{align} \frac{\partial{W}}{\partial{W}}=&amp; \begin{bmatrix} \frac{\partial{w_{11}}}{\partial{W}} &amp; \frac{\partial{w_{12}}}{\partial{W}} &amp; … &amp; \frac{\partial{w_{1n}}}{\partial{W}}\\ \frac{\partial{w_{21}}}{\partial{W}} &amp; \frac{\partial{w_{22}}}{\partial{W}} &amp; … &amp; \frac{\partial{w_{2n}}}{\partial{W}}\\ .\.\\ \frac{\partial{w_{n1}}}{\partial{W}} &amp; \frac{\partial{w_{n2}}}{\partial{W}} &amp; … &amp; \frac{\partial{w_{nn}}}{\partial{W}}\\ \end{bmatrix}\\ =&amp; \begin{bmatrix} \begin{bmatrix} \frac{\partial{w_{11}}}{\partial{w_{11}}} &amp; \frac{\partial{w_{11}}}{\partial{w_{12}}} &amp; … &amp; \frac{\partial{w_{11}}}{\partial{_{1n}}}\\ \frac{\partial{w_{11}}}{\partial{w_{21}}} &amp; \frac{\partial{w_{11}}}{\partial{w_{22}}} &amp; … &amp; \frac{\partial{w_{11}}}{\partial{_{2n}}}\\ .\.\\ \frac{\partial{w_{11}}}{\partial{w_{n1}}} &amp; \frac{\partial{w_{11}}}{\partial{w_{n2}}} &amp; … &amp; \frac{\partial{w_{11}}}{\partial{_{nn}}}\\ \end{bmatrix} &amp; \begin{bmatrix} \frac{\partial{w_{12}}}{\partial{w_{11}}} &amp; \frac{\partial{w_{12}}}{\partial{w_{12}}} &amp; … &amp; \frac{\partial{w_{12}}}{\partial{_{1n}}}\\ \frac{\partial{w_{12}}}{\partial{w_{21}}} &amp; \frac{\partial{w_{12}}}{\partial{w_{22}}} &amp; … &amp; \frac{\partial{w_{12}}}{\partial{_{2n}}}\\ .\.\\ \frac{\partial{w_{12}}}{\partial{w_{n1}}} &amp; \frac{\partial{w_{12}}}{\partial{w_{n2}}} &amp; … &amp; \frac{\partial{w_{12}}}{\partial{_{nn}}}\\ \end{bmatrix}&amp;…\\ .\.\\ \end{bmatrix}\\ =&amp; \begin{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; … &amp; 0\\ 0 &amp; 0 &amp; … &amp; 0\\ .\.\\ 0 &amp; 0 &amp; … &amp; 0\\ \end{bmatrix} &amp; \begin{bmatrix} 0 &amp; 1 &amp; … &amp; 0\\ 0 &amp; 0 &amp; … &amp; 0\\ .\.\\ 0 &amp; 0 &amp; … &amp; 0\\ \end{bmatrix}&amp;…\\ .\.\\ \end{bmatrix}\\ \end{align} $</p><p>接下来，我们知道$s_{t-1}=f({\mathrm{net}_{t-1}})$，它是一个<strong>列向量</strong>。我们让上面的四维张量与这个向量相乘，得到了一个三维张量，再左乘行向量$\delta_t^T$，最终得到一个矩阵：</p><p>$\begin{align} \delta_t^T\frac{\partial{W}}{\partial{W}}f({\mathrm{net}_{t-1}})=&amp; \delta_t^T\frac{\partial{W}}{\partial{W}}{\mathrm{s}_{t-1}}\\ =&amp;\delta_t^T \begin{bmatrix} \begin{bmatrix} 1 &amp; 0 &amp; … &amp; 0\\ 0 &amp; 0 &amp; … &amp; 0\\ .\.\\ 0 &amp; 0 &amp; … &amp; 0\\ \end{bmatrix} &amp; \begin{bmatrix} 0 &amp; 1 &amp; … &amp; 0\\ 0 &amp; 0 &amp; … &amp; 0\\ .\.\\ 0 &amp; 0 &amp; … &amp; 0\\ \end{bmatrix}&amp;…\\ .\.\\ \end{bmatrix} \begin{bmatrix} s_1^{t-1}\\ s_2^{t-1}\\ .\.\\ s_n^{t-1}\\ \end{bmatrix}\\ =&amp;\delta_t^T \begin{bmatrix} \begin{bmatrix} s_1^{t-1}\\ 0\\ .\.\\ 0\\ \end{bmatrix} &amp; \begin{bmatrix} s_2^{t-1}\\ 0\\ .\.\\ 0\\ \end{bmatrix}&amp;…\\ .\.\\ \end{bmatrix}\\ =&amp; \begin{bmatrix} \delta_1^t &amp; \delta_2^t &amp; … &amp;\delta_n^t \end{bmatrix} \begin{bmatrix} \begin{bmatrix} s_1^{t-1}\\ 0\\ .\.\\ 0\\ \end{bmatrix} &amp; \begin{bmatrix} s_2^{t-1}\\ 0\\ .\.\\ 0\\ \end{bmatrix}&amp;…\\ .\.\\ \end{bmatrix}\\ =&amp; \begin{bmatrix} \delta_1^ts_1^{t-1} &amp; \delta_1^ts_2^{t-1} &amp; … &amp;  \delta_1^ts_n^{t-1}\\ \delta_2^ts_1^{t-1} &amp; \delta_2^ts_2^{t-1} &amp; … &amp;  \delta_2^ts_n^{t-1}\\ .\.\\ \delta_n^ts_1^{t-1} &amp; \delta_n^ts_2^{t-1} &amp; … &amp;  \delta_n^ts_n^{t-1}\\ \end{bmatrix}\\ =&amp;\nabla_{Wt}E \end{align} $</p><p>接下来，我们计算<strong>式7</strong>加号右边的部分：</p><p>$\begin{align} \delta_t^TW\frac{\partial{f(\mathrm{net}_{t-1})}}{\partial{W}}=&amp; \delta_t^TW\frac{\partial{f(\mathrm{net}_{t-1})}}{\partial{\mathrm{net}_{t-1}}}\frac{\partial{\mathrm{net}_{t-1}}}{\partial{W}}\\ =&amp;\delta_t^TWf’(\mathrm{net}_{t-1})\frac{\partial{\mathrm{net}_{t-1}}}{\partial{W}}\\ =&amp;\delta_t^T\frac{\partial{\mathrm{net}_t}}{\partial{\mathrm{net}_{t-1}}}\frac{\partial{\mathrm{net}_{t-1}}}{\partial{W}}\\ =&amp;\delta_{t-1}^T\frac{\partial{\mathrm{net}_{t-1}}}{\partial{W}}\\ \end{align} $</p><p>于是，我们得到了如下递推公式：</p><p>$\begin{align} \nabla_WE=&amp;\frac{\partial{E}}{\partial{W}}\\ =&amp;\frac{\partial{E}}{\partial{\mathrm{net}_t}}\frac{\partial{\mathrm{net}_t}}{\partial{W}}\\ =&amp;\nabla_{Wt}E+\delta_{t-1}^T\frac{\partial{\mathrm{net}_{t-1}}}{\partial{W}}\\ =&amp;\nabla_{Wt}E+\nabla_{Wt-1}E+\delta_{t-2}^T\frac{\partial{\mathrm{net}_{t-2}}}{\partial{W}}\\ =&amp;\nabla_{Wt}E+\nabla_{Wt-1}E+…+\nabla_{W1}E\\ =&amp;\sum_{k=1}^t\nabla_{Wk}E \end{align} $</p><p>这样，我们就证明了：最终的梯度是各个时刻的梯度$\nabla_WE$之和。</p><pre><code>----------数学公式超高能预警解除----------</code></pre><p>同权重矩阵W类似，我们可以得到权重矩阵U的计算方法。</p><p>$\begin{align}\nabla_{U_t}E=\begin{bmatrix} \delta_1^tx_1^t &amp; \delta_1^tx_2^t &amp; … &amp;  \delta_1^tx_m^t\\ \delta_2^tx_1^t &amp; \delta_2^tx_2^t &amp; … &amp;  \delta_2^tx_m^t\\ .\.\\ \delta_n^tx_1^t &amp; \delta_n^tx_2^t &amp; … &amp;  \delta_n^tx_m^t\\ \end{bmatrix}\qquad(式8) \end{align} $</p><p><strong>式8</strong>是误差函数在t时刻对权重矩阵U的梯度。和权重矩阵W一样，最终的梯度也是各个时刻的梯度之和：</p><p>$\begin{align}\nabla_UE=\sum_{i=1}^t\nabla_{U_i}E \end{align} $</p><p>具体的证明这里就不再赘述了，感兴趣的读者可以练习推导一下。</p><h3 id="RNN的梯度爆炸和消失问题"><a href="#RNN的梯度爆炸和消失问题" class="headerlink" title="RNN的梯度爆炸和消失问题"></a>RNN的梯度爆炸和消失问题</h3><p>不幸的是，实践中前面介绍的几种RNNs并不能很好的处理较长的序列。一个主要的原因是，RNN在训练中很容易发生<strong>梯度爆炸</strong>和<strong>梯度消失</strong>，这导致训练时梯度不能在较长序列中一直传递下去，从而使RNN无法捕捉到长距离的影响。</p><p>为什么RNN会产生梯度爆炸和消失问题呢？我们接下来将详细分析一下原因。我们根据<strong>式3</strong>可得：</p><p>$\begin{align} \delta_k^T=&amp;\delta_t^T\prod_{i=k}^{t-1}Wdiag[f’(\mathrm{net}_{i})]\\ |\delta_k^T|\leqslant&amp;|\delta_t^T|\prod_{i=k}^{t-1}|W||diag[f’(\mathrm{net}_{i})]|\\ \leqslant&amp;|\delta_t^T|(\beta_W\beta_f)^{t-k} \end{align} $</p><p>上式的$\beta$定义为矩阵的模的上界。因为上式是一个指数函数，如果t-k很大的话（也就是向前看很远的时候），会导致对应的<strong>误差项</strong>的值增长或缩小的非常快，这样就会导致相应的<strong>梯度爆炸</strong>和<strong>梯度消失</strong>问题（取决于大$\beta$于1还是小于1）。</p><p>通常来说，<strong>梯度爆炸</strong>更容易处理一些。因为梯度爆炸的时候，我们的程序会收到NaN错误。我们也可以设置一个梯度阈值，当梯度超过这个阈值的时候可以直接截取。</p><p><strong>梯度消失</strong>更难检测，而且也更难处理一些。总的来说，我们有三种方法应对梯度消失问题：</p><ol><li>合理的初始化权重值。初始化权重，使每个神经元尽可能不要取极大或极小值，以躲开梯度消失的区域。</li><li>使用relu代替sigmoid和tanh作为激活函数。原理请参考上一篇文章<a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="noopener">零基础入门深度学习(4) - 卷积神经网络</a>的<strong>激活函数</strong>一节。</li><li>使用其他结构的RNNs，比如长短时记忆网络（LTSM）和Gated Recurrent Unit（GRU），这是最流行的做法。我们将在以后的文章中介绍这两种网络。</li></ol><h2 id="RNN的应用举例——基于RNN的语言模型"><a href="#RNN的应用举例——基于RNN的语言模型" class="headerlink" title="RNN的应用举例——基于RNN的语言模型"></a>RNN的应用举例——基于RNN的语言模型</h2><p>现在，我们介绍一下基于RNN语言模型。我们首先把词依次输入到循环神经网络中，每输入一个词，循环神经网络就输出截止到目前为止，下一个最可能的词。例如，当我们依次输入：</p><blockquote><p>我 昨天 上学 迟到 了</p></blockquote><p>神经网络的输出如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-a69765380a75f860.png)</p><p>其中，s和e是两个特殊的词，分别表示一个序列的开始和结束。</p><h3 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h3><p>我们知道，神经网络的输入和输出都是<strong>向量</strong>，为了让语言模型能够被神经网络处理，我们必须把词表达为向量的形式，这样神经网络才能处理它。</p><p>神经网络的输入是<strong>词</strong>，我们可以用下面的步骤对输入进行<strong>向量化</strong>：</p><ol><li>建立一个包含所有词的词典，每个词在词典里面有一个唯一的编号。</li><li>任意一个词都可以用一个N维的one-hot向量来表示。其中，N是词典中包含的词的个数。假设一个词在词典中的编号是i，v是表示这个词的向量，$v_j$是向量的第j个元素，则：</li></ol><p>$v_j=\begin{equation}\begin{cases}1\qquad j=i\\0\qquad j\ne i\end{cases}\end{equation} $</p><p>上面这个公式的含义，可以用下面的图来直观的表示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-14ae8b4f92e90c5c.png)</p><p>使用这种向量化方法，我们就得到了一个高维、<strong>稀疏</strong>的向量（稀疏是指绝大部分元素的值都是0）。处理这样的向量会导致我们的神经网络有很多的参数，带来庞大的计算量。因此，往往会需要使用一些降维方法，将高维的稀疏向量转变为低维的稠密向量。不过这个话题我们就不再这篇文章中讨论了。</p><p>语言模型要求的输出是下一个最可能的词，我们可以让循环神经网络计算计算词典中每个词是下一个词的概率，这样，概率最大的词就是下一个最可能的词。因此，神经网络的输出向量也是一个N维向量，向量中的每个元素对应着词典中相应的词是下一个词的概率。如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-3e1562c7031309f1.png)</p><h3 id="Softmax层"><a href="#Softmax层" class="headerlink" title="Softmax层"></a>Softmax层</h3><p>前面提到，<strong>语言模型</strong>是对下一个词出现的<strong>概率</strong>进行建模。那么，怎样让神经网络输出概率呢？方法就是用softmax层作为神经网络的输出层。</p><p>我们先来看一下softmax函数的定义：</p><p>$\begin{align} g(z_i)=\frac{e^{z_i}}{\sum_{k}e^{z_k}} \end{align}$</p><p>这个公式看起来可能很晕，我们举一个例子。Softmax层如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-5a3219fab80ab45f.png)</p><p>从上图我们可以看到，softmax layer的输入是一个向量，输出也是一个向量，两个向量的维度是一样的（在这个例子里面是4）。输入向量x=[1 2 3 4]经过softmax层之后，经过上面的softmax函数计算，转变为输出向量y=[0.03 0.09 0.24 0.64]。计算过程为：</p><p>$\begin{align} y_1&amp;=\frac{e^{x_1}}{\sum_{k}e^{x_k}}\\ &amp;=\frac{e^1}{e^1+e^2+e^3+e^4}\\ &amp;=0.03\\ y_2&amp;=\frac{e^2}{e^1+e^2+e^3+e^4}\\ &amp;=0.09\\ y_3&amp;=\frac{e^3}{e^1+e^2+e^3+e^4}\\ &amp;=0.24\\ y_4&amp;=\frac{e^4}{e^1+e^2+e^3+e^4}\\ &amp;=0.64\\ \end{align} $</p><p>我们来看看输出向量y的特征：</p><ol><li>每一项为取值为0-1之间的正数；</li><li>所有项的总和是1。</li></ol><p>我们不难发现，这些特征和<strong>概率</strong>的特征是一样的，因此我们可以把它们看做是概率。对于<strong>语言模型</strong>来说，我们可以认为模型预测下一个词是词典中第一个词的概率是0.03，是词典中第二个词的概率是0.09，以此类推。</p><h3 id="语言模型的训练"><a href="#语言模型的训练" class="headerlink" title="语言模型的训练"></a>语言模型的训练</h3><p>可以使用<strong>监督学习</strong>的方法对语言模型进行训练，首先，需要准备训练数据集。接下来，我们介绍怎样把语料</p><blockquote><p>我 昨天 上学 迟到 了</p></blockquote><p>转换成语言模型的训练数据集。</p><p>首先，我们获取<strong>输入-标签</strong>对：</p><div class="table-container"><table><thead><tr><th style="text-align:center">输入</th><th style="text-align:center">标签</th></tr></thead><tbody><tr><td style="text-align:center">s</td><td style="text-align:center">我</td></tr><tr><td style="text-align:center">我</td><td style="text-align:center">昨天</td></tr><tr><td style="text-align:center">昨天</td><td style="text-align:center">上学</td></tr><tr><td style="text-align:center">上学</td><td style="text-align:center">迟到</td></tr><tr><td style="text-align:center">迟到</td><td style="text-align:center">了</td></tr><tr><td style="text-align:center">了</td><td style="text-align:center">e</td></tr></tbody></table></div><p>然后，使用前面介绍过的<strong>向量化</strong>方法，对输入x和标签y进行<strong>向量化</strong>。这里面有意思的是，对标签y进行向量化，其结果也是一个one-hot向量。例如，我们对标签『我』进行向量化，得到的向量中，只有第2019个元素的值是1，其他位置的元素的值都是0。它的含义就是下一个词是『我』的概率是1，是其它词的概率都是0。</p><p>最后，我们使用<strong>交叉熵误差函数</strong>作为优化目标，对模型进行优化。</p><p>在实际工程中，我们可以使用大量的语料来对模型进行训练，获取训练数据和训练的方法都是相同的。</p><h3 id="交叉熵误差"><a href="#交叉熵误差" class="headerlink" title="交叉熵误差"></a>交叉熵误差</h3><p>一般来说，当神经网络的输出层是softmax层时，对应的误差函数E通常选择交叉熵误差函数，其定义如下：</p><p>$\begin{align} L(y,o)=-\frac{1}{N}\sum_{n\in{N}}{y_nlogo_n}  \end{align}$</p><p>在上式中，N是训练样本的个数，向量$y_n$是样本的标记，向量$o_n$是网络的输出。标记$y_n$是一个one-hot向量，例如$y_1=[1,0,0,0]$，如果网络的输出$o=[0.03,0.09,0.24,0.64]$，那么，交叉熵误差是（假设只有一个训练样本，即N=1）：</p><p>$\begin{align} L&amp;=-\frac{1}{N}\sum_{n\in{N}}{y_nlogo_n}\\ &amp;=-y_1logo_1\\ &amp;=-(1<em>log0.03+0</em>log0.09+0<em>log0.24+0</em>log0.64)\\ &amp;=3.51 \end{align} $</p><p>我们当然可以选择其他函数作为我们的误差函数，比如最小平方误差函数(MSE)。不过对概率进行建模时，选择交叉熵误差函数更make sense。具体原因，感兴趣的读者请阅读<a href="https://jamesmccaffrey.wordpress.com/2011/12/17/neural-network-classification-categorical-data-softmax-activation-and-cross-entropy-error/" target="_blank" rel="noopener">参考文献7</a>。</p><h2 id="RNN的实现"><a href="#RNN的实现" class="headerlink" title="RNN的实现"></a>RNN的实现</h2><blockquote><p>完整代码请参考GitHub: <a href="https://github.com/hanbt/learn_dl/blob/master/rnn.py" target="_blank" rel="noopener">https://github.com/hanbt/learn_dl/blob/master/rnn.py</a> (python2.7)</p></blockquote><p>为了加深我们对前面介绍的知识的理解，我们来动手实现一个RNN层。我们复用了上一篇文章<a href="https://www.zybuluo.com/hanbingtao/note/485480" target="_blank" rel="noopener">零基础入门深度学习(4) - 卷积神经网络</a>中的一些代码，所以先把它们导入进来。</p><pre class=" language-lang-python"><code class="language-lang-python">import numpy as npfrom cnn import ReluActivator, IdentityActivator, element_wise_op</code></pre><p>我们用RecurrentLayer类来实现一个<strong>循环层</strong>。下面的代码是初始化一个循环层，可以在构造函数中设置卷积层的超参数。我们注意到，循环层有两个权重数组，U和W。</p><pre class=" language-lang-python"><code class="language-lang-python">class RecurrentLayer(object):    def __init__(self, input_width, state_width,                 activator, learning_rate):        self.input_width = input_width        self.state_width = state_width        self.activator = activator        self.learning_rate = learning_rate        self.times = 0       # 当前时刻初始化为t0        self.state_list = [] # 保存各个时刻的state        self.state_list.append(np.zeros(            (state_width, 1)))           # 初始化s0        self.U = np.random.uniform(-1e-4, 1e-4,            (state_width, input_width))  # 初始化U        self.W = np.random.uniform(-1e-4, 1e-4,            (state_width, state_width))  # 初始化W</code></pre><p>在forward方法中，实现循环层的前向计算，这部分比较简单。</p><pre class=" language-lang-python"><code class="language-lang-python">    def forward(self, input_array):        '''        根据『式2』进行前向计算        '''        self.times += 1        state = (np.dot(self.U, input_array) +                 np.dot(self.W, self.state_list[-1]))        element_wise_op(state, self.activator.forward)        self.state_list.append(state)</code></pre><p>在backword方法中，实现BPTT算法。</p><pre class=" language-lang-python"><code class="language-lang-python">    def backward(self, sensitivity_array,                      activator):            '''            实现BPTT算法            '''            self.calc_delta(sensitivity_array, activator)            self.calc_gradient()    def calc_delta(self, sensitivity_array, activator):        self.delta_list = []  # 用来保存各个时刻的误差项        for i in range(self.times):            self.delta_list.append(np.zeros(                (self.state_width, 1)))        self.delta_list.append(sensitivity_array)        # 迭代计算每个时刻的误差项        for k in range(self.times - 1, 0, -1):            self.calc_delta_k(k, activator)    def calc_delta_k(self, k, activator):        '''        根据k+1时刻的delta计算k时刻的delta        '''        state = self.state_list[k+1].copy()        element_wise_op(self.state_list[k+1],                    activator.backward)        self.delta_list[k] = np.dot(            np.dot(self.delta_list[k+1].T, self.W),            np.diag(state[:,0])).T    def calc_gradient(self):        self.gradient_list = [] # 保存各个时刻的权重梯度        for t in range(self.times + 1):            self.gradient_list.append(np.zeros(                (self.state_width, self.state_width)))        for t in range(self.times, 0, -1):            self.calc_gradient_t(t)        # 实际的梯度是各个时刻梯度之和        self.gradient = reduce(            lambda a, b: a + b, self.gradient_list,            self.gradient_list[0]) # [0]被初始化为0且没有被修改过    def calc_gradient_t(self, t):        '''        计算每个时刻t权重的梯度        '''        gradient = np.dot(self.delta_list[t],            self.state_list[t-1].T)        self.gradient_list[t] = gradient</code></pre><p>有意思的是，BPTT算法虽然数学推导的过程很麻烦，但是写成代码却并不复杂。</p><p>在update方法中，实现梯度下降算法。</p><pre class=" language-lang-python"><code class="language-lang-python">    def update(self):        '''        按照梯度下降，更新权重        '''        self.W -= self.learning_rate * self.gradient</code></pre><p>上面的代码不包含权重U的更新。这部分实际上和全连接神经网络是一样的，留给感兴趣的读者自己来完成吧。</p><p><strong>循环层</strong>是一个<strong>带状态</strong>的层，每次forword都会改变循环层的内部状态，这给梯度检查带来了麻烦。因此，我们需要一个reset_state方法，来重置循环层的内部状态。</p><pre class=" language-lang-python"><code class="language-lang-python">    def reset_state(self):        self.times = 0       # 当前时刻初始化为t0        self.state_list = [] # 保存各个时刻的state        self.state_list.append(np.zeros(            (self.state_width, 1)))      # 初始化s0</code></pre><p>最后，是梯度检查的代码。</p><pre class=" language-lang-python"><code class="language-lang-python">def gradient_check():    '''    梯度检查    '''    # 设计一个误差函数，取所有节点输出项之和    error_function = lambda o: o.sum()    rl = RecurrentLayer(3, 2, IdentityActivator(), 1e-3)    # 计算forward值    x, d = data_set()    rl.forward(x[0])    rl.forward(x[1])    # 求取sensitivity map    sensitivity_array = np.ones(rl.state_list[-1].shape,                                dtype=np.float64)    # 计算梯度    rl.backward(sensitivity_array, IdentityActivator())    # 检查梯度    epsilon = 10e-4    for i in range(rl.W.shape[0]):        for j in range(rl.W.shape[1]):            rl.W[i,j] += epsilon            rl.reset_state()            rl.forward(x[0])            rl.forward(x[1])            err1 = error_function(rl.state_list[-1])            rl.W[i,j] -= 2*epsilon            rl.reset_state()            rl.forward(x[0])            rl.forward(x[1])            err2 = error_function(rl.state_list[-1])            expect_grad = (err1 - err2) / (2 * epsilon)            rl.W[i,j] += epsilon            print 'weights(%d,%d): expected - actural %f - %f' % (                i, j, expect_grad, rl.gradient[i,j])</code></pre><p>需要注意，每次计算error之前，都要调用reset_state方法重置循环层的内部状态。下面是梯度检查的结果，没问题！</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-1bdfa618b5dbaabd.png)</p><h2 id="小节"><a href="#小节" class="headerlink" title="小节"></a>小节</h2><p>至此，我们讲完了基本的<strong>循环神经网络</strong>、它的训练算法：<strong>BPTT</strong>，以及在语言模型上的应用。RNN比较烧脑，相信拿下前几篇文章的读者们搞定这篇文章也不在话下吧！然而，<strong>循环神经网络</strong>这个话题并没有完结。我们在前面说到过，基本的循环神经网络存在梯度爆炸和梯度消失问题，并不能真正的处理好长距离的依赖（虽然有一些技巧可以减轻这些问题）。事实上，真正得到广泛的应用的是循环神经网络的一个变体：<strong>长短时记忆网络</strong>。它内部有一些特殊的结构，可以很好的处理长距离的依赖，我们将在下一篇文章中详细的介绍它。现在，让我们稍事休息，准备挑战更为烧脑的<strong>长短时记忆网络</strong>吧。</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(5" alt="img">%20-%20%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/2256672-253fd3d6688ea73e.jpg)</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/" target="_blank" rel="noopener">RECURRENT NEURAL NETWORKS TUTORIAL</a></li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li><li><a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a></li><li><a href="http://distill.pub/2016/augmented-rnns/" target="_blank" rel="noopener">Attention and Augmented Recurrent Neural Networks</a></li><li><a href="http://www.jmlr.org/proceedings/papers/v28/pascanu13.pdf" target="_blank" rel="noopener">On the difficulty of training recurrent neural networks, Bengio et al.</a></li><li><a href="http://www.fit.vutbr.cz/research/groups/speech/publi/2010/mikolov_interspeech2010_IS100722.pdf" target="_blank" rel="noopener">Recurrent neural network based language model, Mikolov et al.</a></li><li><a href="https://jamesmccaffrey.wordpress.com/2011/12/17/neural-network-classification-categorical-data-softmax-activation-and-cross-entropy-error/" target="_blank" rel="noopener">Neural Network Classification, Categorical Data, Softmax Activation, and Cross Entropy Error, McCaffrey</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>零基础入门深度学习-长短时记忆网络</title>
      <link href="/ling-ji-chu-ru-men-shen-du-xue-xi-6-chang-duan-shi-ji-yi-wang-luo-lstm/"/>
      <url>/ling-ji-chu-ru-men-shen-du-xue-xi-6-chang-duan-shi-ji-yi-wang-luo-lstm/</url>
      
        <content type="html"><![CDATA[<p>参考资料：<a href="https://www.zybuluo.com/hanbingtao/note/581764" target="_blank" rel="noopener">https://www.zybuluo.com/hanbingtao/note/581764</a></p><hr><h2 id="往期回顾"><a href="#往期回顾" class="headerlink" title="往期回顾"></a>往期回顾</h2><p>在上一篇文章中，我们介绍了<strong>循环神经网络</strong>以及它的训练算法。我们也介绍了<strong>循环神经网络</strong>很难训练的原因，这导致了它在实际应用中，很难处理长距离的依赖。在本文中，我们将介绍一种改进之后的循环神经网络：<strong>长短时记忆网络(Long Short Term Memory Network, LSTM)</strong>，它成功的解决了原始循环神经网络的缺陷，成为当前最流行的RNN，在语音识别、图片描述、自然语言处理等许多领域中成功应用。但不幸的一面是，<strong>LSTM</strong>的结构很复杂，因此，我们需要花上一些力气，才能把LSTM以及它的训练算法弄明白。在搞清楚<strong>LSTM</strong>之后，我们再介绍一种<strong>LSTM</strong>的变体：<strong>GRU (Gated Recurrent Unit)</strong>。 它的结构比<strong>LSTM</strong>简单，而效果却和<strong>LSTM</strong>一样好，因此，它正在逐渐流行起来。最后，我们仍然会动手实现一个<strong>LSTM</strong>。</p><h2 id="长短时记忆网络是啥"><a href="#长短时记忆网络是啥" class="headerlink" title="长短时记忆网络是啥"></a>长短时记忆网络是啥</h2><p>我们首先了解一下长短时记忆网络产生的背景。回顾一下<a href="https://zybuluo.com/hanbingtao/note/541458" target="_blank" rel="noopener">零基础入门深度学习(5) - 循环神经网络</a>中推导的，误差项沿时间反向传播的公式：</p><p>$\begin{align} \delta_k^T=&amp;\delta_t^T\prod_{i=k}^{t-1}diag[f’(\mathbf{net}_{i})]W\\ \end{align} $</p><p>我们可以根据下面的不等式，来获取$\delta_k^T$的模的上界（模可以看做对$\delta_k^T$中每一项值的大小的度量）：</p><p>$\begin{align} |\delta_k^T|\leqslant&amp;|\delta_t^T|\prod_{i=k}^{t-1}|diag[f’(\mathbf{net}_{i})]||W|\\ \leqslant&amp;|\delta_t^T|(\beta_f\beta_W)^{t-k} \end{align} $</p><p>我们可以看到，误差项$\delta$从t时刻传递到k时刻，其值的上界是$\beta_f\beta_w$的指数函数。$\beta_f\beta_w$分别是对角矩阵$diag[f’(\mathbf{net}_{i})]$和矩阵W模的上界。显然，除非乘积的值位于1附近，否则，当t-k很大时（也就是误差传递很多个时刻时），整个式子的值就会变得极小（当$\beta_f\beta_w$乘积小于1）或者极大（当$\beta_f\beta_w$乘积大于1），前者就是<strong>梯度消失</strong>，后者就是<strong>梯度爆炸</strong>。虽然科学家们搞出了很多技巧（比如怎样初始化权重），让$\beta_f\beta_w$的值尽可能贴近于1，终究还是难以抵挡指数函数的威力。</p><p><strong>梯度消失</strong>到底意味着什么？在<a href="https://zybuluo.com/hanbingtao/note/541458" target="_blank" rel="noopener">零基础入门深度学习(5) - 循环神经网络</a>中我们已证明，权重数组W最终的梯度是各个时刻的梯度之和，即：</p><p>$\begin{align} \nabla_WE&amp;=\sum_{k=1}^t\nabla_{Wk}E\\ &amp;=\nabla_{Wt}E+\nabla_{Wt-1}E+\nabla_{Wt-2}E+…+\nabla_{W1}E \end{align} $</p><p>假设某轮训练中，各时刻的梯度以及最终的梯度之和如下图：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-48784f6366412472.png)</p><p>我们就可以看到，从上图的t-3时刻开始，梯度已经几乎减少到0了。那么，从这个时刻开始再往之前走，得到的梯度（几乎为零）就不会对最终的梯度值有任何贡献，这就相当于无论t-3时刻之前的网络状态h是什么，在训练中都不会对权重数组W的更新产生影响，也就是网络事实上已经忽略了t-3时刻之前的状态。这就是原始RNN无法处理长距离依赖的原因。</p><p>既然找到了问题的原因，那么我们就能解决它。从问题的定位到解决，科学家们大概花了7、8年时间。终于有一天，Hochreiter和Schmidhuber两位科学家发明出<strong>长短时记忆网络</strong>，一举解决这个问题。</p><p>其实，<strong>长短时记忆网络</strong>的思路比较简单。原始RNN的隐藏层只有一个状态，即h，它对于短期的输入非常敏感。那么，假如我们再增加一个状态，即c，让它来保存长期的状态，那么问题不就解决了么？如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-71de4194da5a5ec4.png)</p><p>新增加的状态c，称为<strong>单元状态(cell state)</strong>。我们把上图按照时间维度展开：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-715658c134b9d6f1.png)</p><p>上图仅仅是一个示意图，我们可以看出，在t时刻，LSTM的输入有三个：当前时刻网络的输入值$\mathbf{x}_t$、上一时刻LSTM的输出值$\mathbf{h}_{t-1}$、以及上一时刻的单元状态$\mathbf{c}_{t-1}$；LSTM的输出有两个：当前时刻LSTM输出值$\mathbf{h}_t$、和当前时刻的单元状态$\mathbf{c}_t$。注意$\mathbf{x}$、$\mathbf{h}$、$\mathbf{c}$都是<strong>向量</strong>。</p><p>LSTM的关键，就是怎样控制长期状态c。在这里，LSTM的思路是使用三个控制开关。第一个开关，负责控制继续保存长期状态c；第二个开关，负责控制把即时状态输入到长期状态c；第三个开关，负责控制是否把长期状态c作为当前的LSTM的输出。三个开关的作用如下图所示：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-bff9353b92b9c488.png)</p><p>接下来，我们要描述一下，输出h和单元状态c的具体计算方法。</p><h2 id="长短时记忆网络的前向计算"><a href="#长短时记忆网络的前向计算" class="headerlink" title="长短时记忆网络的前向计算"></a>长短时记忆网络的前向计算</h2><p>前面描述的开关是怎样在算法中实现的呢？这就用到了<strong>门（gate）</strong>的概念。门实际上就是一层<strong>全连接层</strong>，它的输入是一个向量，输出是一个0到1之间的实数向量。假设W是门的权重向量，是偏置项，那么门可以表示为：</p><p>$\begin{align}g(\mathbf{x})=\sigma(W\mathbf{x}+\mathbf{b}) \end{align} $</p><p>门的使用，就是用门的输出向量按元素乘以我们需要控制的那个向量。因为门的输出是0到1之间的实数向量，那么，当门输出为0时，任何向量与之相乘都会得到0向量，这就相当于啥都不能通过；输出为1时，任何向量与之相乘都不会有任何改变，这就相当于啥都可以通过。因为$\sigma$（也就是sigmoid函数）的值域是(0,1)，所以门的状态都是半开半闭的。</p><p>LSTM用两个门来控制单元状态c的内容，一个是<strong>遗忘门（forget gate）</strong>，它决定了上一时刻的单元状态$\mathbf{c}_{t-1}$有多少保留到当前时刻$\mathbf{c}_{t}$；另一个是<strong>输入门（input gate）</strong>，它决定了当前时刻网络的输入$\mathbf{x}_t$有多少保存到单元状态$\mathbf{c}_t$。LSTM用<strong>输出门（output gate）</strong>来控制单元状态$\mathbf{c}_t$有多少输出到LSTM的当前输出值$\mathbf{h}_t$。</p><p>我们先来看一下遗忘门：</p><p>$\begin{align}\mathbf{f}_t=\sigma(W_f\cdot[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_f)\qquad\quad(式1) \end{align} $</p><p>上式中，$W_f$是遗忘门的权重矩阵，$[\mathbf{h}_{t-1},\mathbf{x}_t]$表示把两个向量连接成一个更长的向量，$\mathbf{b}_f$是遗忘门的偏置项，$\sigma$是sigmoid函数。如果输入的维度是$d_x$，隐藏层的维度是$d_h$，单元状态的维度是$d_c$（通常$d_c=d_h$），则遗忘门的权重矩阵$W_f$维度是$d_c\times (d_h+d_x)$。事实上，权重矩阵$W_f$都是两个矩阵拼接而成的：一个是$W_{fh}$，它对应着输入项$\mathbf{h}_{t-1}$，其维度为$d_c\times d_h$；一个是$W_{fx}$，它对应着输入项$\mathbf{x}_t$，其维度为$d_c\times d_x$。$W_f$可以写为：</p><p>$\begin{align} \begin{bmatrix}W_f\end{bmatrix}\begin{bmatrix}\mathbf{h}_{t-1}\\ \mathbf{x}_t\end{bmatrix}&amp;= \begin{bmatrix}W_{fh}&amp;W_{fx}\end{bmatrix}\begin{bmatrix}\mathbf{h}_{t-1}\\ \mathbf{x}_t\end{bmatrix}\\ &amp;=W_{fh}\mathbf{h}_{t-1}+W_{fx}\mathbf{x}_t \end{align} $</p><p>下图显示了遗忘门的计算：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-c7f7ca0aa64b562f.png)</p><p>接下来看看输入门：</p><p>$\begin{align} \mathbf{i}_t=\sigma(W_i\cdot[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_i)\qquad\quad(式2) \end{align} $</p><p>上式中，是输入门的权重矩阵，是输入门的偏置项。下图表示了输入门的计算：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-89529fa23d9c8a7d.png)</p><p>接下来，我们计算用于描述当前输入的单元状态$\mathbf{\tilde{c}}_t$，它是根据上一次的输出和本次输入来计算的：</p><p>$\begin{align} \mathbf{\tilde{c}}_t=\tanh(W_c\cdot[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_c)\qquad\quad(式3) \end{align} $</p><p>下图是$\mathbf{\tilde{c}}_t$的计算：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-73a0246cafc1d10d.png)</p><p>现在，我们计算当前时刻的单元状态$\mathbf{\tilde{c}}_t$。它是由上一次的单元状态$\mathbf{\tilde{c}}_{t-1}$按元素乘以遗忘门$f_t$，再用当前输入的单元状态$\mathbf{\tilde{c}}_t$按元素乘以输入门$i_t$，再将两个积加和产生的：</p><p>$\begin{align} \mathbf{c}_t=f_t\circ{\mathbf{c}_{t-1}}+i_t\circ{\mathbf{\tilde{c}}_t}\qquad\quad(式4) \end{align} $</p><p>符号表示<strong>按元素乘</strong>。下图是$\mathbf{c}_t$的计算：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-5c766f3d734334b1.png)</p><p>这样，我们就把LSTM关于当前的记忆$\mathbf{\tilde{c}}_t$和长期的记忆$\mathbf{\tilde{c}}_{t-1}$组合在一起，形成了新的单元状态$\mathbf{\tilde{c}}_t$。由于遗忘门的控制，它可以保存很久很久之前的信息，由于输入门的控制，它又可以避免当前无关紧要的内容进入记忆。下面，我们要看看输出门，它控制了长期记忆对当前输出的影响：</p><p>$\begin{align} \mathbf{o}_t=\sigma(W_o\cdot[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_o)\qquad\quad(式5)\end{align} $</p><p>下图表示输出门的计算：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-fd4d91d1b68b3759.png)</p><p>LSTM最终的输出，是由输出门和单元状态共同确定的：</p><p>$\begin{align}\mathbf{h}_t=\mathbf{o}_t\circ \tanh(\mathbf{c}_t)\qquad\quad(式6)\end{align} $</p><p>下图表示LSTM最终输出的计算：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-7ea82e4f1ac6cd75.png)</p><p><strong>式1</strong>到<strong>式6</strong>就是LSTM前向计算的全部公式。至此，我们就把LSTM前向计算讲完了。</p><h2 id="长短时记忆网络的训练"><a href="#长短时记忆网络的训练" class="headerlink" title="长短时记忆网络的训练"></a>长短时记忆网络的训练</h2><p>熟悉我们这个系列文章的同学都清楚，训练部分往往比前向计算部分复杂多了。LSTM的前向计算都这么复杂，那么，可想而知，它的训练算法一定是非常非常复杂的。现在只有做几次深呼吸，再一头扎进公式海洋吧。</p><h3 id="LSTM训练算法框架"><a href="#LSTM训练算法框架" class="headerlink" title="LSTM训练算法框架"></a>LSTM训练算法框架</h3><p>LSTM的训练算法仍然是反向传播算法，对于这个算法，我们已经非常熟悉了。主要有下面三个步骤：</p><ol><li>前向计算每个神经元的输出值，对于LSTM来说，即$\mathbf{f}_t$、$\mathbf{i}_t$、$\mathbf{c}_t$、$\mathbf{o}_t$、$\mathbf{h}_t$五个向量的值。计算方法已经在上一节中描述过了。</li><li>反向计算每个神经元的<strong>误差项</strong>$\sigma $值。与<strong>循环神经网络</strong>一样，LSTM误差项的反向传播也是包括两个方向：一个是沿时间的反向传播，即从当前t时刻开始，计算每个时刻的误差项；一个是将误差项向上一层传播。</li><li>根据相应的误差项，计算每个权重的梯度。</li></ol><h3 id="关于公式和符号的说明"><a href="#关于公式和符号的说明" class="headerlink" title="关于公式和符号的说明"></a>关于公式和符号的说明</h3><p>首先，我们对推导中用到的一些公式、符号做一下必要的说明。</p><p>接下来的推导中，我们设定gate的激活函数为sigmoid函数，输出的激活函数为tanh函数。他们的导数分别为：</p><p>$\begin{align} \sigma(z)&amp;=y=\frac{1}{1+e^{-z}}\\ \sigma’(z)&amp;=y(1-y)\\ \tanh(z)&amp;=y=\frac{e^z-e^{-z}}{e^z+e^{-z}}\\ \tanh’(z)&amp;=1-y^2 \end{align} $</p><p>从上面可以看出，sigmoid和tanh函数的导数都是原函数的函数。这样，我们一旦计算原函数的值，就可以用它来计算出导数的值。</p><p>LSTM需要学习的参数共有8组，分别是：遗忘门的权重矩阵$W_f$和偏置项$\mathbf{b}_f$、输入门的权重矩阵$W_i$和偏置项$\mathbf{b}_i$、输出门的权重矩阵$W_o$和偏置项$\mathbf{b}_o$，以及计算单元状态的权重矩阵$W_c$和偏置项$\mathbf{b}_c$。因为权重矩阵的两部分在反向传播中使用不同的公式，因此在后续的推导中，权重矩阵$W_f$、$W_i$、$W_c$、$W_o$都将被写为分开的两个矩阵：$W_{fh}$、$W_{fx}$、$W_{ih}$、$W_{ix}$、$W_{oh}$、$W_{ox}$、$W_{ch}$、$W_{cx}$。</p><p>我们解释一下按元素乘$\circ$符号。当$\circ$作用于两个<strong>向量</strong>时，运算如下：</p><p>$\begin{align}\mathbf{a}\circ\mathbf{b}=\begin{bmatrix} a_1\\a_2\\a_3\...\\a_n \end{bmatrix}\circ\begin{bmatrix} b_1\\b_2\\b_3\...\\b_n \end{bmatrix}=\begin{bmatrix} a_1b_1\\a_2b_2\\a_3b_3\...\\a_nb_n \end{bmatrix} \end{align} $</p><p>当作用于一个<strong>向量</strong>和一个<strong>矩阵</strong>时，运算如下：</p><p>$\begin{align} \mathbf{a}\circ X&amp;=\begin{bmatrix} a_1\\a_2\\a_3\...\\a_n \end{bmatrix}\circ\begin{bmatrix} x_{11} &amp; x_{12} &amp; x_{13} &amp; … &amp; x_{1n}\\ x_{21} &amp; x_{22} &amp; x_{23} &amp; … &amp; x_{2n}\\ x_{31} &amp; x_{32} &amp; x_{33} &amp; … &amp; x_{3n}\\ &amp; &amp; …\\ x_{n1} &amp; x_{n2} &amp; x_{n3} &amp; … &amp; x_{nn}\\ \end{bmatrix}\\ &amp;=\begin{bmatrix} a_1x_{11} &amp; a_1x_{12} &amp; a_1x_{13} &amp; … &amp; a_1x_{1n}\\ a_2x_{21} &amp; a_2x_{22} &amp; a_2x_{23} &amp; … &amp; a_2x_{2n}\\ a_3x_{31} &amp; a_3x_{32} &amp; a_3x_{33} &amp; … &amp; a_3x_{3n}\\ &amp; &amp; …\\ a_nx_{n1} &amp; a_nx_{n2} &amp; a_nx_{n3} &amp; … &amp; a_nx_{nn}\\ \end{bmatrix} \end{align} $</p><p>当作用于两个<strong>矩阵</strong>时，两个矩阵对应位置的元素相乘。按元素乘可以在某些情况下简化矩阵和向量运算。例如，当一个对角矩阵右乘一个矩阵时，相当于用对角矩阵的对角线组成的向量按元素乘那个矩阵：</p><p>$\begin{align} diag[\mathbf{a}]X=\mathbf{a}\circ X \end{align}$</p><p>当一个行向量右乘一个对角矩阵时，相当于这个行向量按元素乘那个矩阵对角线组成的向量：</p><p>$\begin{align} \mathbf{a}^Tdiag[\mathbf{b}]=\mathbf{a}\circ\mathbf{b} \end{align} $</p><p>上面这两点，在我们后续推导中会多次用到。</p><p>在t时刻，LSTM的输出值为$\mathbf{h}_t$。我们定义t时刻的误差项$\delta_t$为：</p><p>$\begin{align}\delta_t\overset{def}{=}\frac{\partial{E}}{\partial{\mathbf{h}_t}} \end{align} $</p><p>注意，和前面几篇文章不同，我们这里假设误差项是损失函数对输出值的导数，而不是对加权输入$net_t^l$的导数。因为LSTM有四个加权输入，分别对应$\mathbf{f}_t$、$\mathbf{i}_t$、$\mathbf{c}_t$、$\mathbf{o}_t$，我们希望往上一层传递一个误差项而不是四个。但我们仍然需要定义出这四个加权输入，以及他们对应的误差项。</p><p>$\begin{align} \mathbf{net}_{f,t}&amp;=W_f[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_f\\ &amp;=W_{fh}\mathbf{h}_{t-1}+W_{fx}\mathbf{x}_t+\mathbf{b}_f\\ \mathbf{net}_{i,t}&amp;=W_i[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_i\\ &amp;=W_{ih}\mathbf{h}_{t-1}+W_{ix}\mathbf{x}_t+\mathbf{b}_i\\ \mathbf{net}_{\tilde{c},t}&amp;=W_c[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_c\\ &amp;=W_{ch}\mathbf{h}_{t-1}+W_{cx}\mathbf{x}_t+\mathbf{b}_c\\ \mathbf{net}_{o,t}&amp;=W_o[\mathbf{h}_{t-1},\mathbf{x}_t]+\mathbf{b}_o\\ &amp;=W_{oh}\mathbf{h}_{t-1}+W_{ox}\mathbf{x}_t+\mathbf{b}_o\\ \delta_{f,t}&amp;\overset{def}{=}\frac{\partial{E}}{\partial{\mathbf{net}_{f,t}}}\\ \delta_{i,t}&amp;\overset{def}{=}\frac{\partial{E}}{\partial{\mathbf{net}_{i,t}}}\\ \delta_{\tilde{c},t}&amp;\overset{def}{=}\frac{\partial{E}}{\partial{\mathbf{net}_{\tilde{c},t}}}\\ \delta_{o,t}&amp;\overset{def}{=}\frac{\partial{E}}{\partial{\mathbf{net}_{o,t}}}\\ \end{align} $</p><h3 id="误差项沿时间的反向传递"><a href="#误差项沿时间的反向传递" class="headerlink" title="误差项沿时间的反向传递"></a>误差项沿时间的反向传递</h3><p>沿时间反向传递误差项，就是要计算出t-1时刻的误差项$\sigma_{t-1}$。</p><p>$\begin{align} \delta_{t-1}^T&amp;=\frac{\partial{E}}{\partial{\mathbf{h_{t-1}}}}\\ &amp;=\frac{\partial{E}}{\partial{\mathbf{h_t}}}\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{h_{t-1}}}}\\ &amp;=\delta_{t}^T\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{h_{t-1}}}} \end{align} $</p><p>我们知道，$\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{h_{t-1}}}}$是一个Jacobian矩阵。如果隐藏层h的维度是N的话，那么它就是一个$N\times N$矩阵。为了求出它，我们列出$\mathbf{h}_t$的计算公式，即前面的<strong>式6</strong>和<strong>式4</strong>：</p><p>$\begin{align} \mathbf{h}_t&amp;=\mathbf{o}_t\circ \tanh(\mathbf{c}_t)\\ \mathbf{c}_t&amp;=\mathbf{f}_t\circ\mathbf{c}_{t-1}+\mathbf{i}_t\circ\mathbf{\tilde{c}}_t \end{align} $</p><p>显然，$\mathbf{o}_t$、$\mathbf{f}_t$、$\mathbf{i}_t$、$\mathbf{\tilde{c}}_t$都是$\mathbf{h}_{t-1}$的函数，那么，利用全导数公式可得：</p><p>$\begin{align} \delta_t^T\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{h_{t-1}}}}&amp;=\delta_t^T\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{o}_t}}\frac{\partial{\mathbf{o}_t}}{\partial{\mathbf{net}_{o,t}}}\frac{\partial{\mathbf{net}_{o,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_t^T\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{c}_t}}\frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{f_{t}}}}\frac{\partial{\mathbf{f}_t}}{\partial{\mathbf{net}_{f,t}}}\frac{\partial{\mathbf{net}_{f,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_t^T\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{c}_t}}\frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{i_{t}}}}\frac{\partial{\mathbf{i}_t}}{\partial{\mathbf{net}_{i,t}}}\frac{\partial{\mathbf{net}_{i,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_t^T\frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{c}_t}}\frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{\tilde{c}}_{t}}}\frac{\partial{\mathbf{\tilde{c}}_t}}{\partial{\mathbf{net}_{\tilde{c},t}}}\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{\mathbf{h_{t-1}}}}\\ &amp;=\delta_{o,t}^T\frac{\partial{\mathbf{net}_{o,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_{f,t}^T\frac{\partial{\mathbf{net}_{f,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_{i,t}^T\frac{\partial{\mathbf{net}_{i,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_{\tilde{c},t}^T\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{\mathbf{h_{t-1}}}}\qquad\quad(式7) \end{align} $</p><p>下面，我们要把<strong>式7</strong>中的每个偏导数都求出来。根据<strong>式6</strong>，我们可以求出：</p><p>$\begin{align} \frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{o}_t}}&amp;=diag[\tanh(\mathbf{c}_t)]\\ \frac{\partial{\mathbf{h_t}}}{\partial{\mathbf{c}_t}}&amp;=diag[\mathbf{o}_t\circ(1-\tanh(\mathbf{c}_t)^2)] \end{align} $</p><p>根据<strong>式4</strong>，我们可以求出：</p><p>$\begin{align} \frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{f_{t}}}}&amp;=diag[\mathbf{c}_{t-1}]\\ \frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{i_{t}}}}&amp;=diag[\mathbf{\tilde{c}}_t]\\ \frac{\partial{\mathbf{c}_t}}{\partial{\mathbf{\tilde{c}_{t}}}}&amp;=diag[\mathbf{i}_t]\\ \end{align} $</p><p>因为：</p><p>$\begin{align} \mathbf{o}_t&amp;=\sigma(\mathbf{net}_{o,t})\\ \mathbf{net}_{o,t}&amp;=W_{oh}\mathbf{h}_{t-1}+W_{ox}\mathbf{x}_t+\mathbf{b}_o\\\\ \mathbf{f}_t&amp;=\sigma(\mathbf{net}_{f,t})\\ \mathbf{net}_{f,t}&amp;=W_{fh}\mathbf{h}_{t-1}+W_{fx}\mathbf{x}_t+\mathbf{b}_f\\\\ \mathbf{i}_t&amp;=\sigma(\mathbf{net}_{i,t})\\ \mathbf{net}_{i,t}&amp;=W_{ih}\mathbf{h}_{t-1}+W_{ix}\mathbf{x}_t+\mathbf{b}_i\\\\ \mathbf{\tilde{c}}_t&amp;=\tanh(\mathbf{net}_{\tilde{c},t})\\ \mathbf{net}_{\tilde{c},t}&amp;=W_{ch}\mathbf{h}_{t-1}+W_{cx}\mathbf{x}_t+\mathbf{b}_c\\ \end{align} $</p><p>我们很容易得出：</p><p>$\begin{align} \frac{\partial{\mathbf{o}_t}}{\partial{\mathbf{net}_{o,t}}}&amp;=diag[\mathbf{o}_t\circ(1-\mathbf{o}_t)]\\ \frac{\partial{\mathbf{net}_{o,t}}}{\partial{\mathbf{h_{t-1}}}}&amp;=W_{oh}\\ \frac{\partial{\mathbf{f}_t}}{\partial{\mathbf{net}_{f,t}}}&amp;=diag[\mathbf{f}_t\circ(1-\mathbf{f}_t)]\\ \frac{\partial{\mathbf{net}_{f,t}}}{\partial{\mathbf{h}_{t-1}}}&amp;=W_{fh}\\ \frac{\partial{\mathbf{i}_t}}{\partial{\mathbf{net}_{i,t}}}&amp;=diag[\mathbf{i}_t\circ(1-\mathbf{i}_t)]\\ \frac{\partial{\mathbf{net}_{i,t}}}{\partial{\mathbf{h}_{t-1}}}&amp;=W_{ih}\\ \frac{\partial{\mathbf{\tilde{c}}_t}}{\partial{\mathbf{net}_{\tilde{c},t}}}&amp;=diag[1-\mathbf{\tilde{c}}_t^2]\\ \frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{\mathbf{h}_{t-1}}}&amp;=W_{ch} \end{align} $</p><p>将上述偏导数带入到<strong>式7</strong>，我们得到：</p><p>$\begin{align} \delta_{t-1}&amp;=\delta_{o,t}^T\frac{\partial{\mathbf{net}_{o,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_{f,t}^T\frac{\partial{\mathbf{net}_{f,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_{i,t}^T\frac{\partial{\mathbf{net}_{i,t}}}{\partial{\mathbf{h_{t-1}}}} +\delta_{\tilde{c},t}^T\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{\mathbf{h_{t-1}}}}\\ &amp;=\delta_{o,t}^T W_{oh} +\delta_{f,t}^TW_{fh} +\delta_{i,t}^TW_{ih} +\delta_{\tilde{c},t}^TW_{ch}\qquad\quad(式8)\\ \end{align} $</p><p>根据$\delta_{o,t}$、$\delta_{f,t}$、$\delta_{i,t}$、$\delta_{\tilde{c},t}$的定义，可知：</p><p>$\begin{align} \delta_{o,t}^T&amp;=\delta_t^T\circ\tanh(\mathbf{c}_t)\circ\mathbf{o}_t\circ(1-\mathbf{o}_t)\qquad\quad(式9)\\ \delta_{f,t}^T&amp;=\delta_t^T\circ\mathbf{o}_t\circ(1-\tanh(\mathbf{c}_t)^2)\circ\mathbf{c}_{t-1}\circ\mathbf{f}_t\circ(1-\mathbf{f}_t)\qquad(式10)\\ \delta_{i,t}^T&amp;=\delta_t^T\circ\mathbf{o}_t\circ(1-\tanh(\mathbf{c}_t)^2)\circ\mathbf{\tilde{c}}_t\circ\mathbf{i}_t\circ(1-\mathbf{i}_t)\qquad\quad(式11)\\ \delta_{\tilde{c},t}^T&amp;=\delta_t^T\circ\mathbf{o}_t\circ(1-\tanh(\mathbf{c}_t)^2)\circ\mathbf{i}_t\circ(1-\mathbf{\tilde{c}}^2)\qquad\quad(式12)\\ \end{align} $</p><p><strong>式8</strong>到<strong>式12</strong>就是将误差沿时间反向传播一个时刻的公式。有了它，我们可以写出将误差项向前传递到任意k时刻的公式：</p><p>$\begin{align} \delta_k^T=\prod_{j=k}^{t-1}\delta_{o,j}^TW_{oh} +\delta_{f,j}^TW_{fh} +\delta_{i,j}^TW_{ih} +\delta_{\tilde{c},j}^TW_{ch}\qquad\quad(式13) \end{align}$</p><h3 id="将误差项传递到上一层"><a href="#将误差项传递到上一层" class="headerlink" title="将误差项传递到上一层"></a>将误差项传递到上一层</h3><p>我们假设当前为第l层，定义l-1层的误差项是误差函数对l-1层<strong>加权输入</strong>的导数，即：</p><p>$\begin {align} \delta_t^{l-1}\overset{def}{=}\frac{\partial{E}}{\mathbf{net}_t^{l-1}} \end {align} $</p><p>本次LSTM的输入$x_t$由下面的公式计算：</p><p>$\begin {align} \mathbf{x}_t^l=f^{l-1}(\mathbf{net}_t^{l-1}) \end{align} $</p><p>上式中，$f^{l-1}$表示第l-1层的<strong>激活函数</strong>。</p><p>因为$\mathbf{net}_{f,t}^l$、$\mathbf{net}_{i,t}^l$、$\mathbf{net}_{\tilde{c},t}^l$、$\mathbf{net}_{o,t}^l$都是$\mathbf{x}_t$的函数，$\mathbf{x}_t$又是$\mathbf{net}_t^{l-1}$的函数，因此，要求出E对$\mathbf{net}_t^{l-1}$的导数，就需要使用全导数公式：</p><p>$\begin{align} \frac{\partial{E}}{\partial{\mathbf{net}_t^{l-1}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{\mathbf{net}_{f,t}^l}}}\frac{\partial{\mathbf{\mathbf{net}_{f,t}^l}}}{\partial{\mathbf{x}_t^l}}\frac{\partial{\mathbf{x}_t^l}}{\partial{\mathbf{\mathbf{net}_t^{l-1}}}} +\frac{\partial{E}}{\partial{\mathbf{\mathbf{net}_{i,t}^l}}}\frac{\partial{\mathbf{\mathbf{net}_{i,t}^l}}}{\partial{\mathbf{x}_t^l}}\frac{\partial{\mathbf{x}_t^l}}{\partial{\mathbf{\mathbf{net}_t^{l-1}}}} +\frac{\partial{E}}{\partial{\mathbf{\mathbf{net}_{\tilde{c},t}^l}}}\frac{\partial{\mathbf{\mathbf{net}_{\tilde{c},t}^l}}}{\partial{\mathbf{x}_t^l}}\frac{\partial{\mathbf{x}_t^l}}{\partial{\mathbf{\mathbf{net}_t^{l-1}}}} +\frac{\partial{E}}{\partial{\mathbf{\mathbf{net}_{o,t}^l}}}\frac{\partial{\mathbf{\mathbf{net}_{o,t}^l}}}{\partial{\mathbf{x}_t^l}}\frac{\partial{\mathbf{x}_t^l}}{\partial{\mathbf{\mathbf{net}_t^{l-1}}}}\\ &amp;=\delta_{f,t}^TW_{fx}\circ f’(\mathbf{net}_t^{l-1})+\delta_{i,t}^TW_{ix}\circ f’(\mathbf{net}_t^{l-1})+\delta_{\tilde{c},t}^TW_{cx}\circ f’(\mathbf{net}_t^{l-1})+\delta_{o,t}^TW_{ox}\circ f’(\mathbf{net}_t^{l-1})\\ &amp;=(\delta_{f,t}^TW_{fx}+\delta_{i,t}^TW_{ix}+\delta_{\tilde{c},t}^TW_{cx}+\delta_{o,t}^TW_{ox})\circ f’(\mathbf{net}_t^{l-1})\qquad\quad(式14) \end{align} $</p><p><strong>式14</strong>就是将误差传递到上一层的公式。</p><h3 id="权重梯度的计算"><a href="#权重梯度的计算" class="headerlink" title="权重梯度的计算"></a>权重梯度的计算</h3><p>对于$W_{fh}$、$W_{ih}$、$W_{ch}$、$W_{oh}$的权重梯度，我们知道它的梯度是各个时刻梯度之和（证明过程请参考文章<a href="https://zybuluo.com/hanbingtao/note/541458" target="_blank" rel="noopener">零基础入门深度学习(5) - 循环神经网络</a>），我们首先求出它们在t时刻的梯度，然后再求出他们最终的梯度。</p><p>我们已经求得了误差项$\delta_{o,t}$、$\delta_{f,t}$、$\delta_{i,t}$、$\delta_{\tilde{c},t}$，很容易求出t时刻的$W_{oh}$、$W_{ih}$、$W_{fh}$、$W_{ch}$的：</p><p>$\begin{align} \frac{\partial{E}}{\partial{W_{oh,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{o,t}}}\frac{\partial{\mathbf{net}_{o,t}}}{\partial{W_{oh,t}}}\\ &amp;=\delta_{o,t}\mathbf{h}_{t-1}^T\\\\ \frac{\partial{E}}{\partial{W_{fh,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{f,t}}}\frac{\partial{\mathbf{net}_{f,t}}}{\partial{W_{fh,t}}}\\ &amp;=\delta_{f,t}\mathbf{h}_{t-1}^T\\\\ \frac{\partial{E}}{\partial{W_{ih,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{i,t}}}\frac{\partial{\mathbf{net}_{i,t}}}{\partial{W_{ih,t}}}\\ &amp;=\delta_{i,t}\mathbf{h}_{t-1}^T\\\\ \frac{\partial{E}}{\partial{W_{ch,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{\tilde{c},t}}}\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{W_{ch,t}}}\\ &amp;=\delta_{\tilde{c},t}\mathbf{h}_{t-1}^T\\ \end{align} $</p><p>将各个时刻的梯度加在一起，就能得到最终的梯度：</p><p>$\begin{align} \frac{\partial{E}}{\partial{W_{oh}}}&amp;=\sum_{j=1}^t\delta_{o,j}\mathbf{h}_{j-1}^T\\ \frac{\partial{E}}{\partial{W_{fh}}}&amp;=\sum_{j=1}^t\delta_{f,j}\mathbf{h}_{j-1}^T\\ \frac{\partial{E}}{\partial{W_{ih}}}&amp;=\sum_{j=1}^t\delta_{i,j}\mathbf{h}_{j-1}^T\\ \frac{\partial{E}}{\partial{W_{ch}}}&amp;=\sum_{j=1}^t\delta_{\tilde{c},j}\mathbf{h}_{j-1}^T\\ \end{align} $</p><p>对于偏置项$\mathbf{b}_f$、$\mathbf{b}_i$、$\mathbf{b}_c$、$\mathbf{b}_o$的梯度，也是将各个时刻的梯度加在一起。下面是各个时刻的偏置项梯度：</p><p>$\begin{align} \frac{\partial{E}}{\partial{\mathbf{b}_{o,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{o,t}}}\frac{\partial{\mathbf{net}_{o,t}}}{\partial{\mathbf{b}_{o,t}}}\\ &amp;=\delta_{o,t}\\\\ \frac{\partial{E}}{\partial{\mathbf{b}_{f,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{f,t}}}\frac{\partial{\mathbf{net}_{f,t}}}{\partial{\mathbf{b}_{f,t}}}\\ &amp;=\delta_{f,t}\\\\ \frac{\partial{E}}{\partial{\mathbf{b}_{i,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{i,t}}}\frac{\partial{\mathbf{net}_{i,t}}}{\partial{\mathbf{b}_{i,t}}}\\ &amp;=\delta_{i,t}\\\\ \frac{\partial{E}}{\partial{\mathbf{b}_{c,t}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{\tilde{c},t}}}\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{\mathbf{b}_{c,t}}}\\ &amp;=\delta_{\tilde{c},t}\\ \end{align} $</p><p>下面是最终的偏置项梯度，即将各个时刻的偏置项梯度加在一起：</p><p>$\begin{align} \frac{\partial{E}}{\partial{\mathbf{b}_o}}&amp;=\sum_{j=1}^t\delta_{o,j}\\ \frac{\partial{E}}{\partial{\mathbf{b}_i}}&amp;=\sum_{j=1}^t\delta_{i,j}\\ \frac{\partial{E}}{\partial{\mathbf{b}_f}}&amp;=\sum_{j=1}^t\delta_{f,j}\\ \frac{\partial{E}}{\partial{\mathbf{b}_c}}&amp;=\sum_{j=1}^t\delta_{\tilde{c},j}\\ \end{align} $</p><p>对于$W_{fx}$、$W_{ix}$、$W_{cx}$、$W_{ox}$的权重梯度，只需要根据相应的误差项直接计算即可：</p><p>$\begin{align} \frac{\partial{E}}{\partial{W_{ox}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{o,t}}}\frac{\partial{\mathbf{net}_{o,t}}}{\partial{W_{ox}}}\\ &amp;=\delta_{o,t}\mathbf{x}_{t}^T\\\\ \frac{\partial{E}}{\partial{W_{fx}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{f,t}}}\frac{\partial{\mathbf{net}_{f,t}}}{\partial{W_{fx}}}\\ &amp;=\delta_{f,t}\mathbf{x}_{t}^T\\\\ \frac{\partial{E}}{\partial{W_{ix}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{i,t}}}\frac{\partial{\mathbf{net}_{i,t}}}{\partial{W_{ix}}}\\ &amp;=\delta_{i,t}\mathbf{x}_{t}^T\\\\ \frac{\partial{E}}{\partial{W_{cx}}}&amp;=\frac{\partial{E}}{\partial{\mathbf{net}_{\tilde{c},t}}}\frac{\partial{\mathbf{net}_{\tilde{c},t}}}{\partial{W_{cx}}}\\ &amp;=\delta_{\tilde{c},t}\mathbf{x}_{t}^T\\ \end{align} $</p><p>以上就是LSTM的训练算法的全部公式。因为这里面存在很多重复的模式，仔细看看，会发觉并不是太复杂。</p><p>当然，LSTM存在着相当多的变体，读者可以在互联网上找到很多资料。因为大家已经熟悉了基本LSTM的算法，因此理解这些变体比较容易，因此本文就不再赘述了。</p><h2 id="长短时记忆网络的实现"><a href="#长短时记忆网络的实现" class="headerlink" title="长短时记忆网络的实现"></a>长短时记忆网络的实现</h2><blockquote><p>完整代码请参考GitHub: <a href="https://github.com/hanbt/learn_dl/blob/master/lstm.py" target="_blank" rel="noopener">https://github.com/hanbt/learn_dl/blob/master/lstm.py</a> (python2.7)</p></blockquote><p>在下面的实现中，LSTMLayer的参数包括输入维度、输出维度、隐藏层维度，单元状态维度等于隐藏层维度。gate的激活函数为sigmoid函数，输出的激活函数为tanh。</p><h3 id="激活函数的实现"><a href="#激活函数的实现" class="headerlink" title="激活函数的实现"></a>激活函数的实现</h3><p>我们先实现两个激活函数：sigmoid和tanh。</p><pre class=" language-lang-python"><code class="language-lang-python">class SigmoidActivator(object):    def forward(self, weighted_input):        return 1.0 / (1.0 + np.exp(-weighted_input))    def backward(self, output):        return output * (1 - output)class TanhActivator(object):    def forward(self, weighted_input):        return 2.0 / (1.0 + np.exp(-2 * weighted_input)) - 1.0    def backward(self, output):        return 1 - output * output</code></pre><h3 id="LSTM初始化"><a href="#LSTM初始化" class="headerlink" title="LSTM初始化"></a>LSTM初始化</h3><p>和前两篇文章代码架构一样，我们把LSTM的实现放在LstmLayer类中。</p><p>根据LSTM前向计算和方向传播算法，我们需要初始化一系列矩阵和向量。这些矩阵和向量有两类用途，一类是用于保存模型参数，例如$W_f$、$W_i$、$W_o$、$W_c$、$\mathbf{b}_f$、$\mathbf{b}_i$、$\mathbf{b}_o$、$\mathbf{b}_c$；另一类是保存各种中间计算结果，以便于反向传播算法使用，它们包括$\mathbf{h}_t$、$\mathbf{f}_t$、$\mathbf{i}_t$、$\mathbf{o}_t$、$\mathbf{\tilde{c}}_t$、$\mathbf{\tilde{c}}_t$、$\delta_t$、$\delta_{f,t}$、$\delta_{i,t}$、$\delta_{o,t}$、$\delta_{\tilde{c},t}$，以及各个权重对应的梯度。</p><p>在构造函数的初始化中，只初始化了与forward计算相关的变量，与backward相关的变量没有初始化。这是因为构造LSTM对象的时候，我们还不知道它未来是用于训练（既有forward又有backward）还是推理（只有forward）。</p><pre class=" language-lang-python"><code class="language-lang-python">class LstmLayer(object):    def __init__(self, input_width, state_width,                  learning_rate):        self.input_width = input_width        self.state_width = state_width        self.learning_rate = learning_rate        # 门的激活函数        self.gate_activator = SigmoidActivator()        # 输出的激活函数        self.output_activator = TanhActivator()        # 当前时刻初始化为t0        self.times = 0               # 各个时刻的单元状态向量c        self.c_list = self.init_state_vec()        # 各个时刻的输出向量h        self.h_list = self.init_state_vec()        # 各个时刻的遗忘门f        self.f_list = self.init_state_vec()        # 各个时刻的输入门i        self.i_list = self.init_state_vec()        # 各个时刻的输出门o        self.o_list = self.init_state_vec()        # 各个时刻的即时状态c~        self.ct_list = self.init_state_vec()        # 遗忘门权重矩阵Wfh, Wfx, 偏置项bf        self.Wfh, self.Wfx, self.bf = (            self.init_weight_mat())        # 输入门权重矩阵Wfh, Wfx, 偏置项bf        self.Wih, self.Wix, self.bi = (            self.init_weight_mat())        # 输出门权重矩阵Wfh, Wfx, 偏置项bf        self.Woh, self.Wox, self.bo = (            self.init_weight_mat())        # 单元状态权重矩阵Wfh, Wfx, 偏置项bf        self.Wch, self.Wcx, self.bc = (            self.init_weight_mat())    def init_state_vec(self):        '''        初始化保存状态的向量        '''        state_vec_list = []        state_vec_list.append(np.zeros(            (self.state_width, 1)))        return state_vec_list    def init_weight_mat(self):        '''        初始化权重矩阵        '''        Wh = np.random.uniform(-1e-4, 1e-4,            (self.state_width, self.state_width))        Wx = np.random.uniform(-1e-4, 1e-4,            (self.state_width, self.input_width))        b = np.zeros((self.state_width, 1))        return Wh, Wx, b</code></pre><h3 id="前向计算的实现"><a href="#前向计算的实现" class="headerlink" title="前向计算的实现"></a>前向计算的实现</h3><p>forward方法实现了LSTM的前向计算：</p><pre class=" language-lang-python"><code class="language-lang-python">        def forward(self, x):        '''        根据式1-式6进行前向计算        '''        self.times += 1        # 遗忘门        fg = self.calc_gate(x, self.Wfx, self.Wfh,             self.bf, self.gate_activator)        self.f_list.append(fg)        # 输入门        ig = self.calc_gate(x, self.Wix, self.Wih,            self.bi, self.gate_activator)        self.i_list.append(ig)        # 输出门        og = self.calc_gate(x, self.Wox, self.Woh,            self.bo, self.gate_activator)        self.o_list.append(og)        # 即时状态        ct = self.calc_gate(x, self.Wcx, self.Wch,            self.bc, self.output_activator)        self.ct_list.append(ct)        # 单元状态        c = fg * self.c_list[self.times - 1] + ig * ct        self.c_list.append(c)        # 输出        h = og * self.output_activator.forward(c)        self.h_list.append(h)    def calc_gate(self, x, Wx, Wh, b, activator):        '''        计算门        '''        h = self.h_list[self.times - 1] # 上次的LSTM输出        net = np.dot(Wh, h) + np.dot(Wx, x) + b        gate = activator.forward(net)        return gate</code></pre><p>从上面的代码我们可以看到，门的计算都是相同的算法，而门和的计算仅仅是激活函数不同。因此我们提出了calc_gate方法，这样减少了很多重复代码。</p><h3 id="反向传播算法的实现"><a href="#反向传播算法的实现" class="headerlink" title="反向传播算法的实现"></a>反向传播算法的实现</h3><p>backward方法实现了LSTM的反向传播算法。需要注意的是，与backword相关的内部状态变量是在调用backward方法之后才初始化的。这种延迟初始化的一个好处是，如果LSTM只是用来推理，那么就不需要初始化这些变量，节省了很多内存。</p><pre class=" language-lang-python"><code class="language-lang-python">    def backward(self, x, delta_h, activator):        '''        实现LSTM训练算法        '''        self.calc_delta(delta_h, activator)        self.calc_gradient(x)</code></pre><p>算法主要分成两个部分，一部分使计算误差项：</p><pre class=" language-lang-python"><code class="language-lang-python">        def calc_delta(self, delta_h, activator):        # 初始化各个时刻的误差项        self.delta_h_list = self.init_delta()  # 输出误差项        self.delta_o_list = self.init_delta()  # 输出门误差项        self.delta_i_list = self.init_delta()  # 输入门误差项        self.delta_f_list = self.init_delta()  # 遗忘门误差项        self.delta_ct_list = self.init_delta() # 即时输出误差项        # 保存从上一层传递下来的当前时刻的误差项        self.delta_h_list[-1] = delta_h        # 迭代计算每个时刻的误差项        for k in range(self.times, 0, -1):            self.calc_delta_k(k)    def init_delta(self):        '''        初始化误差项        '''        delta_list = []        for i in range(self.times + 1):            delta_list.append(np.zeros(                (self.state_width, 1)))        return delta_list    def calc_delta_k(self, k):        '''        根据k时刻的delta_h，计算k时刻的delta_f、        delta_i、delta_o、delta_ct，以及k-1时刻的delta_h        '''        # 获得k时刻前向计算的值        ig = self.i_list[k]        og = self.o_list[k]        fg = self.f_list[k]        ct = self.ct_list[k]        c = self.c_list[k]        c_prev = self.c_list[k-1]        tanh_c = self.output_activator.forward(c)        delta_k = self.delta_h_list[k]        # 根据式9计算delta_o        delta_o = (delta_k * tanh_c *             self.gate_activator.backward(og))        delta_f = (delta_k * og *             (1 - tanh_c * tanh_c) * c_prev *            self.gate_activator.backward(fg))        delta_i = (delta_k * og *             (1 - tanh_c * tanh_c) * ct *            self.gate_activator.backward(ig))        delta_ct = (delta_k * og *             (1 - tanh_c * tanh_c) * ig *            self.output_activator.backward(ct))        delta_h_prev = (                np.dot(delta_o.transpose(), self.Woh) +                np.dot(delta_i.transpose(), self.Wih) +                np.dot(delta_f.transpose(), self.Wfh) +                np.dot(delta_ct.transpose(), self.Wch)            ).transpose()        # 保存全部delta值        self.delta_h_list[k-1] = delta_h_prev        self.delta_f_list[k] = delta_f        self.delta_i_list[k] = delta_i        self.delta_o_list[k] = delta_o        self.delta_ct_list[k] = delta_ct</code></pre><p>另一部分是计算梯度：</p><pre class=" language-lang-python"><code class="language-lang-python">     def calc_gradient(self, x):        # 初始化遗忘门权重梯度矩阵和偏置项        self.Wfh_grad, self.Wfx_grad, self.bf_grad = (            self.init_weight_gradient_mat())        # 初始化输入门权重梯度矩阵和偏置项        self.Wih_grad, self.Wix_grad, self.bi_grad = (            self.init_weight_gradient_mat())        # 初始化输出门权重梯度矩阵和偏置项        self.Woh_grad, self.Wox_grad, self.bo_grad = (            self.init_weight_gradient_mat())        # 初始化单元状态权重梯度矩阵和偏置项        self.Wch_grad, self.Wcx_grad, self.bc_grad = (            self.init_weight_gradient_mat())       # 计算对上一次输出h的权重梯度        for t in range(self.times, 0, -1):            # 计算各个时刻的梯度            (Wfh_grad, bf_grad,            Wih_grad, bi_grad,            Woh_grad, bo_grad,            Wch_grad, bc_grad) = (                self.calc_gradient_t(t))            # 实际梯度是各时刻梯度之和            self.Wfh_grad += Wfh_grad            self.bf_grad += bf_grad            self.Wih_grad += Wih_grad            self.bi_grad += bi_grad            self.Woh_grad += Woh_grad            self.bo_grad += bo_grad            self.Wch_grad += Wch_grad            self.bc_grad += bc_grad            print '-----%d-----' % t            print Wfh_grad            print self.Wfh_grad        # 计算对本次输入x的权重梯度        xt = x.transpose()        self.Wfx_grad = np.dot(self.delta_f_list[-1], xt)        self.Wix_grad = np.dot(self.delta_i_list[-1], xt)        self.Wox_grad = np.dot(self.delta_o_list[-1], xt)        self.Wcx_grad = np.dot(self.delta_ct_list[-1], xt)    def init_weight_gradient_mat(self):        '''        初始化权重矩阵        '''        Wh_grad = np.zeros((self.state_width,            self.state_width))        Wx_grad = np.zeros((self.state_width,            self.input_width))        b_grad = np.zeros((self.state_width, 1))        return Wh_grad, Wx_grad, b_grad    def calc_gradient_t(self, t):        '''        计算每个时刻t权重的梯度        '''        h_prev = self.h_list[t-1].transpose()        Wfh_grad = np.dot(self.delta_f_list[t], h_prev)        bf_grad = self.delta_f_list[t]        Wih_grad = np.dot(self.delta_i_list[t], h_prev)        bi_grad = self.delta_f_list[t]        Woh_grad = np.dot(self.delta_o_list[t], h_prev)        bo_grad = self.delta_f_list[t]        Wch_grad = np.dot(self.delta_ct_list[t], h_prev)        bc_grad = self.delta_ct_list[t]        return Wfh_grad, bf_grad, Wih_grad, bi_grad, \               Woh_grad, bo_grad, Wch_grad, bc_grad</code></pre><h3 id="梯度下降算法的实现"><a href="#梯度下降算法的实现" class="headerlink" title="梯度下降算法的实现"></a>梯度下降算法的实现</h3><p>下面是用梯度下降算法来更新权重：</p><pre class=" language-lang-python"><code class="language-lang-python">    def update(self):        '''        按照梯度下降，更新权重        '''        self.Wfh -= self.learning_rate * self.Whf_grad        self.Wfx -= self.learning_rate * self.Whx_grad        self.bf -= self.learning_rate * self.bf_grad        self.Wih -= self.learning_rate * self.Whi_grad        self.Wix -= self.learning_rate * self.Whi_grad        self.bi -= self.learning_rate * self.bi_grad        self.Woh -= self.learning_rate * self.Wof_grad        self.Wox -= self.learning_rate * self.Wox_grad        self.bo -= self.learning_rate * self.bo_grad        self.Wch -= self.learning_rate * self.Wcf_grad        self.Wcx -= self.learning_rate * self.Wcx_grad        self.bc -= self.learning_rate * self.bc_grad</code></pre><h3 id="梯度检查的实现"><a href="#梯度检查的实现" class="headerlink" title="梯度检查的实现"></a>梯度检查的实现</h3><p>和RecurrentLayer一样，为了支持梯度检查，我们需要支持重置内部状态：</p><pre><code>    def reset_state(self):        # 当前时刻初始化为t0        self.times = 0               # 各个时刻的单元状态向量c        self.c_list = self.init_state_vec()        # 各个时刻的输出向量h        self.h_list = self.init_state_vec()        # 各个时刻的遗忘门f        self.f_list = self.init_state_vec()        # 各个时刻的输入门i        self.i_list = self.init_state_vec()        # 各个时刻的输出门o        self.o_list = self.init_state_vec()        # 各个时刻的即时状态c~        self.ct_list = self.init_state_vec()</code></pre><p>最后，是梯度检查的代码：</p><pre class=" language-lang-python"><code class="language-lang-python">def data_set():    x = [np.array([[1], [2], [3]]),         np.array([[2], [3], [4]])]    d = np.array([[1], [2]])    return x, ddef gradient_check():    '''    梯度检查    '''    # 设计一个误差函数，取所有节点输出项之和    error_function = lambda o: o.sum()    lstm = LstmLayer(3, 2, 1e-3)    # 计算forward值    x, d = data_set()    lstm.forward(x[0])    lstm.forward(x[1])    # 求取sensitivity map    sensitivity_array = np.ones(lstm.h_list[-1].shape,                                dtype=np.float64)    # 计算梯度    lstm.backward(x[1], sensitivity_array, IdentityActivator())    # 检查梯度    epsilon = 10e-4    for i in range(lstm.Wfh.shape[0]):        for j in range(lstm.Wfh.shape[1]):            lstm.Wfh[i,j] += epsilon            lstm.reset_state()            lstm.forward(x[0])            lstm.forward(x[1])            err1 = error_function(lstm.h_list[-1])            lstm.Wfh[i,j] -= 2*epsilon            lstm.reset_state()            lstm.forward(x[0])            lstm.forward(x[1])            err2 = error_function(lstm.h_list[-1])            expect_grad = (err1 - err2) / (2 * epsilon)            lstm.Wfh[i,j] += epsilon            print 'weights(%d,%d): expected - actural %.4e - %.4e' % (                i, j, expect_grad, lstm.Wfh_grad[i,j])    return lstm</code></pre><p>我们只对$W_{fh}$做了检查，读者可以自行增加对其他梯度的检查。下面是某次梯度检查的结果：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-cb1c4561375c22a1.png)</p><h2 id="GRU"><a href="#GRU" class="headerlink" title="GRU"></a>GRU</h2><p>前面我们讲了一种普通的LSTM，事实上LSTM存在很多<strong>变体</strong>，许多论文中的LSTM都或多或少的不太一样。在众多的LSTM变体中，<strong>GRU (Gated Recurrent Unit)</strong>也许是最成功的一种。它对LSTM做了很多简化，同时却保持着和LSTM相同的效果。因此，GRU最近变得越来越流行。</p><p>GRU对LSTM做了两个大改动：</p><ol><li>将输入门、遗忘门、输出门变为两个门：更新门（Update Gate）$\mathbf{z}_t$和重置门（Reset Gate）$\mathbf{r}_t$。</li><li>将单元状态与输出合并为一个状态：$\mathbf{h}$。</li></ol><p>GRU的前向计算公式为：</p><p>$\begin{align} \mathbf{z}_t&amp;=\sigma(W_z\cdot[\mathbf{h}_{t-1},\mathbf{x}_t])\\ \mathbf{r}_t&amp;=\sigma(W_r\cdot[\mathbf{h}_{t-1},\mathbf{x}_t])\\ \mathbf{\tilde{h}}_t&amp;=\tanh(W\cdot[\mathbf{r}_t\circ\mathbf{h}_{t-1},\mathbf{x}_t])\\ \mathbf{h}&amp;=(1-\mathbf{z}_t)\circ\mathbf{h}_{t-1}+\mathbf{z}_t\circ\mathbf{\tilde{h}}_t \end{align} $</p><p>下图是GRU的示意图：</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-b784d887bf693253.png)</p><p>GRU的训练算法比LSTM简单一些，留给读者自行推导，本文就不再赘述了。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>至此，LSTM——也许是结构最复杂的一类神经网络——就讲完了，相信拿下前几篇文章的读者们搞定这篇文章也不在话下吧！现在我们已经了解<strong>循环神经网络</strong>和它最流行的变体——<strong>LSTM</strong>，它们都可以用来处理序列。但是，有时候仅仅拥有处理序列的能力还不够，还需要处理比序列更为复杂的结构（比如树结构），这时候就需要用到另外一类网络：<strong>递归神经网络(Recursive Neural Network)</strong>，巧合的是，它的缩写也是<strong>RNN</strong>。在下一篇文章中，我们将介绍<strong>递归神经网络</strong>和它的训练算法。现在，漫长的烧脑暂告一段落，休息一下吧:)</p><p><img src="%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0(6" alt="img">%20-%20%E9%95%BF%E7%9F%AD%E6%97%B6%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C(LSTM)/2256672-9ba33f65294bfb98.jpg)</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li><a href="http://cs224d.stanford.edu/" target="_blank" rel="noopener">CS224d: Deep Learning for Natural Language Processing</a></li><li><a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a></li><li><a href="http://arunmallya.github.io/writeups/nn/lstm/index.html" target="_blank" rel="noopener">LSTM Forward and Backward Pass</a></li></ol>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Generate Tweets Using Markov Chains</title>
      <link href="/other/generate-tweets-using-markov-chain/"/>
      <url>/other/generate-tweets-using-markov-chain/</url>
      
        <content type="html"><![CDATA[<h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><pre class=" language-lang-python"><code class="language-lang-python">import markovify</code></pre><h2 id="Load-Corpus"><a href="#Load-Corpus" class="headerlink" title="Load Corpus"></a>Load Corpus</h2><p>The corpus I am using is just one I found online. The corpus you choose is central to generating realistic text.</p><pre class=" language-lang-python"><code class="language-lang-python"># Get raw text as stringwith open("brown.txt") as f:    text = f.read()</code></pre><h2 id="Build-Markov-Chain"><a href="#Build-Markov-Chain" class="headerlink" title="Build Markov Chain"></a>Build Markov Chain</h2><pre class=" language-lang-python"><code class="language-lang-python"># Build the model.text_model = markovify.Text(text)</code></pre><h1 id="Generate-One-Tweet"><a href="#Generate-One-Tweet" class="headerlink" title="Generate One Tweet"></a>Generate One Tweet</h1><pre class=" language-lang-python"><code class="language-lang-python"># Print three randomly-generated sentences of no more than 140 charactersfor i in range(3):    print(text_model.make_short_sentence(140))</code></pre><pre><code>Within a month, calls were still productive and most devotees of baseball attended the dozens of them.Even death, therefore, has a leather bolo drawn through a local rajah in 1949.He had a rather sharp and confident.</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Mine Twitter&#39;s Stream For Hashtags Or Words</title>
      <link href="/other/mine-a-twitter-hashtags-and-words/"/>
      <url>/other/mine-a-twitter-hashtags-and-words/</url>
      
        <content type="html"><![CDATA[<p>This is a script which monitor’s Twitter for tweets containing certain hashtags, words, or phrases. When one of those appears, it saves that tweet, and the user’s information to a csv file. A similar version of this script is available on <a href="https://github.com/chrisalbon/twitter_miner" target="_blank" rel="noopener">GitHub here</a>. The main difference between the code presented here and the repo is that here I am added extensive comments in the code explaining what is happening. Also, the code below runs as a Jupyter notebook.</p><p>To get the code below to run, you need to added your own Twitter API credentials.</p><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><pre class=" language-lang-python"><code class="language-lang-python">#Import librariesfrom tweepy.streaming import StreamListenerfrom tweepy import OAuthHandlerfrom tweepy import Streamimport timeimport csvimport sys</code></pre><h2 id="Create-A-Twitter-Stream-Miner"><a href="#Create-A-Twitter-Stream-Miner" class="headerlink" title="Create A Twitter Stream Miner"></a>Create A Twitter Stream Miner</h2><pre class=" language-lang-python"><code class="language-lang-python"># Create a streamer objectclass StdOutListener(StreamListener):    # Define a function that is initialized when the miner is called    def __init__(self, api = None):        # That sets the api        self.api = api        # Create a file with 'data_' and the current time        self.filename = 'data'+'_'+time.strftime('%Y%m%d-%H%M%S')+'.csv'        # Create a new file with that filename        csvFile = open(self.filename, 'w')        # Create a csv writer        csvWriter = csv.writer(csvFile)        # Write a single row with the headers of the columns        csvWriter.writerow(['text',                            'created_at',                            'geo',                            'lang',                            'place',                            'coordinates',                            'user.favourites_count',                            'user.statuses_count',                            'user.description',                            'user.location',                            'user.id',                            'user.created_at',                            'user.verified',                            'user.following',                            'user.url',                            'user.listed_count',                            'user.followers_count',                            'user.default_profile_image',                            'user.utc_offset',                            'user.friends_count',                            'user.default_profile',                            'user.name',                            'user.lang',                            'user.screen_name',                            'user.geo_enabled',                            'user.profile_background_color',                            'user.profile_image_url',                            'user.time_zone',                            'id',                            'favorite_count',                            'retweeted',                            'source',                            'favorited',                            'retweet_count'])    # When a tweet appears    def on_status(self, status):        # Open the csv file created previously        csvFile = open(self.filename, 'a')        # Create a csv writer        csvWriter = csv.writer(csvFile)        # If the tweet is not a retweet        if not 'RT @' in status.text:            # Try to             try:                # Write the tweet's information to the csv file                csvWriter.writerow([status.text,                                    status.created_at,                                    status.geo,                                    status.lang,                                    status.place,                                    status.coordinates,                                    status.user.favourites_count,                                    status.user.statuses_count,                                    status.user.description,                                    status.user.location,                                    status.user.id,                                    status.user.created_at,                                    status.user.verified,                                    status.user.following,                                    status.user.url,                                    status.user.listed_count,                                    status.user.followers_count,                                    status.user.default_profile_image,                                    status.user.utc_offset,                                    status.user.friends_count,                                    status.user.default_profile,                                    status.user.name,                                    status.user.lang,                                    status.user.screen_name,                                    status.user.geo_enabled,                                    status.user.profile_background_color,                                    status.user.profile_image_url,                                    status.user.time_zone,                                    status.id,                                    status.favorite_count,                                    status.retweeted,                                    status.source,                                    status.favorited,                                    status.retweet_count])            # If some error occurs            except Exception as e:                # Print the error                print(e)                # and continue                pass        # Close the csv file        csvFile.close()        # Return nothing        return    # When an error occurs    def on_error(self, status_code):        # Print the error code        print('Encountered error with status code:', status_code)        # If the error code is 401, which is the error for bad credentials        if status_code == 401:            # End the stream            return False    # When a deleted tweet appears    def on_delete(self, status_id, user_id):        # Print message        print("Delete notice")        # Return nothing        return    # When reach the rate limit    def on_limit(self, track):        # Print rate limiting error        print("Rate limited, continuing")        # Continue mining tweets        return True    # When timed out    def on_timeout(self):        # Print timeout message        print(sys.stderr, 'Timeout...')        # Wait 10 seconds        time.sleep(10)        # Return nothing        return</code></pre><h2 id="Create-A-Wrapper-For-The-Miner"><a href="#Create-A-Wrapper-For-The-Miner" class="headerlink" title="Create A Wrapper For The Miner"></a>Create A Wrapper For The Miner</h2><pre class=" language-lang-python"><code class="language-lang-python"># Create a mining functiondef start_mining(queries):    '''    Inputs list of strings. Returns tweets containing those strings.    '''    #Variables that contains the user credentials to access Twitter API    consumer_key = "YOUR_CREDENTIALS"    consumer_secret = "YOUR_CREDENTIALS"    access_token = "YOUR_CREDENTIALS"    access_token_secret = "YOUR_CREDENTIALS"    # Create a listener    l = StdOutListener()    # Create authorization info    auth = OAuthHandler(consumer_key, consumer_secret)    auth.set_access_token(access_token, access_token_secret)    # Create a stream object with listener and authorization    stream = Stream(auth, l)    # Run the stream object using the user defined queries    stream.filter(track=queries)</code></pre><h2 id="Run-The-Stream-Miner"><a href="#Run-The-Stream-Miner" class="headerlink" title="Run The Stream Miner"></a>Run The Stream Miner</h2><pre class=" language-lang-python"><code class="language-lang-python"># Start the minerstart_mining(['python', '#Python'])</code></pre><pre><code>Encountered error with status code: 401</code></pre>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>What Is The Probability An Economy Class Seat Is An Aisle Seat?</title>
      <link href="/other/aisle-seat-probabilities/"/>
      <url>/other/aisle-seat-probabilities/</url>
      
        <content type="html"><![CDATA[<p>There are two types of people in the world, aisle seaters and window seaters. I am an aisle seater, nothing is worse than limited bathroom access on a long flight. The first thing I do when I get my ticket is check to see if I have a window seat. If not, I immediately head over to the airline counter and try to get one.</p><p>Last flight, on Turkish Airlines, I ran into a curious situation. I recieved my boarding pass with my seat number, 18C, but the ticket did not specify if C was an aisle seat or not. Making matters worse, the airline counter was swamped with a few dozen people. So I asked myself: <strong>given only the seat letter, C, what is the probability that it is an aisle seat?</strong></p><p>Later, on the flight, I decided to find out.</p><h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><pre class=" language-lang-python"><code class="language-lang-python"># Import required modulesimport pandas as pdimport numpy as np# Set plots to display in the iPython notebook%matplotlib inline</code></pre><h2 id="Setup-possible-seat-configurations"><a href="#Setup-possible-seat-configurations" class="headerlink" title="Setup possible seat configurations"></a>Setup possible seat configurations</h2><p>I am a pretty frequently flyer on a variety of airlines and aircraft. There are a variety of seating configurations out there, but typically they follow some basic rules:</p><ul><li>No window cluster of seats has more than three seats.</li><li>On small flights with three seats, the single seat is on the left side.</li><li>No flight has more than nine rows.</li></ul><p>Based on these rules, here are the “typical” seating configurations from aircraft with between two and nine seats per row. A ‘1’ codifies that a seat is an aisle seat, a ‘0’ codifies that it is a non-aisle seat (i.e. window or middle), and ‘np.nan’ denotes that the aircraft has less than nine seats (this is so all the list lengths are the same). </p><pre class=" language-lang-python"><code class="language-lang-python"># An aircraft with two seats per rowrows2 = [1,1, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan]# An aircraft with three seats per rowrows3 = [1,1,0, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan,]# An aircraft with four seats per rowrows4 = [0,1,1,0, np.nan, np.nan, np.nan, np.nan, np.nan]# An aircraft with five seats per rowrows5 = [0,1,1,0,0, np.nan, np.nan,np.nan, np.nan]# An aircraft with six seats per rowrows6 = [0,1,1,1,1,0, np.nan, np.nan, np.nan]# An aircraft with seven seats per rowrows7 = [0,1,1,0,1,1,0, np.nan, np.nan]# An aircraft with eight seats per rowrows8 = [0,0,1,1,1,1,0,0, np.nan]# An aircraft with nine seats per rowrows9 = [0,0,1,1,0,1,1,0,0]</code></pre><p>For example, in an aircraft with five seats per row, <code>rows5</code>, the seating arrangement would be:</p><ol><li>window</li><li>aisle</li><li>aisle</li><li>middle</li><li>window</li><li>no seat</li><li>no seat</li><li>no seat</li><li>no seat</li></ol><p>Next, I’m take advantage of pandas row summation options, but to do this I need to wrangle the data into a pandas dataframe. Essentially I am using the pandas dataframe as a matrix.</p><pre class=" language-lang-python"><code class="language-lang-python"># Create a list variable of all possible aircraft configurationsseating_map = [rows2, rows3, rows4, rows5, rows6, rows7, rows8, rows9]</code></pre><pre class=" language-lang-python"><code class="language-lang-python"># Create a dataframe from the seating_map variabledf = pd.DataFrame(seating_map,                   columns=['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'],                  index=['rows2', 'rows3', 'rows4', 'rows5', 'rows6', 'rows7', 'rows8', 'rows9'])</code></pre><p>Here is all the data we need to construct our probabilities. The columns represent individual seat letters (A, B, etc.) while the rows represent the number of seats-per-row in the aircraft.</p><pre class=" language-lang-python"><code class="language-lang-python"># View the dataframedf</code></pre><div><style>    .dataframe thead tr:only-child th {        text-align: right;    }    .dataframe thead th {        text-align: left;    }    .dataframe tbody tr th {        vertical-align: top;    }</style><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>A</th>      <th>B</th>      <th>C</th>      <th>D</th>      <th>E</th>      <th>F</th>      <th>G</th>      <th>H</th>      <th>I</th>    </tr>  </thead>  <tbody>    <tr>      <th>rows2</th>      <td>1</td>      <td>1</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>rows3</th>      <td>1</td>      <td>1</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>rows4</th>      <td>0</td>      <td>1</td>      <td>1.0</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>rows5</th>      <td>0</td>      <td>1</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>rows6</th>      <td>0</td>      <td>1</td>      <td>1.0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>rows7</th>      <td>0</td>      <td>1</td>      <td>1.0</td>      <td>0.0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>NaN</td>      <td>NaN</td>    </tr>    <tr>      <th>rows8</th>      <td>0</td>      <td>0</td>      <td>1.0</td>      <td>1.0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>      <td>NaN</td>    </tr>    <tr>      <th>rows9</th>      <td>0</td>      <td>0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>1.0</td>      <td>1.0</td>      <td>0.0</td>      <td>0.0</td>    </tr>  </tbody></table></div><h2 id="Calculate-aisle-probability"><a href="#Calculate-aisle-probability" class="headerlink" title="Calculate aisle probability"></a>Calculate aisle probability</h2><p>Because each aircraft seats-per-row configuration (i.e. row) is binary (1 if aisle, 0 if non-aisle), the probability that a seat is an aisle is simply the mean value of each seat letter (i.e. column).</p><pre class=" language-lang-python"><code class="language-lang-python"># Create a list wherein each element is the mean value of a columnaisle_probability = [df['A'].mean(),                      df['B'].mean(),                     df['C'].mean(),                     df['D'].mean(),                     df['E'].mean(),                     df['F'].mean(),                     df['G'].mean(),                     df['H'].mean(),                     df['I'].mean()]</code></pre><pre class=" language-lang-python"><code class="language-lang-python"># Display the variableaisle_probability</code></pre><pre><code>[0.25, 0.75, 0.8571428571428571, 0.5, 0.6, 0.75, 0.3333333333333333, 0.0, 0.0]</code></pre><p>So there you have it, the probability that each seat letter is an aisle. However, we can make the presentation a little more intituative.</p><h2 id="Visualize-seat-letter-probabilities"><a href="#Visualize-seat-letter-probabilities" class="headerlink" title="Visualize seat letter probabilities"></a>Visualize seat letter probabilities</h2><p>The most obvious visualization to convey the probabilities would be seat letters on the x-axis and probabilities on the y-axis. Panda’s plot function makes that easy.</p><pre class=" language-lang-python"><code class="language-lang-python"># Create a list of strings to use as the x-axis labelsseats = ['Seat A', 'Seat B', 'Seat C', 'Seat D',          'Seat E', 'Seat F', 'Seat G', 'Seat H', 'Seat I']</code></pre><pre class=" language-lang-python"><code class="language-lang-python"># Plot the probabilities, using 'seats' as the index as a bar chartpd.Series(aisle_probability, index=seats).plot(kind='bar', # set y to range between 0 and 1                                                    ylim=[0,1],                                                    # set the figure size                                                    figsize=[10,6],                                                    # set the figure title                                                    title='Probabilty of being an Aisle Seat in Economy Class')</code></pre><pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x10f1231d0&gt;</code></pre><p><img src="aisle_seat_probabilities_20_1.png" alt="png"></p><p>So there we have it! If given a boarding pass with seat C you have a 86% probability of being in an aisle seat!</p><p>I hope this was helpful!</p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>Simple Clustering With SciPy</title>
      <link href="/other/scipy-simple-clustering/"/>
      <url>/other/scipy-simple-clustering/</url>
      
        <content type="html"><![CDATA[<h3 id="Import-modules"><a href="#Import-modules" class="headerlink" title="Import modules"></a>Import modules</h3><pre class=" language-lang-python"><code class="language-lang-python">import numpy as np%matplotlib inlineimport matplotlib.pyplot as pltfrom scipy.cluster import vq</code></pre><h3 id="Create-coordinates-for-battles-for-each-year-of-the-war"><a href="#Create-coordinates-for-battles-for-each-year-of-the-war" class="headerlink" title="Create coordinates for battles for each year of the war"></a>Create coordinates for battles for each year of the war</h3><pre class=" language-lang-python"><code class="language-lang-python"># create 100 coordinate pairs (i.e. two values), then add 5 to all of themyear_1 = np.random.randn(100, 2) + 5# create 30 coordinatee pairs (i.e. two values), then subtract 5 to all of themyear_2 = np.random.randn(30, 2) - 5# create 50 coordinatee pairs (i.e. two values)year_3 = np.random.randn(50, 2)</code></pre><h3 id="View-the-first-3-entries-of-each-year-of-battles"><a href="#View-the-first-3-entries-of-each-year-of-battles" class="headerlink" title="View the first 3 entries of each year of battles"></a>View the first 3 entries of each year of battles</h3><pre class=" language-lang-python"><code class="language-lang-python">print('year 1 battles:',  year_1[0:3])print('year 2 battles:', year_2[0:3])print('year 3 battles:', year_3[0:3])</code></pre><pre><code>year 1 battles: [[ 5.25720722  4.78051294] [ 4.11980541  6.24062638] [ 4.04612449  5.23819217]]year 2 battles: [[-3.90607071 -5.20880154] [-4.14244415 -4.52520445] [-6.01162308 -5.53489708]]year 3 battles: [[-0.54820297 -0.97483204] [ 0.12813873  0.55198748] [-0.55677223 -0.68900608]]</code></pre><h3 id="Pool-all-three-years-of-coordinates"><a href="#Pool-all-three-years-of-coordinates" class="headerlink" title="Pool all three years of coordinates"></a>Pool all three years of coordinates</h3><pre class=" language-lang-python"><code class="language-lang-python"># vertically stack year_1, year_2, and year_3 elementsbattles = np.vstack([year_1, year_2, year_3])</code></pre><h3 id="Cluster-the-battle-locations-into-three-groups"><a href="#Cluster-the-battle-locations-into-three-groups" class="headerlink" title="Cluster the battle locations into three groups"></a>Cluster the battle locations into three groups</h3><pre class=" language-lang-python"><code class="language-lang-python"># calculate the centroid coordinates of each cluster # and the variance of all the clusterscentroids, variance  = vq.kmeans(battles, 3)</code></pre><h3 id="View-the-centroid-coordinate-for-each-of-the-three-clusters"><a href="#View-the-centroid-coordinate-for-each-of-the-three-clusters" class="headerlink" title="View the centroid coordinate for each of the three clusters"></a>View the centroid coordinate for each of the three clusters</h3><pre class=" language-lang-python"><code class="language-lang-python">centroids</code></pre><pre><code>array([[ 5.02707263,  5.03041508],       [-0.05392784,  0.12892838],       [-4.88957266, -4.85051116]])</code></pre><h3 id="View-the-variance-of-the-clusters-they-all-share-the-same"><a href="#View-the-variance-of-the-clusters-they-all-share-the-same" class="headerlink" title="View the variance of the clusters (they all share the same)"></a>View the variance of the clusters (they all share the same)</h3><pre class=" language-lang-python"><code class="language-lang-python">variance</code></pre><pre><code>1.2948126660038406</code></pre><h3 id="Seperate-the-battle-data-into-clusters"><a href="#Seperate-the-battle-data-into-clusters" class="headerlink" title="Seperate the battle data into clusters"></a>Seperate the battle data into clusters</h3><pre class=" language-lang-python"><code class="language-lang-python">identified, distance = vq.vq(battles, centroids)</code></pre><h3 id="View-the-cluster-of-each-battle"><a href="#View-the-cluster-of-each-battle" class="headerlink" title="View the cluster of each battle"></a>View the cluster of each battle</h3><pre class=" language-lang-python"><code class="language-lang-python">identified</code></pre><pre><code>array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)</code></pre><h3 id="View-the-distance-of-each-individual-battle-from-their-cluster’s-centroid"><a href="#View-the-distance-of-each-individual-battle-from-their-cluster’s-centroid" class="headerlink" title="View the distance of each individual battle from their cluster’s centroid"></a>View the distance of each individual battle from their cluster’s centroid</h3><pre class=" language-lang-python"><code class="language-lang-python">distance</code></pre><pre><code>array([ 0.3397249 ,  1.51252941,  1.00271161,  0.7583883 ,  0.58103782,        1.81905849,  1.45452846,  1.34523274,  0.69254441,  3.32123157,        1.73900653,  1.01999434,  1.5392708 ,  0.64417605,  1.25822142,        1.68913457,  1.09543587,  0.20750281,  2.90778804,  1.62549404,        1.0224336 ,  1.05196193,  0.98434964,  0.25634371,  1.19779956,        1.73517217,  2.69339667,  1.32792584,  0.97809768,  1.52654056,        2.20554365,  1.0403091 ,  0.93698624,  1.53359041,  0.91717984,        0.3008527 ,  0.42901893,  0.95824461,  1.93321831,  1.89139314,        1.49982335,  0.63265951,  1.48579627,  1.04574742,  0.83477916,        2.80489932,  1.50671741,  0.35230994,  1.18607368,  1.36078497,        1.17298152,  0.95961251,  0.95348923,  1.41903574,  1.7816999 ,        1.32087763,  0.94807163,  2.22741733,  0.66198152,  0.97404075,        0.24009773,  1.22021557,  1.36298565,  1.77358477,  0.62586652,        1.45234278,  1.87925214,  2.18673534,  0.97113871,  1.0436524 ,        1.63491437,  1.43922603,  1.8066756 ,  2.55661988,  0.64905457,        0.6939938 ,  1.41183181,  2.72140674,  1.70390906,  3.53986459,        1.52044903,  1.98702847,  1.2488108 ,  2.61774172,  2.66067284,        0.80078946,  0.79648259,  2.72215296,  1.26904383,  1.16048896,        1.42571458,  1.18519189,  0.46592397,  0.63831379,  0.2294296 ,        0.90199062,  0.99296186,  1.79154225,  0.23854105,  1.19095902,        1.0467321 ,  0.81487758,  1.31429876,  0.14625493,  1.04421102,        0.72132375,  2.2209666 ,  1.00145286,  1.30465026,  1.57217776,        1.31999891,  0.80321763,  2.12942642,  0.81168612,  1.40294667,        0.89994242,  1.70402817,  0.79621269,  1.29554062,  1.87340273,        2.40582742,  2.99089606,  1.01348705,  0.54974364,  0.39367389,        2.28343779,  1.51924388,  0.52095884,  1.54219385,  0.62972955,        1.20937793,  0.46057272,  0.96014023,  0.2287637 ,  0.84009151,        1.34393522,  1.5983523 ,  0.46066181,  0.49504327,  2.22788557,        1.74688212,  1.99998478,  0.25864751,  1.06955924,  1.68029793,        3.41862662,  1.9273365 ,  0.91580509,  0.94390424,  1.42991149,        0.64314749,  0.26250126,  1.09000179,  0.42658645,  0.40866344,        0.47829004,  0.47718204,  0.53641019,  1.42037169,  2.20413065,        1.85270104,  1.9544685 ,  1.40727147,  0.85730366,  1.63316935,        1.09642325,  1.36490331,  1.307389  ,  1.9727463 ,  1.35859479,        2.43699622,  0.80833152,  2.50758584,  0.95216108,  0.16936114,        0.98714981,  0.19962377,  1.13262204,  2.47056129,  2.00154513])</code></pre><h3 id="Index-the-battles-data-by-the-cluster-to-which-they-belong"><a href="#Index-the-battles-data-by-the-cluster-to-which-they-belong" class="headerlink" title="Index the battles data by the cluster to which they belong"></a>Index the battles data by the cluster to which they belong</h3><pre class=" language-lang-python"><code class="language-lang-python">cluster_1 = battles[identified == 0]cluster_2 = battles[identified == 1]cluster_3 = battles[identified == 2]</code></pre><h3 id="Print-the-first-three-coordinate-pairs-of-each-cluster"><a href="#Print-the-first-three-coordinate-pairs-of-each-cluster" class="headerlink" title="Print the first three coordinate pairs of each cluster"></a>Print the first three coordinate pairs of each cluster</h3><pre class=" language-lang-python"><code class="language-lang-python">print(cluster_1[0:3])print(cluster_2[0:3])print(cluster_3[0:3])</code></pre><pre><code>[[ 5.25720722  4.78051294] [ 4.11980541  6.24062638] [ 4.04612449  5.23819217]][[-0.54820297 -0.97483204] [ 0.12813873  0.55198748] [-0.55677223 -0.68900608]][[-3.90607071 -5.20880154] [-4.14244415 -4.52520445] [-6.01162308 -5.53489708]]</code></pre><h3 id="Plot-all-the-battles-color-each-battle-by-cluster"><a href="#Plot-all-the-battles-color-each-battle-by-cluster" class="headerlink" title="Plot all the battles, color each battle by cluster"></a>Plot all the battles, color each battle by cluster</h3><pre class=" language-lang-python"><code class="language-lang-python"># create a scatter plot there the x-axis is the first column of battles# the y-axis is the second column of battles, the size is 100, and# the color of each point is determined by the indentified variableplt.scatter(battles[:,0], battles[:,1], s=100, c=identified)</code></pre><pre><code>&lt;matplotlib.collections.PathCollection at 0x10d43f588&gt;</code></pre><p><img src="scipy_simple_clustering_26_1.png" alt="png"></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
